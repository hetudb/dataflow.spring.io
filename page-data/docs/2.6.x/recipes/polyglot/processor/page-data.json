{"componentChunkName":"component---src-templates-documentation-js","path":"/docs/2.6.x/recipes/polyglot/processor/","result":{"data":{"pages":{"edges":[{"node":{"id":"d4eb66c4-5040-5518-8791-0facfe4ef019","fields":{"path":"/docs/2.6.x/installation/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Installation","description":"How to install Data Flow","path":"installation/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"55fe19c0-5937-50ce-9b8b-c111fa28b393","fields":{"path":"/docs/2.6.x/installation/local/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Local Machine","description":"Local Machine Installation Guide","path":"installation/local/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0468a110-a1f9-5437-a130-2a8fef3720ae","fields":{"path":"/docs/2.6.x/installation/local/docker/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Docker Compose","description":"Installation using Docker Compose","path":"installation/local/docker","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"93ff4cc6-719a-528c-a0c2-bd692215126c","fields":{"path":"/docs/2.6.x/installation/local/docker-customize/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Docker Compose Customization","description":"Customize the Docker Compose installation","path":"installation/local/docker-customize","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d7c6dbb6-dc16-5cdd-b5fd-bd4ac72301b2","fields":{"path":"/docs/2.6.x/installation/local/manual/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Manual","description":"Manual installation","path":"installation/local/manual","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7a05059c-c9e6-559a-93b4-3f145feea083","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry","description":"Data Flow Cloud Foundry Installation Guide","path":"installation/cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"eafb71a0-7f1b-52e4-a928-3dcdeb69b50e","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/cf-cli/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry CLI","description":"Install using the Cloud Foundry CLI","path":"installation/cloudfoundry/cf-cli","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"897ab8e6-86a7-57b6-95e9-d87939b082b7","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/cf-local/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Running locally","description":"Configure the local servers to deploy to Cloud Foundry","path":"installation/cloudfoundry/cf-local","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cae53d6a-9175-53a4-b94d-e87f5fcbf09c","fields":{"path":"/docs/2.6.x/installation/kubernetes/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Kubernetes","description":"Data Flow Kubernetes Installation Guide","path":"installation/kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d64f0f3d-2987-50c9-839c-61c17844f4b4","fields":{"path":"/docs/2.6.x/installation/kubernetes/creating-a-cluster/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Creating a Cluster","description":"Creating a Kubernetes Cluster","path":"installation/kubernetes/creating-a-cluster","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2efdd123-cbc4-5d26-bba1-52f378682148","fields":{"path":"/docs/2.6.x/installation/kubernetes/helm/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Helm","description":"Installation using Helm","path":"installation/kubernetes/helm","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2bdbe862-6bed-533d-8be5-502d8be827e3","fields":{"path":"/docs/2.6.x/installation/kubernetes/kubectl/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"kubectl","description":"Installation using kubectl","path":"installation/kubernetes/kubectl","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4d0da4fd-6198-51a0-946e-3503f626614b","fields":{"path":"/docs/2.6.x/installation/kubernetes/compatibility/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Kubernetes Compatibility","description":"Compatibility with Kubernetes Versions","path":"installation/kubernetes/compatibility","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"91c992f9-9acd-5928-b351-29468fcea493","fields":{"path":"/docs/2.6.x/concepts/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Concepts","description":"Core Concepts in Spring Cloud Data Flow","path":"concepts/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a06d76f8-3a10-5199-9e1b-7f6077e6c532","fields":{"path":"/docs/2.6.x/concepts/architecture/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Architecture","description":"Introduction to Data Flow's Architecture.","path":"concepts/architecture/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"94f3cfcf-6bd5-5c38-b5b9-22874a071ea6","fields":{"path":"/docs/2.6.x/concepts/streams/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Stream Processing","description":"Stream Processing Framework and Concepts","path":"concepts/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3eab1b33-471e-5357-8745-9849bd960ff2","fields":{"path":"/docs/2.6.x/concepts/batch-jobs/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Batch Processing","description":"Batch Processing Framework and Concepts","path":"concepts/batch-jobs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bf947dc7-2380-5011-8573-8a6329f35cf1","fields":{"path":"/docs/2.6.x/concepts/monitoring/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Monitoring","description":"Runtime monitoring of Stream data pipelines","path":"concepts/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"65bac064-3e6a-5bed-9e2f-8ff830588879","fields":{"path":"/docs/2.6.x/concepts/tooling/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Tooling","description":"Dashboard and Shell","path":"concepts/tooling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"17639b95-6dca-58ea-a1c8-078112d55d5d","fields":{"path":"/docs/2.6.x/stream-developer-guides/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Developer guides ","description":"Learn how to create Streaming data pipelines using prebuilt microservices or create your own.","path":"stream-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d626d6a5-f24a-5a50-b080-05c354e24229","fields":{"path":"/docs/2.6.x/stream-developer-guides/getting-started/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Stream Processing","path":"stream-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8faa20b9-2b8b-58e3-a1b4-4c604d3e43b6","fields":{"path":"/docs/2.6.x/stream-developer-guides/getting-started/stream/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing","description":"Create and deploy a streaming data pipeline using prebuilt applications on your Local Machine","path":"stream-developer-guides/getting-started/stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1e0d632f-b411-570f-a8e3-e51b6725e104","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Development","description":"Stream Processing Developer Guide","path":"stream-developer-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b40acf35-a4eb-53cd-9008-7bbcec53aed0","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/standalone-stream-rabbitmq/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on RabbitMQ","description":"Create your own microservices for Stream processing using RabbitMQ and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b2392640-d4bb-5f50-90c4-a776e1f13b3b","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/standalone-stream-kafka/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on Apache Kafka","description":"Create your own microservices for Stream processing using Apache Kafka and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8fc394f4-b438-500d-b8ab-535b53b8ab1e","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/data-flow-stream/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing using Spring Cloud Data Flow","description":"Create and Deploy a Stream Processing Pipeline using Spring Cloud Data Flow","path":"stream-developer-guides/streams/data-flow-stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4ded6921-2628-5cc1-b6a5-5dfb7059b4f4","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/stream-other-binders/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Spring Application Development on other Messaging Middleware","description":"Create your own microservices for Stream processing using other messaging middleware such as Google Pub/Sub, Amazon Kinesis, and Solace JMS","path":"stream-developer-guides/streams/stream-other-binders/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"01f6e12a-61b7-5a1a-8b2a-b717c0d31081","fields":{"path":"/docs/2.6.x/stream-developer-guides/programming-models/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Programming Models","description":"Programming models","path":"stream-developer-guides/programming-models/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f7fdfd7a-3b6f-5256-95eb-d155d344768c","fields":{"path":"/docs/2.6.x/stream-developer-guides/continuous-delivery/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery","description":"CD using Skipper","path":"stream-developer-guides/continuous-delivery/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"29a5a86c-23e2-5ea1-bcb9-915964c6951e","fields":{"path":"/docs/2.6.x/stream-developer-guides/continuous-delivery/cd-basics/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery of streaming applications","description":"Continuous Delivery of Streaming applications","path":"stream-developer-guides/continuous-delivery/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c8560c94-0744-5875-a3fc-9a0262600793","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Streams","path":"stream-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6082c898-df9d-5ba4-b0d9-e693c0f45b8a","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/debugging-stream-apps/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream Applications","description":"Debugging Stream Applications outside of Data Flow","path":"stream-developer-guides/troubleshooting/debugging-stream-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b332aa16-2897-534f-b06d-7445ae3743ed","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/debugging-scdf-streams/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream applications deployed by Data Flow","description":"Debugging Data Flow Stream deployments","path":"stream-developer-guides/troubleshooting/debugging-scdf-streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4de0aad5-b76a-5f58-9418-82e6abb6daa0","fields":{"path":"/docs/2.6.x/batch-developer-guides/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"batch-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"40856a0d-0eea-5698-b001-2560c7c08986","fields":{"path":"/docs/2.6.x/batch-developer-guides/getting-started/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Batch","path":"batch-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"181a41ff-8e14-5802-a348-3dcbd91207b6","fields":{"path":"/docs/2.6.x/batch-developer-guides/getting-started/task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Task Processing","description":"Create and deploy a simple Task pipeline using a prebuilt Task application on your local machine","path":"batch-developer-guides/getting-started/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2e8201c8-0ac3-5cbc-a9ff-4d46568a11ba","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Development","description":"Batch Developer Guide","path":"batch-developer-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"eef2d991-e898-5491-bcb1-ad963a84b2ae","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/spring-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"batch-developer-guides/batch/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d15169a4-cdbb-5f3c-95d3-34c55864e9a3","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/spring-batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"batch-developer-guides/batch/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e790e5f2-09a4-5474-a09c-c0060231388a","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2f90faa8-a4c1-5997-96d2-4f97103be151","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-spring-batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"batch-developer-guides/batch/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"fd94641a-89b7-5567-8263-357f50ecc764","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-composed-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"batch-developer-guides/batch/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"afe38fbe-1362-51fd-9d87-4e3326859ba7","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task-kubernetes/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"33858feb-00dd-5223-bd77-da1894c5c453","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a4c38b30-a881-51c7-b7c7-ad2c2eab6127","fields":{"path":"/docs/2.6.x/batch-developer-guides/continuous-deployment/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"batch-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"89a04294-fb0e-5411-9adf-ef7dbcc5b2ab","fields":{"path":"/docs/2.6.x/batch-developer-guides/continuous-deployment/cd-basics/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"batch-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"472bfd60-d1e4-5d78-bce1-7fbcac20a106","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"batch-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b3319e09-bc9a-58ac-ac3f-d25edafcc8eb","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/debugging-task-apps/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"batch-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"70e3c3cf-5558-581e-8f8c-fe7665bc89d1","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"batch-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d7b32b66-26ca-5f77-b4c8-faa482449080","fields":{"path":"/docs/2.6.x/feature-guides/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Feature guides","description":"High level overview of Data Flow Features","path":"feature-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c78c28bf-a6d5-53b5-bc0a-4aeb6428e293","fields":{"path":"/docs/2.6.x/feature-guides/general/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"General","description":"General Features in Data Flow","path":"feature-guides/general/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4d39f197-0252-5cdf-88f7-796e8ddd772a","fields":{"path":"/docs/2.6.x/feature-guides/general/application-metadata/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Application Metadata","description":"Create and use application properties metadata","path":"feature-guides/general/application-metadata/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"394b1c87-f6b9-5611-a670-74158473d94e","fields":{"path":"/docs/2.6.x/feature-guides/streams/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Streams","description":"Stream Features in Data Flow","path":"feature-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6c7e764e-1682-59d7-9dd6-89eeb7291700","fields":{"path":"/docs/2.6.x/feature-guides/streams/deployment-properties/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a stream deployment with deployment property overrides","path":"feature-guides/streams/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8cdf006d-4a35-5c0e-b3c1-62689c101fe6","fields":{"path":"/docs/2.6.x/feature-guides/streams/function-composition/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Composing Functions","description":"Daisy-chain Java functions in an existing Spring Cloud Stream application","path":"feature-guides/streams/function-composition/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e7ac087d-3d96-5a5b-a217-55d3cbc5fca3","fields":{"path":"/docs/2.6.x/feature-guides/streams/named-destinations/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Named Destinations","description":"Use the Named Destinations to interact with the Topics/Queues directly","path":"feature-guides/streams/named-destinations/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"31cf45b3-bb88-55ab-9090-b345b99bc785","fields":{"path":"/docs/2.6.x/feature-guides/streams/monitoring/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Stream Monitoring","description":"Monitoring streaming data pipelines with Prometheus and InfluxDB","path":"feature-guides/streams/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"152fe9be-20da-5dc5-82bc-260e301b6583","fields":{"path":"/docs/2.6.x/feature-guides/streams/stream-application-dsl/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Stream Application DSL","description":"Learn how to use the Stream Application DSL","path":"feature-guides/streams/stream-application-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"03ad3b84-bfd0-56cb-b9a0-118ed454cb37","fields":{"path":"/docs/2.6.x/feature-guides/streams/labels/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Labeling Applications","description":"Label the stream applications to uniquely interact with them","path":"feature-guides/streams/labels/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6a22ede4-9643-55c9-8c7c-7987b8c6309d","fields":{"path":"/docs/2.6.x/feature-guides/streams/application-count/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Application Count","description":"Initiate stream deployment with multiple application instances","path":"feature-guides/streams/application-count/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9705414f-cfa2-5928-ab08-5d4343443bd1","fields":{"path":"/docs/2.6.x/feature-guides/streams/fanin-fanout/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Fan-in and Fan-out","description":"Publish and subscribe to multiple destinations using the fan-in and fan-out capabilities","path":"feature-guides/streams/fanin-fanout/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dbd86818-7801-5f87-a49f-9be67b912a6d","fields":{"path":"/docs/2.6.x/feature-guides/streams/partitioning/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Data Partitioning","description":"Learn more about data partitioning support to build stateful streaming data pipelines","path":"feature-guides/streams/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a7310690-ab0f-55bb-861b-3184d0bc0dd8","fields":{"path":"/docs/2.6.x/feature-guides/streams/scaling/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Scaling","description":"Scaling streaming data pipeline with Spring Cloud Data Flow","path":"feature-guides/streams/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"686c7331-267e-5e19-b340-a748d20e1de2","fields":{"path":"/docs/2.6.x/feature-guides/streams/java-dsl/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Java DSL","description":"Programmatically create streams using the Java DSL","path":"feature-guides/streams/java-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3de6ad19-6800-554e-9482-f93ad877682a","fields":{"path":"/docs/2.6.x/feature-guides/streams/taps/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Tapping a Stream","description":"Create a stream from another stream without interrupting the data processing","path":"feature-guides/streams/taps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2ebd228a-2f1c-5c3f-86c3-6d0e7ebeb60c","fields":{"path":"/docs/2.6.x/feature-guides/batch/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Batch","description":"Batch Features in Data Flow","path":"feature-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f18c13dd-0967-5258-a9ed-2d0effb06a94","fields":{"path":"/docs/2.6.x/feature-guides/batch/deployment-properties/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a Batch deployment with deployment property overrides","path":"feature-guides/batch/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8ceffe7c-207a-5449-b416-2f4610608174","fields":{"path":"/docs/2.6.x/feature-guides/batch/scheduling/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Scheduling Batch Jobs","description":"Learn how to schedule Batch Jobs","path":"feature-guides/batch/scheduling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6d1d3059-6972-521c-aca8-ec6d05f1cde5","fields":{"path":"/docs/2.6.x/feature-guides/batch/partitioning/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Remote Partitioned Batch Job","description":"Learn more about partitioning support for Batch Jobs","path":"feature-guides/batch/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"56e21312-3401-500b-b7d3-e7c0243f5036","fields":{"path":"/docs/2.6.x/feature-guides/batch/monitoring/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Task Monitoring","description":"Monitoring task data pipelines with InfluxDB","path":"feature-guides/batch/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"63fd40ad-444b-5595-a758-ee3bc06f3470","fields":{"path":"/docs/2.6.x/feature-guides/batch/restarting/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Restarting Batch Jobs","description":"Learn how to restart Batch Jobs","path":"feature-guides/batch/restarting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e8d7213f-842d-55b9-968e-fa9468fbb1b7","fields":{"path":"/docs/2.6.x/feature-guides/batch/composed-task/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Composed Tasks","description":"Learn how to create and manage composed tasks","path":"feature-guides/batch/composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4d0f7f2b-fabf-550a-953c-cac43dbf9263","fields":{"path":"/docs/2.6.x/recipes/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Recipes","description":"Recipes that help solve some common use-cases","path":"recipes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3de792ac-05ae-5ced-8bed-41e91c752158","fields":{"path":"/docs/2.6.x/recipes/polyglot/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Polyglot","description":"Using multiple programming languages","path":"recipes/polyglot/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"36ff7cbd-d490-5e5c-8f3c-98219c24ab86","fields":{"path":"/docs/2.6.x/recipes/polyglot/processor/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Stream Processor","description":"Python Application as a Data Flow Stream Processor","path":"recipes/polyglot/processor/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d077e364-55a8-5626-a175-87aaba3ed076","fields":{"path":"/docs/2.6.x/recipes/polyglot/task/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Task","description":"Create and Deploy a Python Task","path":"recipes/polyglot/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6a27b0d6-4644-5a20-bc16-36b349b625ab","fields":{"path":"/docs/2.6.x/recipes/polyglot/app/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Application","description":"Create and Deploy a Python Application in a Stream","path":"recipes/polyglot/app/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"922bc0b9-e7d9-517f-b90e-3d708e2e368b","fields":{"path":"/docs/2.6.x/recipes/rabbitmq/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ","description":"RabbitMQ","path":"recipes/rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"824ba154-1675-5a56-9cb1-198145138085","fields":{"path":"/docs/2.6.x/recipes/rabbitmq/rabbit-source-sink/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ as Source and Sink","description":"RabbitMQ as Source and Sink + RabbitMQ binder","path":"recipes/rabbitmq/rabbit-source-sink/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8cea6d67-6070-541c-bdf4-eb8bb7de2d8b","fields":{"path":"/docs/2.6.x/recipes/kafka/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Apache Kafka","description":"Kafka","path":"recipes/kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"591d39f1-8de9-5e97-9ece-b6f04224f819","fields":{"path":"/docs/2.6.x/recipes/kafka/ext-kafka-cluster-cf/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"External Kafka Cluster","description":"Connect to an external Kafka Cluster from Cloud Foundry","path":"recipes/kafka/ext-kafka-cluster-cf/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4e811c1a-001d-55e5-8e16-06e7b512b33c","fields":{"path":"/docs/2.6.x/recipes/kinesis/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis","description":"Amazon Kinesis","path":"recipes/kinesis/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7ba60f0d-484c-5366-b8fe-79ff0e618f86","fields":{"path":"/docs/2.6.x/recipes/kinesis/simple-producer-consumer/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis Binder","description":"A sample of Spring Cloud Stream + Amazon Kinesis Binder in action","path":"recipes/kinesis/simple-producer-consumer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1ee618fe-64d0-579b-a77d-9257e8860731","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform Deployments","description":"Multiple Platform Deployments","path":"recipes/multi-platform-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2ee55850-fe0d-556c-8da1-b382c2dfbca7","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/multiple-platform-accounts/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Role of Multiple Platform Deployments","description":"A walk-through of multiple platform requirements and the configurations for Cloud Foundry and Kubernetes","path":"recipes/multi-platform-deployment/multiple-platform-accounts","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f9c6b7a7-dd7c-5ad0-96db-40a0da32ff09","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/multi-platform-task/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform support for Tasks","description":"Learn how to launch and schedule tasks across multiple platforms","path":"recipes/multi-platform-deployment/multi-platform-task","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"168e6851-9799-5f87-a048-6b85974a5b2b","fields":{"path":"/docs/2.6.x/recipes/scaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Scaling","description":"Prometheus and Data Flow to autoscale streaming data pipelines","path":"recipes/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c069825c-a660-51aa-a17e-bf2e5529bd46","fields":{"path":"/docs/2.6.x/recipes/scaling/manual-scaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Manual Scaling","description":"Scale applications using SCDF Shell","path":"recipes/scaling/manual-scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"655b0e01-0075-5e02-940f-73562c1df09c","fields":{"path":"/docs/2.6.x/recipes/scaling/autoscaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Autoscaling","description":"Autoscale streaming data pipeline with SCDF and Prometheus","path":"recipes/scaling/autoscaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a24382a8-69c7-516b-be4e-3005fd9e4e1d","fields":{"path":"/docs/2.6.x/recipes/batch/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Batch","description":"Using Spring Cloud Data Flow with Spring Batch","path":"recipes/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bef282f4-812e-5380-95ad-a6158cd664e5","fields":{"path":"/docs/2.6.x/recipes/batch/batch-only-mode/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Batch-only Mode","description":"Set up Spring Cloud Data Flow to use only batch and not streams","path":"recipes/batch/batch-only-mode/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3e3d1519-f305-513b-91d8-8c170101c7d3","fields":{"path":"/docs/2.6.x/recipes/batch/sftp-to-jdbc/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"SFTP to JDBC","description":"Ingest Files from SFTP to a JDBC data store using Data Flow and Spring Batch","path":"recipes/batch/sftp-to-jdbc/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5e406a25-183a-5faf-b106-2727add47aa9","fields":{"path":"/docs/2.6.x/recipes/functional-apps/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Using Functional Approach in Spring Cloud Stream applications","path":"recipes/functional-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"060d1319-66a9-5a8a-8ed0-9c9f4e0e0fc0","fields":{"path":"/docs/2.6.x/recipes/functional-apps/scst-function-bindings/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Configuring the Spring Cloud Stream Functional applications","path":"recipes/functional-apps/scst-function-bindings/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6c3c3ea4-da1d-5762-87e6-2cfe62f63319","fields":{"path":"/docs/2.6.x/recipes/cloud-providers/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Cloud Providers","description":"Using functionality provided by cloud providers","path":"recipes/cloud-providers/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"14e103a3-61f6-5fc8-b499-854b4bd3d76a","fields":{"path":"/docs/2.6.x/recipes/cloud-providers/gke-regional-clusters/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"GKE Regional Clusters","description":"Deploying Spring Cloud Data Flow to a GKE Regional Cluster","path":"recipes/cloud-providers/gke-regional-clusters/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"16a7f267-5b9f-5261-b7f8-6846ba920ed7","fields":{"path":"/docs/2.6.x/resources/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Resources","description":"Sample Applications, References Docs, Videos, Blogs...","path":"resources/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"15ce6d96-f8ce-55e1-8536-210a7451383b","fields":{"path":"/docs/2.6.x/resources/reference-docs/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Reference Documentation","description":"Collection of reference guides for Spring Cloud Data Flow","path":"resources/reference-docs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"09359c52-7d8f-58fe-a9cf-8685a9f53c1b","fields":{"path":"/docs/2.6.x/resources/samples/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Samples","description":"Collection of samples","path":"resources/samples/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8e9e653b-b304-5646-8a5f-d2b2734527a5","fields":{"path":"/docs/2.6.x/resources/faq/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Frequently Asked Questions","description":"","path":"resources/faq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2f552280-40b8-5962-bec1-461854e0c533","fields":{"path":"/docs/2.6.x/applications/","version":"2.6.x","category":"applications"},"frontmatter":{"title":"Applications","description":"Using stream and task applications","path":"applications/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"024c00a7-58c5-565c-96c6-21444383546b","fields":{"path":"/docs/2.6.x/applications/pre-packaged/","version":"2.6.x","category":"applications"},"frontmatter":{"title":"Pre-packaged Applications","description":"Pre-packaged stream and task applications","path":"applications/pre-packaged","meta_title":null,"meta_description":null,"keywords":["application","pre-packaged"]}}}]},"page":{"html":"<h1 id=\"python-stream-processor\" style=\"position:relative;\"><a href=\"#python-stream-processor\" aria-label=\"python stream processor permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Python Stream Processor</h1>\n<p>The example code in this section shows how to run a Python script as a processor within a Data Flow Stream.</p>\n<p>In this guide, we package the Python script as a Docker image and deploy it to Kubernetes. We use Apache Kafka as the messaging middleware.\nWe register the docker image in Data Flow as an application of the type <code class=\"language-text\">Processor</code>.</p>\n<p>The guide demonstrates a text-processing streaming data pipeline. It receives text-messages over HTTP, delegates the text processing to a Python script registered as a Data Flow processor, and prints the result to the logs. The Python script reverses the input text if the <code class=\"language-text\">reversestring</code> property is set to <code class=\"language-text\">true</code>. Otherwise, the resulting message remains unchanged.</p>\n<p>The following diagram shows the text-reversing processing pipeline:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 706px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABhUlEQVQoz21Sy07DMBDMV/EHfA9XznwIv8AFiTNcOICEOPXAoyVx0jhPJ3GC8+qw6zRVS7PSau3EuzMej1NVFZRSNnmdZdlhXRQFxnEEx263O8v5+3E4SZLA9314nocoihCGoU0hhN3PA5diCcBReY6UhnLl4VJKW+M4srUxLcq6taz535xLQDzUafsO2vzCUMUR0hzt0GOrNGpdWsYMokmOeUDTtTbHmaEbh/CjLbhyM4fpOhSKGJcajyuBh7cfvLsxyqpEmqYY9s15XcGjXp9641JNA71AYPP5gUAGkCpDozU2SYRKF3herXF5c4+L6ztc3T6haTRkmiCgc5rPUU8gPHibNYIsRk8yOCKNsI0lvEQeGI4HBg1ev0O8fEmsghQkyHTVvRyKAASxE8QyqYqJIQ/RrSEN+xMbnEq5Q98ZayVjDOmpiW2Duq6RkwxJoeyem5z/r3RuB2AYRuT59MqsIdvKdV0L0BJAo+vDeWfJqCfrfWXNZrOzhZgRW6ejB+Scr/UH0LsBfgG/EqAAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/71f4641047b98a32967a2397d6639825/507e6/polyglot-python-processor-architecture.webp 200w,\n/static/71f4641047b98a32967a2397d6639825/28a80/polyglot-python-processor-architecture.webp 400w,\n/static/71f4641047b98a32967a2397d6639825/52234/polyglot-python-processor-architecture.webp 706w\"\n          sizes=\"(max-width: 706px) 100vw, 706px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/71f4641047b98a32967a2397d6639825/36ca5/polyglot-python-processor-architecture.png 200w,\n/static/71f4641047b98a32967a2397d6639825/a3397/polyglot-python-processor-architecture.png 400w,\n/static/71f4641047b98a32967a2397d6639825/685e1/polyglot-python-processor-architecture.png 706w\"\n          sizes=\"(max-width: 706px) 100vw, 706px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/71f4641047b98a32967a2397d6639825/685e1/polyglot-python-processor-architecture.png\"\n          alt=\"SCDF Python Tasks\"\n          title=\"SCDF Python Tasks\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n    </span></p>\n<h2 id=\"development\" style=\"position:relative;\"><a href=\"#development\" aria-label=\"development permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Development</h2>\n<p>You can find the source code in the samples GitHub <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/tree/master/dataflow-website/recipes/polyglot/polyglot-python-processor\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">repository</a> and download it as a zipped archive from <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/raw/master/dataflow-website/recipes/polyglot/polyglot-python-processor.zip\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">polyglot-python-processor.zip</a>.</p>\n<p>The processor uses the <a href=\"https://github.com/dpkp/kafka-python\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">kafka-python</a> library to create consumer and producer connections.</p>\n<p>The main loop of execution resides in <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/polyglot/polyglot-python-processor/python_processor.py\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">python_processor.py</a>.\nFor each message received on the inbound Kafka topic, the script either sends the output to the Kafka topic as-is, or, if <code class=\"language-text\">--reversestring=true</code> is passed to the processor as part of the stream definition, reverses the string and then sends it to the output. The following listing shows <code class=\"language-text\">python_processor.py</code>:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#!/usr/bin/env python</span>\n\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> sys\n\n<span class=\"token keyword\">from</span> kafka <span class=\"token keyword\">import</span> KafkaConsumer<span class=\"token punctuation\">,</span> KafkaProducer\n<span class=\"token keyword\">from</span> util<span class=\"token punctuation\">.</span>http_status_server <span class=\"token keyword\">import</span> HttpHealthServer\n<span class=\"token keyword\">from</span> util<span class=\"token punctuation\">.</span>task_args <span class=\"token keyword\">import</span> get_kafka_binder_brokers<span class=\"token punctuation\">,</span> get_input_channel<span class=\"token punctuation\">,</span> get_output_channel<span class=\"token punctuation\">,</span> get_reverse_string\n\nconsumer <span class=\"token operator\">=</span> KafkaConsumer<span class=\"token punctuation\">(</span>get_input_channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> bootstrap_servers<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>get_kafka_binder_brokers<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nproducer <span class=\"token operator\">=</span> KafkaProducer<span class=\"token punctuation\">(</span>bootstrap_servers<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>get_kafka_binder_brokers<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nHttpHealthServer<span class=\"token punctuation\">.</span>run_thread<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> consumer<span class=\"token punctuation\">:</span>\n        output_message <span class=\"token operator\">=</span> message<span class=\"token punctuation\">.</span>value\n        reverse_string <span class=\"token operator\">=</span> get_reverse_string<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> reverse_string <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span> <span class=\"token keyword\">and</span> reverse_string<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"true\"</span><span class=\"token punctuation\">:</span>\n            output_message <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token builtin\">reversed</span><span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        producer<span class=\"token punctuation\">.</span>send<span class=\"token punctuation\">(</span>get_output_channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> output_message<span class=\"token punctuation\">)</span></code></pre></div>\n      </div>\n<p>Helper methods are defined in a utility file called <code class=\"language-text\">task_args.py</code>. They aid in extracting common environment and command line values.</p>\n<p>An <code class=\"language-text\">HTTPServer</code> implementation runs as a thread that responds to Spring Boot path health check endpoints (<code class=\"language-text\">/actuator/health</code> and <code class=\"language-text\">/actuator/info</code>) with a default implementation of always returning HTTP 200. A <code class=\"language-text\">Dockerfile</code> creates the image.</p>\n<p>For <code class=\"language-text\">python_processor.py</code> to act as a Data Flow <code class=\"language-text\">processor</code>, it needs to be bundled in a docker image and uploaded to <code class=\"language-text\">DockerHub</code>. The following <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/polyglot/polyglot-python-processor/Dockerfile\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Dockerfile</a> shows how to bundle a Python script into a Docker image:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"docker\"><pre class=\"language-docker\"><code class=\"language-docker\"><span class=\"token instruction\"><span class=\"token keyword\">FROM</span> springcloud/openjdk:latest</span>\n\n<span class=\"token instruction\"><span class=\"token keyword\">RUN</span> apt-get update &amp;&amp; apt-get install --no-install-recommends -y <span class=\"token operator\">\\</span>\n    python-pip <span class=\"token operator\">\\</span>\n &amp;&amp; rm -rf /var/lib/apt/lists/*</span>\n\n<span class=\"token instruction\"><span class=\"token keyword\">RUN</span> pip install kafka-python</span>\n\n<span class=\"token instruction\"><span class=\"token keyword\">COPY</span> python_processor.py /processor/</span>\n<span class=\"token instruction\"><span class=\"token keyword\">COPY</span> util/*.py /processor/util/</span>\n\n<span class=\"token instruction\"><span class=\"token keyword\">ENTRYPOINT</span> [<span class=\"token string\">\"python\"</span>, <span class=\"token string\">\"/processor/python_processor.py\"</span>, <span class=\"token string\">\"$@\"</span>, <span class=\"token string\">\"--\"</span>]</span></code></pre></div>\n      </div>\n<p>The Dockerfile installs the required dependencies, adds the <code class=\"language-text\">python_processor.py</code> script and utilities (under the <code class=\"language-text\">util</code> folder), and sets the command entry.</p>\n<h3 id=\"build\" style=\"position:relative;\"><a href=\"#build\" aria-label=\"build permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Build</h3>\n<p>We can now build the Docker image and push it to the DockerHub registry. To do so:</p>\n<ol>\n<li>\n<p>Check out the <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">sample project</a> and navigate to the <code class=\"language-text\">polyglot-python-processor</code> folder:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/spring-cloud/spring-cloud-dataflow-samples\n<span class=\"token builtin class-name\">cd</span> ./spring-cloud-dataflow-samples/dataflow-website/recipes/polyglot/polyglot-python-processor/</code></pre></div>\n      </div>\n</li>\n<li>\n<p>From within the <code class=\"language-text\">polyglot-python-processor/</code>, build and push the polyglot-python-processor Docker image to DockerHub:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">docker build -t springcloud/polyglot-python-processor:0.1 <span class=\"token builtin class-name\">.</span>\ndocker push springcloud/polyglot-python-processor:0.1</code></pre></div>\n      </div>\n<!--TIP-->\n<p>Replace <code class=\"language-text\">springcloud</code> with your docker hub prefix.</p>\n<!--END_TIP-->\n</li>\n</ol>\n<p>Once published in Docker Hub, you can register the image in Data Flow and deploy it.</p>\n<h2 id=\"deployment\" style=\"position:relative;\"><a href=\"#deployment\" aria-label=\"deployment permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deployment</h2>\n<p>To deploy the processor:</p>\n<ol>\n<li>Follow the <a href=\"/docs/2.6.x/installation/kubernetes/\">installation instructions</a> to set up Data Flow on Kubernetes.</li>\n<li>\n<p>Retrieve the Data Flow url from Minikube by running the following command:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">minikube <span class=\"token function\">service</span> --url scdf-server</code></pre></div>\n      </div>\n</li>\n<li>\n<p>Configure your Data Flow shell by running the following command:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow config server --uri <span class=\"token operator\">&lt;</span>Your Data Flow URL<span class=\"token operator\">></span></code></pre></div>\n      </div>\n</li>\n<li>\n<p>Import the SCDF app starters</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app <span class=\"token function\">import</span> --uri https://dataflow.spring.io/kafka-docker-latest</code></pre></div>\n      </div>\n</li>\n<li>\n<p>Register the <code class=\"language-text\">polyglot-python-processor</code> as <code class=\"language-text\">python-processor</code> of type <code class=\"language-text\">processor</code>.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --type processor --name python-processor --uri docker://springcloud/polyglot-python-processor:0.1</code></pre></div>\n      </div>\n<p>The <code class=\"language-text\">docker://springcloud/polyglot-python-processor:0.1</code> is resolved from the <a href=\"https://hub.docker.com/r/springcloud/polyglot-python-processor\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">DockerHub repository</a>.</p>\n</li>\n<li>\n<p>Create Data Flow <code class=\"language-text\">text-reversal</code> Stream by running the following command:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">stream create --name text-reversal --definition \"http --server.port=32123 | python-processor --reversestring=true  | log\"</code></pre></div>\n      </div>\n<p>The <code class=\"language-text\">http</code> source listens for incoming http messages on port <code class=\"language-text\">32123</code> and forwards them to the <code class=\"language-text\">python-processor</code>. The processor is configured to reverse the input messages (if <code class=\"language-text\">reversestring=true</code>) and sends them downstream to the <code class=\"language-text\">log</code> sink.</p>\n</li>\n<li>\n<p>Deploy the stream by using the <code class=\"language-text\">kubernetes.createNodePort</code> property to expose the HTTP port to the local host by running the following command:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">stream deploy text-reversal --properties \"deployer.http.kubernetes.createNodePort=32123\"</code></pre></div>\n      </div>\n</li>\n<li>\n<p>Retrieve the http-source url from minikube to publish the test data by running the following command:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">minikube <span class=\"token function\">service</span> --url text-reversal-http-v1\nhttp://192.168.99.104:32123</code></pre></div>\n      </div>\n</li>\n<li>\n<p>Post a sample message against the http-source application by running the following command:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">http post --target http://192.168.99.104:32123 --data \"hello world\"</code></pre></div>\n      </div>\n<p>If the post is successful you should see a confirmation message like this:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">> POST (text/plain) http://192.168.99.104:32123 hello world\n> 202 ACCEPTED</code></pre></div>\n      </div>\n</li>\n<li>\n<p>Inspect the logs for posted message by running the following command</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl logs -f &lt;log pod name></code></pre></div>\n      </div>\n<p>You should see output similar to the following:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">INFO 1 --- [container-0-C-1] log-sink                                 : dlrow olleh</code></pre></div>\n      </div>\n<p>You should see the posted message in reversed order (in this case, <code class=\"language-text\">dlrow olleh</code>).</p>\n</li>\n</ol>","headings":[{"value":"Python Stream Processor","depth":1},{"value":"Development","depth":2},{"value":"Build","depth":3},{"value":"Deployment","depth":2}],"fields":{"path":"/docs/2.6.x/recipes/polyglot/processor/","version":"2.6.x","category":"recipes","sourcePath":"pages/6-recipes/1-polyglot/1-polyglot-python-processor.md"},"frontmatter":{"title":"Python Stream Processor","summary":null,"path":"recipes/polyglot/processor/","toc":null,"prevNext":null}}},"pageContext":{"slug":"/docs/2.6.x/recipes/polyglot/processor/","version":"2.6.x","versionPath":""}},"staticQueryHashes":["2044043181"]}