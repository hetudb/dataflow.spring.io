{"componentChunkName":"component---src-templates-documentation-js","path":"/docs/2.6.x/recipes/cloud-providers/gke-regional-clusters/","result":{"data":{"pages":{"edges":[{"node":{"id":"e9021eeb-a6bb-59ff-ac01-48c86eabd4a0","fields":{"path":"/docs/2.6.x/installation/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Installation","description":"How to install Data Flow","path":"installation/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4d2ef486-b1d3-5021-b5ba-42ec362b1562","fields":{"path":"/docs/2.6.x/installation/local/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Local Machine","description":"Local Machine Installation Guide","path":"installation/local/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5677e8b5-0bd6-5e56-86b2-885107a13e1b","fields":{"path":"/docs/2.6.x/installation/local/docker/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Docker Compose","description":"Installation using Docker Compose","path":"installation/local/docker","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f8b9d584-3559-5744-beba-9e5d2ca30de6","fields":{"path":"/docs/2.6.x/installation/local/docker-customize/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Docker Compose Customization","description":"Customize the Docker Compose installation","path":"installation/local/docker-customize","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1e019f6e-b12c-5dfb-af9f-0ee64023c52c","fields":{"path":"/docs/2.6.x/installation/local/manual/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Manual","description":"Manual installation","path":"installation/local/manual","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"90cc84da-bf5e-51a4-8bf1-27e4f643ba6e","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry","description":"Data Flow Cloud Foundry Installation Guide","path":"installation/cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dcde0625-3190-504f-a1a6-f56e72fdc7ae","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/cf-cli/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry CLI","description":"Install using the Cloud Foundry CLI","path":"installation/cloudfoundry/cf-cli","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a5ffaf9e-68c1-57e6-82d6-6164f5f93c0b","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/cf-local/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Running locally","description":"Configure the local servers to deploy to Cloud Foundry","path":"installation/cloudfoundry/cf-local","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4477369a-b2fe-5745-b092-e3b67713d013","fields":{"path":"/docs/2.6.x/installation/kubernetes/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Kubernetes","description":"Data Flow Kubernetes Installation Guide","path":"installation/kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"119f4320-d2f6-5cbf-a9a9-8284623dd171","fields":{"path":"/docs/2.6.x/installation/kubernetes/creating-a-cluster/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Creating a Cluster","description":"Creating a Kubernetes Cluster","path":"installation/kubernetes/creating-a-cluster","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"db871ceb-3a12-5869-ae62-719e896b1db0","fields":{"path":"/docs/2.6.x/installation/kubernetes/helm/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Helm","description":"Installation using Helm","path":"installation/kubernetes/helm","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"caf737ab-3988-5332-8aff-f4623ff1bd1f","fields":{"path":"/docs/2.6.x/installation/kubernetes/kubectl/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"kubectl","description":"Installation using kubectl","path":"installation/kubernetes/kubectl","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c5fa77bd-d62a-5098-bcca-70542ab0c26e","fields":{"path":"/docs/2.6.x/installation/kubernetes/compatibility/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Kubernetes Compatibility","description":"Compatibility with Kubernetes Versions","path":"installation/kubernetes/compatibility","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"929fcfcf-1990-5367-af35-a9e781a72e6b","fields":{"path":"/docs/2.6.x/concepts/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Concepts","description":"Core Concepts in Spring Cloud Data Flow","path":"concepts/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"99224add-aea3-5da9-b131-c7f449c8d48e","fields":{"path":"/docs/2.6.x/concepts/architecture/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Architecture","description":"Introduction to Data Flow's Architecture.","path":"concepts/architecture/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d61c129f-87f4-5650-96ef-5c4d102df471","fields":{"path":"/docs/2.6.x/concepts/streams/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Stream Processing","description":"Stream Processing Framework and Concepts","path":"concepts/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"89ecf7e1-75c6-5d48-a6cc-ce96d27828d2","fields":{"path":"/docs/2.6.x/concepts/batch-jobs/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Batch Processing","description":"Batch Processing Framework and Concepts","path":"concepts/batch-jobs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3c0c3e30-fbef-5bc9-a751-9a98ce2623c3","fields":{"path":"/docs/2.6.x/concepts/monitoring/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Monitoring","description":"Runtime monitoring of Stream data pipelines","path":"concepts/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f42c5920-63af-5427-8ec4-da4cec31d9d3","fields":{"path":"/docs/2.6.x/concepts/tooling/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Tooling","description":"Dashboard and Shell","path":"concepts/tooling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"de52e1a6-ded9-53a7-9880-1912d060def0","fields":{"path":"/docs/2.6.x/stream-developer-guides/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Developer guides ","description":"Learn how to create Streaming data pipelines using prebuilt microservices or create your own.","path":"stream-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"25aa7b2c-d0a7-594b-b2e8-5688e30d9b2e","fields":{"path":"/docs/2.6.x/stream-developer-guides/getting-started/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Stream Processing","path":"stream-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"662bc53d-bfe5-573e-aff6-90c1ac01c219","fields":{"path":"/docs/2.6.x/stream-developer-guides/getting-started/stream/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing","description":"Create and deploy a streaming data pipeline using prebuilt applications on your Local Machine","path":"stream-developer-guides/getting-started/stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5e286ba1-bf9e-5bef-b317-439cee0dad6a","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Development","description":"Stream Processing Developer Guide","path":"stream-developer-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"330b159e-9210-5f4d-9df0-7975a8b80df3","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/standalone-stream-rabbitmq/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on RabbitMQ","description":"Create your own microservices for Stream processing using RabbitMQ and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f4886ff1-ae23-51fe-a76c-c5d8a688dd5b","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/standalone-stream-kafka/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on Apache Kafka","description":"Create your own microservices for Stream processing using Apache Kafka and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cabf8341-e0bf-5bb2-afa0-4d99e24ce1e8","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/data-flow-stream/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing using Spring Cloud Data Flow","description":"Create and Deploy a Stream Processing Pipeline using Spring Cloud Data Flow","path":"stream-developer-guides/streams/data-flow-stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e5aceaf2-0ade-5d25-8c07-46dc78c41596","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/stream-other-binders/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Spring Application Development on other Messaging Middleware","description":"Create your own microservices for Stream processing using other messaging middleware such as Google Pub/Sub, Amazon Kinesis, and Solace JMS","path":"stream-developer-guides/streams/stream-other-binders/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5cf102aa-7ea7-56e2-9efd-6d9ecca536fe","fields":{"path":"/docs/2.6.x/stream-developer-guides/programming-models/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Programming Models","description":"Programming models","path":"stream-developer-guides/programming-models/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cb665729-22e1-5fc3-9022-c0dd45f194cb","fields":{"path":"/docs/2.6.x/stream-developer-guides/continuous-delivery/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery","description":"CD using Skipper","path":"stream-developer-guides/continuous-delivery/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a11a49c7-beb0-591c-9eb3-edb64c83c6b1","fields":{"path":"/docs/2.6.x/stream-developer-guides/continuous-delivery/cd-basics/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery of streaming applications","description":"Continuous Delivery of Streaming applications","path":"stream-developer-guides/continuous-delivery/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"26860f37-faed-5b74-b92b-26fb867505ca","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Streams","path":"stream-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"48779233-7811-551b-bb00-1bc1a9729927","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/debugging-stream-apps/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream Applications","description":"Debugging Stream Applications outside of Data Flow","path":"stream-developer-guides/troubleshooting/debugging-stream-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5f57c55d-32e4-59fc-91c1-8a52bcbb48ee","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/debugging-scdf-streams/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream applications deployed by Data Flow","description":"Debugging Data Flow Stream deployments","path":"stream-developer-guides/troubleshooting/debugging-scdf-streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"37a22652-17b0-5d93-8ca8-bca78334ea76","fields":{"path":"/docs/2.6.x/batch-developer-guides/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"batch-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"801a3829-0592-5238-a423-a7401fda6d75","fields":{"path":"/docs/2.6.x/batch-developer-guides/getting-started/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Batch","path":"batch-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6d3eaaf0-06a0-5b15-9e34-22e5a3bc3c4a","fields":{"path":"/docs/2.6.x/batch-developer-guides/getting-started/task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Task Processing","description":"Create and deploy a simple Task pipeline using a prebuilt Task application on your local machine","path":"batch-developer-guides/getting-started/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1c467d57-4330-57b5-a082-ce1d66c7b97d","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Development","description":"Batch Developer Guide","path":"batch-developer-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0bc43ff5-11dc-538a-8a22-dccbbb01b166","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/spring-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"batch-developer-guides/batch/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"07cab399-4800-5892-b85c-2a7458c18d5f","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/spring-batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"batch-developer-guides/batch/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c82bad2b-2e5d-5771-bce6-27066ff3ef82","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cec2f163-1cd9-5052-981e-89a5e085cb84","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-spring-batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"batch-developer-guides/batch/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d100d3c9-ac7e-578d-9707-d7af65827827","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-composed-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"batch-developer-guides/batch/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c1352ada-7f61-57d2-976d-3f49bd2b3ab6","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task-kubernetes/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d903c65f-f587-5023-ad49-d9a2da203603","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"db6a5270-4b1c-550c-ab60-345a6cb8e8bd","fields":{"path":"/docs/2.6.x/batch-developer-guides/continuous-deployment/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"batch-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"27640e7d-20c3-5857-a9f7-e5e74e56a98d","fields":{"path":"/docs/2.6.x/batch-developer-guides/continuous-deployment/cd-basics/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"batch-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1044acb3-91f1-5a91-9187-d6e5d33133e4","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"batch-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"460d5979-e8e4-5a5c-bbf6-db7ee54a471f","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/debugging-task-apps/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"batch-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b0663c20-e821-5837-a799-a53686f5c67b","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"batch-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0db0658d-b083-5c3d-b43c-f33701394dbc","fields":{"path":"/docs/2.6.x/feature-guides/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Feature guides","description":"High level overview of Data Flow Features","path":"feature-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3d4a79f7-bc01-57f4-8fee-1ec7f8038396","fields":{"path":"/docs/2.6.x/feature-guides/general/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"General","description":"General Features in Data Flow","path":"feature-guides/general/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"72147749-774f-5535-83d3-d0237da98171","fields":{"path":"/docs/2.6.x/feature-guides/general/application-metadata/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Application Metadata","description":"Create and use application properties metadata","path":"feature-guides/general/application-metadata/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bdb03de9-49e7-54cc-9c78-012a7d62f551","fields":{"path":"/docs/2.6.x/feature-guides/streams/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Streams","description":"Stream Features in Data Flow","path":"feature-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9e46d55d-12bb-5dfb-8ae8-1eb0cd5af0d4","fields":{"path":"/docs/2.6.x/feature-guides/streams/deployment-properties/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a stream deployment with deployment property overrides","path":"feature-guides/streams/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9cfa8e02-c993-57f5-9b80-79ac6b30bacd","fields":{"path":"/docs/2.6.x/feature-guides/streams/function-composition/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Composing Functions","description":"Daisy-chain Java functions in an existing Spring Cloud Stream application","path":"feature-guides/streams/function-composition/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4bf293a4-98e7-5e83-ba2f-d691ea4ea8e7","fields":{"path":"/docs/2.6.x/feature-guides/streams/named-destinations/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Named Destinations","description":"Use the Named Destinations to interact with the Topics/Queues directly","path":"feature-guides/streams/named-destinations/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f2492bb6-cf38-56b7-a5b0-7b480d93831b","fields":{"path":"/docs/2.6.x/feature-guides/streams/monitoring/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Stream Monitoring","description":"Monitoring streaming data pipelines with Prometheus and InfluxDB","path":"feature-guides/streams/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ea8d17bc-832b-5010-8493-0057ce1e3c9e","fields":{"path":"/docs/2.6.x/feature-guides/streams/stream-application-dsl/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Stream Application DSL","description":"Learn how to use the Stream Application DSL","path":"feature-guides/streams/stream-application-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7e0c92af-5ac0-525e-886d-24ef860121cc","fields":{"path":"/docs/2.6.x/feature-guides/streams/labels/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Labeling Applications","description":"Label the stream applications to uniquely interact with them","path":"feature-guides/streams/labels/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c434626b-145c-511f-8591-9c3ddcb282a3","fields":{"path":"/docs/2.6.x/feature-guides/streams/application-count/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Application Count","description":"Initiate stream deployment with multiple application instances","path":"feature-guides/streams/application-count/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1f734409-9f01-5699-8906-d4b81b4fc7df","fields":{"path":"/docs/2.6.x/feature-guides/streams/fanin-fanout/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Fan-in and Fan-out","description":"Publish and subscribe to multiple destinations using the fan-in and fan-out capabilities","path":"feature-guides/streams/fanin-fanout/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8a34cc56-301c-5298-8be5-5aa9a712d156","fields":{"path":"/docs/2.6.x/feature-guides/streams/partitioning/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Data Partitioning","description":"Learn more about data partitioning support to build stateful streaming data pipelines","path":"feature-guides/streams/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3e10f1c9-14b7-50e3-b295-7fac6fd8de79","fields":{"path":"/docs/2.6.x/feature-guides/streams/scaling/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Scaling","description":"Scaling streaming data pipeline with Spring Cloud Data Flow","path":"feature-guides/streams/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5c27a2e4-32bb-5f8c-8a71-120c286b8c70","fields":{"path":"/docs/2.6.x/feature-guides/streams/java-dsl/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Java DSL","description":"Programmatically create streams using the Java DSL","path":"feature-guides/streams/java-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"531c7f03-b972-5bb7-a252-a7a584fc8ef5","fields":{"path":"/docs/2.6.x/feature-guides/streams/taps/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Tapping a Stream","description":"Create a stream from another stream without interrupting the data processing","path":"feature-guides/streams/taps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"76e86fcf-b096-55af-b668-54a9ee785297","fields":{"path":"/docs/2.6.x/feature-guides/batch/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Batch","description":"Batch Features in Data Flow","path":"feature-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dd3f1828-4361-5163-ac19-dfc79b6feeff","fields":{"path":"/docs/2.6.x/feature-guides/batch/deployment-properties/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a Batch deployment with deployment property overrides","path":"feature-guides/batch/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"db544e92-6c62-5c3e-b630-b1a8a0a65300","fields":{"path":"/docs/2.6.x/feature-guides/batch/scheduling/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Scheduling Batch Jobs","description":"Learn how to schedule Batch Jobs","path":"feature-guides/batch/scheduling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"939b3288-80cc-5c8c-b608-6d3e6a3566fa","fields":{"path":"/docs/2.6.x/feature-guides/batch/partitioning/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Remote Partitioned Batch Job","description":"Learn more about partitioning support for Batch Jobs","path":"feature-guides/batch/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3b6f6285-0025-58ac-a678-507000366895","fields":{"path":"/docs/2.6.x/feature-guides/batch/monitoring/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Task Monitoring","description":"Monitoring task data pipelines with InfluxDB","path":"feature-guides/batch/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"88baffea-f888-5470-990b-3ae96079720a","fields":{"path":"/docs/2.6.x/feature-guides/batch/restarting/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Restarting Batch Jobs","description":"Learn how to restart Batch Jobs","path":"feature-guides/batch/restarting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5ccd8a85-54c4-5734-960d-61cd737d976c","fields":{"path":"/docs/2.6.x/feature-guides/batch/composed-task/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Composed Tasks","description":"Learn how to create and manage composed tasks","path":"feature-guides/batch/composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cf488e7a-a79a-58a1-84c7-f239b00f0a36","fields":{"path":"/docs/2.6.x/recipes/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Recipes","description":"Recipes that help solve some common use-cases","path":"recipes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"832b2669-96c0-5acf-955f-a8092425bd75","fields":{"path":"/docs/2.6.x/recipes/polyglot/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Polyglot","description":"Using multiple programming languages","path":"recipes/polyglot/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4c7ade10-63e9-5c59-b33c-dc10405cb8bc","fields":{"path":"/docs/2.6.x/recipes/polyglot/processor/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Stream Processor","description":"Python Application as a Data Flow Stream Processor","path":"recipes/polyglot/processor/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8b17d791-bab2-56cc-adfc-cf2ce3ebc3c8","fields":{"path":"/docs/2.6.x/recipes/polyglot/task/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Task","description":"Create and Deploy a Python Task","path":"recipes/polyglot/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e6de6439-cf64-56a5-aad3-35e69c5f0ede","fields":{"path":"/docs/2.6.x/recipes/polyglot/app/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Application","description":"Create and Deploy a Python Application in a Stream","path":"recipes/polyglot/app/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f0245349-2811-5319-a15e-049eb69ead0a","fields":{"path":"/docs/2.6.x/recipes/rabbitmq/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ","description":"RabbitMQ","path":"recipes/rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"040ded45-231f-5c98-a3ee-b79f3e463adf","fields":{"path":"/docs/2.6.x/recipes/rabbitmq/rabbit-source-sink/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ as Source and Sink","description":"RabbitMQ as Source and Sink + RabbitMQ binder","path":"recipes/rabbitmq/rabbit-source-sink/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"58377b55-b637-5353-aad8-ea5634b5ba70","fields":{"path":"/docs/2.6.x/recipes/kafka/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Apache Kafka","description":"Kafka","path":"recipes/kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"96d36967-fb2f-5188-99c1-1ab07a5669dd","fields":{"path":"/docs/2.6.x/recipes/kafka/ext-kafka-cluster-cf/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"External Kafka Cluster","description":"Connect to an external Kafka Cluster from Cloud Foundry","path":"recipes/kafka/ext-kafka-cluster-cf/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f8d244b8-35e6-5dd1-8c0e-a0f2683cc8f1","fields":{"path":"/docs/2.6.x/recipes/kinesis/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis","description":"Amazon Kinesis","path":"recipes/kinesis/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4dd53e72-e7ae-5ff7-a3c0-f45db20dffdd","fields":{"path":"/docs/2.6.x/recipes/kinesis/simple-producer-consumer/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis Binder","description":"A sample of Spring Cloud Stream + Amazon Kinesis Binder in action","path":"recipes/kinesis/simple-producer-consumer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"44ad6f69-e0bf-5a2c-b1e0-6e44c4f32960","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform Deployments","description":"Multiple Platform Deployments","path":"recipes/multi-platform-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e151daf9-0907-5888-a264-fd1225e70752","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/multiple-platform-accounts/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Role of Multiple Platform Deployments","description":"A walk-through of multiple platform requirements and the configurations for Cloud Foundry and Kubernetes","path":"recipes/multi-platform-deployment/multiple-platform-accounts","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7d0b675d-d227-5eae-8e6a-bcdfe22e24a1","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/multi-platform-task/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform support for Tasks","description":"Learn how to launch and schedule tasks across multiple platforms","path":"recipes/multi-platform-deployment/multi-platform-task","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e2bb5e49-03c6-572d-909f-ba0175bac7a1","fields":{"path":"/docs/2.6.x/recipes/scaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Scaling","description":"Prometheus and Data Flow to autoscale streaming data pipelines","path":"recipes/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ebe9d02c-933f-575a-b6a2-70902f36adbb","fields":{"path":"/docs/2.6.x/recipes/scaling/manual-scaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Manual Scaling","description":"Scale applications using SCDF Shell","path":"recipes/scaling/manual-scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1a8da8d0-dc19-588e-842b-6753e5f680a3","fields":{"path":"/docs/2.6.x/recipes/scaling/autoscaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Autoscaling","description":"Autoscale streaming data pipeline with SCDF and Prometheus","path":"recipes/scaling/autoscaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"41246959-ff77-5531-8710-baa307c71cf3","fields":{"path":"/docs/2.6.x/recipes/batch/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Batch","description":"Using Spring Cloud Data Flow with Spring Batch","path":"recipes/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"376ac9e8-46be-5ea1-8ab7-a651e3d9acc4","fields":{"path":"/docs/2.6.x/recipes/batch/batch-only-mode/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Batch-only Mode","description":"Set up Spring Cloud Data Flow to use only batch and not streams","path":"recipes/batch/batch-only-mode/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a26aab98-8b26-5318-8b76-131c7c6c9fd6","fields":{"path":"/docs/2.6.x/recipes/batch/sftp-to-jdbc/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"SFTP to JDBC","description":"Ingest Files from SFTP to a JDBC data store using Data Flow and Spring Batch","path":"recipes/batch/sftp-to-jdbc/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"51203ff4-d111-57ea-bf53-15b3f24e38d0","fields":{"path":"/docs/2.6.x/recipes/functional-apps/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Using Functional Approach in Spring Cloud Stream applications","path":"recipes/functional-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b86a08d0-bac2-5780-b8e1-eb48f0a4f9da","fields":{"path":"/docs/2.6.x/recipes/functional-apps/scst-function-bindings/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Configuring the Spring Cloud Stream Functional applications","path":"recipes/functional-apps/scst-function-bindings/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0d4fc819-caeb-567e-98c1-703594e0a8f5","fields":{"path":"/docs/2.6.x/recipes/cloud-providers/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Cloud Providers","description":"Using functionality provided by cloud providers","path":"recipes/cloud-providers/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6c4c5dda-3035-5a42-86a6-4f69957a5031","fields":{"path":"/docs/2.6.x/recipes/cloud-providers/gke-regional-clusters/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"GKE Regional Clusters","description":"Deploying Spring Cloud Data Flow to a GKE Regional Cluster","path":"recipes/cloud-providers/gke-regional-clusters/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"861688d5-2c38-508d-978e-640323c6d6f8","fields":{"path":"/docs/2.6.x/resources/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Resources","description":"Sample Applications, References Docs, Videos, Blogs...","path":"resources/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ae36aa66-bfc0-5e25-a8d5-fadf9923ab74","fields":{"path":"/docs/2.6.x/resources/reference-docs/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Reference Documentation","description":"Collection of reference guides for Spring Cloud Data Flow","path":"resources/reference-docs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4c5f2c8b-1d31-5ae4-a8b6-72ce57ccbfb0","fields":{"path":"/docs/2.6.x/resources/samples/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Samples","description":"Collection of samples","path":"resources/samples/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6338daa2-c819-5f7d-80c8-544b0f84079d","fields":{"path":"/docs/2.6.x/resources/faq/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Frequently Asked Questions","description":"","path":"resources/faq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9ceb4a4c-e3d7-51ce-ad2b-92062de9b87b","fields":{"path":"/docs/2.6.x/applications/","version":"2.6.x","category":"applications"},"frontmatter":{"title":"Applications","description":"Using stream and task applications","path":"applications/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ad96a136-c832-5548-ad1d-fa05028763c0","fields":{"path":"/docs/2.6.x/applications/pre-packaged/","version":"2.6.x","category":"applications"},"frontmatter":{"title":"Pre-packaged Applications","description":"Pre-packaged stream and task applications","path":"applications/pre-packaged","meta_title":null,"meta_description":null,"keywords":["application","pre-packaged"]}}}]},"page":{"html":"<h1 id=\"deploying-spring-cloud-data-flow-to-a-gke-regional-cluster\" style=\"position:relative;\"><a href=\"#deploying-spring-cloud-data-flow-to-a-gke-regional-cluster\" aria-label=\"deploying spring cloud data flow to a gke regional cluster permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploying Spring Cloud Data Flow to a GKE Regional Cluster</h1>\n<p>When deploying applications to an environment, it is often ideal to have a strategy set up to handle infrastructure outages. Outages could range from hardware failures to complete data centers going offline, resulting in applications becoming unavailable. Rather than having those workloads potentially halt operations until an outage is resolved, another option is to have those workloads migrated to another part of your infrastructure to continue operations. It may also be useful to specify where particular applications must reside or be co-located with other applications.</p>\n<p>With <a href=\"https://kubernetes.io/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kubernetes</a>, failure of nodes and the workloads running on them are automatically handled by rescheduling those workloads onto other available nodes. In a simple use case, a Kubernetes cluster consisting of a single control plane and multiple worker nodes residing in the same location is often implemented by default. This type of configuration, in the event of a failure, does not provide any high availability.</p>\n<p>As this recipe is focused on GKE as the cloud provider, location will mean one or more \"zones\" inside a particular \"region\". A \"region\" refers to a specific geographical location, for example, <code class=\"language-text\">us-east1</code>. Within a \"region\", there are multiple \"zones\" such as <code class=\"language-text\">us-east1-b</code>, <code class=\"language-text\">us-east1-c</code>, and so on that are isolated from other zones. It's important to choose regions and zones based on your specific needs, such as CPU/GPU types, disk types, compute power, etc. More in-depth information that should be reviewed can be found in the <a href=\"https://cloud.google.com/compute/docs/regions-zones/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Regions and Zones</a> documentation.</p>\n<p>Beyond a single-zone cluster, GKE supports two other types of clusters:</p>\n<ul>\n<li>Multi-zonal clusters - Single replica of the control plane running in a single zone with worker nodes running in multiple zones of a given region</li>\n<li>Regional clusters - Multiple replicas of the control plane running in multiple zones within a given region with nodes running in the same zone as each control plane</li>\n</ul>\n<p>This recipe will focus on <code class=\"language-text\">Regional clusters</code> as it provides a greater level of high availability than <code class=\"language-text\">Single Zone</code> or <code class=\"language-text\">Multi-zonal</code> clusters.</p>\n<h2 id=\"prerequisites\" style=\"position:relative;\"><a href=\"#prerequisites\" aria-label=\"prerequisites permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Prerequisites</h2>\n<p>A <a href=\"https://cloud.google.com/gcp/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Google Cloud</a> (GCP) account with permissions to create new <a href=\"https://cloud.google.com/kubernetes-engine/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Google Kubernetes Engine</a> (GKE) clusters is required. A web interface is provided to interact with GCP/GKE as well as a CLI, which can be obtained via the <a href=\"https://cloud.google.com/sdk\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Google Cloud SDK</a> and installed. Standard tooling such as <a href=\"https://github.com/kubernetes/kubectl/releases\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kubectl</a> needs to be installed for interaction with Kubernetes clusters.</p>\n<h2 id=\"creating-the-cluster\" style=\"position:relative;\"><a href=\"#creating-the-cluster\" aria-label=\"creating the cluster permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Creating the Cluster</h2>\n<p>In this recipe, we will use the GKE web console to create the cluster. We will utilize the defaults in most cases, except for the location type and instance sizes. When creating a new cluster, the first bits of information to select is the \"Cluster Basics\". The screenshot below shows the options chosen for this demo:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 800px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 92%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAIAAADUsmlHAAAACXBIWXMAAAsSAAALEgHS3X78AAABh0lEQVQ4y5VT2W6DMBD0//9cn1IpqtqkkUrAJtjm8G3oYDc0SaFqR2hlzM7ueFiTXsULVyUVsrM2TNZPnRq5VLQqynMhOJ+2QfpBF0XVcGGdD3EKYfRhVNp8FAWeqqouV/CEpmm6hHEciXMOO13bxhhTOWxGbCKprmvG2DmhSIWKhExGPjHaSCmdsyAtevABqafTabfbgUkpxStiLlSWJaK1lqAPmqCe934hO+eRqpRCRgghJiwLtIE05BO8QDaa3zqBDyjPWD2uAQnGGPDReZxtuHdVG/v6esCZp1+RO/O2bW93rY3nsvbebdGyBJJXCPeyHWTPLmzIhttQTlYLdyqWVEqB0wjYKYTIdi5/JC/IqiREdunr+tL3PTxHHIYBC0R4/n3mLfLTM9/vX4zRtw0fDdsid4PXxlzHbvorGVBan96PGCPoNAl6hrFXYOfL7Z+A24xSDDZ+tUzgsm8EyBgsl7FJNuk/M0aR/m/Z3oe3wxGXcpmHB+Q5XzUs34159Of7uYZM/gQkehr6olbwMAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/7d0edb352649238e7167584d36f039ce/507e6/cluster-basics.webp 200w,\n/static/7d0edb352649238e7167584d36f039ce/28a80/cluster-basics.webp 400w,\n/static/7d0edb352649238e7167584d36f039ce/8d2ea/cluster-basics.webp 800w,\n/static/7d0edb352649238e7167584d36f039ce/68fc1/cluster-basics.webp 1200w,\n/static/7d0edb352649238e7167584d36f039ce/43d96/cluster-basics.webp 1600w,\n/static/7d0edb352649238e7167584d36f039ce/2bfc1/cluster-basics.webp 1758w\"\n          sizes=\"(max-width: 800px) 100vw, 800px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/7d0edb352649238e7167584d36f039ce/36ca5/cluster-basics.png 200w,\n/static/7d0edb352649238e7167584d36f039ce/a3397/cluster-basics.png 400w,\n/static/7d0edb352649238e7167584d36f039ce/a331c/cluster-basics.png 800w,\n/static/7d0edb352649238e7167584d36f039ce/8537d/cluster-basics.png 1200w,\n/static/7d0edb352649238e7167584d36f039ce/1a152/cluster-basics.png 1600w,\n/static/7d0edb352649238e7167584d36f039ce/7ab55/cluster-basics.png 1758w\"\n          sizes=\"(max-width: 800px) 100vw, 800px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/7d0edb352649238e7167584d36f039ce/a331c/cluster-basics.png\"\n          alt=\"Regional Cluster Basics\"\n          title=\"Regional Cluster Basics\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n    </span></p>\n<p>The important parts of this section are:</p>\n<ul>\n<li><code class=\"language-text\">Regional</code> is selected as the <code class=\"language-text\">Location Type</code></li>\n<li><code class=\"language-text\">Region</code> is selected, in this case, <code class=\"language-text\">us-east1</code>. This value should be determined by your specific requirements as described above.</li>\n<li><code class=\"language-text\">Specify default node locations</code> has 3 zones selected. 3 zones will be selected automatically, but in the event, there are more than 3, this section allows explicit selection of zones.</li>\n</ul>\n<p>Other values on this section such as <code class=\"language-text\">Name</code>, and <code class=\"language-text\">Master version</code> settings can be customized as appropriate.</p>\n<p>Next the machine type is selected in the <code class=\"language-text\">Nodes</code> subsection of <code class=\"language-text\">Node Pools -> default-pool</code> as shown in the screenshot below:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 800px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 93%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAIAAAAf7rriAAAACXBIWXMAAAsSAAALEgHS3X78AAAB5klEQVQ4y3VT25ajIBDk/79rn/dlH+chk028EOUiIKhcnBLOeNjZWCchBOnuquqWbH5XSr8yeoBSKaUPiU1BKK+Md84JIbTWRusQQqpA9pSstZxzrPuBhG+Mseta58rJJQhihuGFFQHnKfZt2yKj+gYqg9E0TTIDG+892XwYmaD0tW4eRWPacRJiQuQwDOC8LMs8z9jg9pZRNjgnxiapwv3xknqb3Y6/k4lSe9Bpu67re3gxjuM8HxJSyp9MDXQIjmADpdQYkx8fmpH7/nl/PP4ihVIT6rzXHLxf1xVpvg3LmlO8N9PHTTx7Oxk/imXkTulVqoVJx5DtkLiToxNS/siN+kIqbZyZHQhrY81srcPeYb/5mPntBPfg3vP5RP2TNiRxzuALFEECFmyyU750GBdQj+AHM8C5iDHVlRnjaEHpExpjM2A7spztJLkIh5//0t6FYH3foMEwEsFQV09BVfkIZj+cVCYM3JdeILgeniLw0FxIFqlnWeDPh/n1W0LLsh6yTzkgcs4iedtAXJqUldIo7Y0NdeqaPLkaekr7z9uNjSNcihWgAiu4QMtlZQa7jxdD//+otArOvw/GM7xGcwY6BJ22ApxHPGy7DEbzmqbB/CD+TFRQ2gb+l8GlwjkSNedCG5q/ANnfU1Zp30DbAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/531c3fb9bfb44ba6ffdda099d694dc80/507e6/cluster-nodes.webp 200w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/28a80/cluster-nodes.webp 400w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/8d2ea/cluster-nodes.webp 800w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/68fc1/cluster-nodes.webp 1200w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/43d96/cluster-nodes.webp 1600w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/9defe/cluster-nodes.webp 1742w\"\n          sizes=\"(max-width: 800px) 100vw, 800px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/531c3fb9bfb44ba6ffdda099d694dc80/36ca5/cluster-nodes.png 200w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/a3397/cluster-nodes.png 400w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/a331c/cluster-nodes.png 800w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/8537d/cluster-nodes.png 1200w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/1a152/cluster-nodes.png 1600w,\n/static/531c3fb9bfb44ba6ffdda099d694dc80/d90ad/cluster-nodes.png 1742w\"\n          sizes=\"(max-width: 800px) 100vw, 800px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/531c3fb9bfb44ba6ffdda099d694dc80/a331c/cluster-nodes.png\"\n          alt=\"Regional Cluster Nodes\"\n          title=\"Regional Cluster Nodes\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n    </span></p>\n<p>The main change in this section is selecting a machine type of <code class=\"language-text\">n1-standard-4 (4 vCPU, 15GB memory)</code>. This gives us a bit more room to work with than the default. Settings can be customized as appropriate.</p>\n<div class=\"admonition tip\"><p>The number of nodes and machine type will vary based on your specific requirements for base needs in addition to failover tolerance. For example, the selected configuration may be sized based on the expected number of applications that may be spread across those nodes. Still, in the event of a node or even one or more region failures, clusters should be sized to support this extra load. Failing to do so will result in workloads un-schedulable until capacity is available. Various strategies can be implemented, for example, upfront sizing, using a <a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Cluster Autoscaler</a> and so on.</p></div>\n<p>With the customizations made, the cluster can be created by clicking the \"Create\" button as shown in the below screenshot:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 800px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 18.999999999999996%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAAsSAAALEgHS3X78AAAAeklEQVQI122MQQ7DIAwEeXk+kTf0UTn2hJAIYDBGQA2lkJ6SkTWyVvYKrbVSylprjFl2zgHAsPc+pdR7b631J8T4lFISUf5TJnXCzLVmInx+Xq3tBvMyIxWMeayfK/qpzxHr9N66Mgh124/99Y7oztMgooPoQzZQAtUv6KDoPk7Zu2MAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/8df8d4b97239aaef66ba2aca9a985917/507e6/cluster-create.webp 200w,\n/static/8df8d4b97239aaef66ba2aca9a985917/28a80/cluster-create.webp 400w,\n/static/8df8d4b97239aaef66ba2aca9a985917/8d2ea/cluster-create.webp 800w,\n/static/8df8d4b97239aaef66ba2aca9a985917/68fc1/cluster-create.webp 1200w,\n/static/8df8d4b97239aaef66ba2aca9a985917/43d96/cluster-create.webp 1600w,\n/static/8df8d4b97239aaef66ba2aca9a985917/23f72/cluster-create.webp 1661w\"\n          sizes=\"(max-width: 800px) 100vw, 800px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/8df8d4b97239aaef66ba2aca9a985917/36ca5/cluster-create.png 200w,\n/static/8df8d4b97239aaef66ba2aca9a985917/a3397/cluster-create.png 400w,\n/static/8df8d4b97239aaef66ba2aca9a985917/a331c/cluster-create.png 800w,\n/static/8df8d4b97239aaef66ba2aca9a985917/8537d/cluster-create.png 1200w,\n/static/8df8d4b97239aaef66ba2aca9a985917/1a152/cluster-create.png 1600w,\n/static/8df8d4b97239aaef66ba2aca9a985917/b3115/cluster-create.png 1661w\"\n          sizes=\"(max-width: 800px) 100vw, 800px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/8df8d4b97239aaef66ba2aca9a985917/a331c/cluster-create.png\"\n          alt=\"Create Regional Cluster\"\n          title=\"Create Regional Cluster\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n    </span></p>\n<div class=\"admonition tip\"><p>It's worth pointing out that while using the GKE UI can be convenient to customize your cluster configuration, the same can be done from the Google Cloud CLI. A handy way to generate this command is by clicking on the <code class=\"language-text\">command line</code> link which will generate the appropriate gcloud CLI command that can be used to create the same cluster configuration.</p></div>\n<p>When the cluster finishes creating, there will be 3 worker nodes deployed to each of the 3 regions, for a total of 9 worker nodes. Please note, GKE does not provide the ability to access control plane nodes.</p>\n<p>Lastly, the credentials need to be fetched via the <code class=\"language-text\">gcloud</code> CLI so <code class=\"language-text\">kubectl</code> can interact with the cluster:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ gcloud container clusters get-credentials regional-demo --zone us-east1 --project PROJECT_ID</code></pre></div>\n      </div>\n<p>Replacing PROJECT_ID with your GKE project ID. Additionally, to make it easier to identify the context name:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl config rename-context gke_PROJECT_ID_us-east1_regional-demo regional-demo</code></pre></div>\n      </div>\n<p>Verify the correct current context is set with <code class=\"language-text\">kubectl</code> (indicated by <code class=\"language-text\">*</code>):</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl config get-contexts\nCURRENT   NAME            CLUSTER                                                   AUTHINFO                                                  NAMESPACE\n*         regional-demo   gke_PROJECT_ID_us-east1_regional-demo   gke_PROJECT_ID_us-east1_regional-demo</code></pre></div>\n      </div>\n<h2 id=\"verify-the-cluster-creation\" style=\"position:relative;\"><a href=\"#verify-the-cluster-creation\" aria-label=\"verify the cluster creation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Verify the Cluster Creation</h2>\n<p>Verify the worker nodes are available:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get nodes\nNAME                                           STATUS   ROLES    AGE   VERSION\ngke-regional-demo-default-pool-e121c001-k667   Ready    &lt;none>   13m   v1.16.9-gke.2\ngke-regional-demo-default-pool-e121c001-zhrt   Ready    &lt;none>   13m   v1.16.9-gke.2\ngke-regional-demo-default-pool-e121c001-zpv4   Ready    &lt;none>   13m   v1.16.9-gke.2\ngke-regional-demo-default-pool-ea10f422-5f72   Ready    &lt;none>   13m   v1.16.9-gke.2\ngke-regional-demo-default-pool-ea10f422-ntdk   Ready    &lt;none>   13m   v1.16.9-gke.2\ngke-regional-demo-default-pool-ea10f422-vw3c   Ready    &lt;none>   13m   v1.16.9-gke.2\ngke-regional-demo-default-pool-fb3e6608-0lx2   Ready    &lt;none>   13m   v1.16.9-gke.2\ngke-regional-demo-default-pool-fb3e6608-0rcc   Ready    &lt;none>   13m   v1.16.9-gke.2\ngke-regional-demo-default-pool-fb3e6608-2qsk   Ready    &lt;none>   13m   v1.16.9-gke.2</code></pre></div>\n      </div>\n<p>As shown, there are 9 nodes with 3 in each pool.</p>\n<p>Each node will have a label applied by the key of <code class=\"language-text\">failure-domain.beta.kubernetes.io/zone</code> and a value of the zone it is located in. To identify which nodes are placed in which zones, we can select on the label, for example:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get nodes -l failure-domain.beta.kubernetes.io/zone=us-east1-b\nNAME                                           STATUS   ROLES    AGE   VERSION\ngke-regional-demo-default-pool-ea10f422-5f72   Ready    &lt;none>   29m   v1.16.9-gke.2\ngke-regional-demo-default-pool-ea10f422-ntdk   Ready    &lt;none>   29m   v1.16.9-gke.2\ngke-regional-demo-default-pool-ea10f422-vw3c   Ready    &lt;none>   29m   v1.16.9-gke.2</code></pre></div>\n      </div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get nodes -l failure-domain.beta.kubernetes.io/zone=us-east1-c\nNAME                                           STATUS   ROLES    AGE   VERSION\ngke-regional-demo-default-pool-e121c001-k667   Ready    &lt;none>   29m   v1.16.9-gke.2\ngke-regional-demo-default-pool-e121c001-zhrt   Ready    &lt;none>   29m   v1.16.9-gke.2\ngke-regional-demo-default-pool-e121c001-zpv4   Ready    &lt;none>   29m   v1.16.9-gke.2</code></pre></div>\n      </div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get nodes -l failure-domain.beta.kubernetes.io/zone=us-east1-d\nNAME                                           STATUS   ROLES    AGE   VERSION\ngke-regional-demo-default-pool-fb3e6608-0lx2   Ready    &lt;none>   29m   v1.16.9-gke.2\ngke-regional-demo-default-pool-fb3e6608-0rcc   Ready    &lt;none>   29m   v1.16.9-gke.2\ngke-regional-demo-default-pool-fb3e6608-2qsk   Ready    &lt;none>   29m   v1.16.9-gke.2</code></pre></div>\n      </div>\n<h2 id=\"deploying-spring-cloud-data-flow\" style=\"position:relative;\"><a href=\"#deploying-spring-cloud-data-flow\" aria-label=\"deploying spring cloud data flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploying Spring Cloud Data Flow</h2>\n<p>At this point there is now a fully functional multi-node cluster spread across 3 zones in 1 region, with 3 worker nodes in each.</p>\n<p>Spring Cloud Data Flow provides manifest files to deploy Data Flow, Skipper and service dependencies such as a database and messaging middleware. These files are located in the <code class=\"language-text\">src/kubernetes</code> directory of the <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spring Cloud Data Flow</a> Git repository.</p>\n<p>The relevant files can be applied as-is letting Kubernetes handle where they should be scheduled, but we can also modify where we want these applications deployed, the number of instances and so on using standard Kubernetes constructs.</p>\n<p>In this recipe, we will implement the following use-case for our deployment:</p>\n<ul>\n<li>3 replicas of Skipper should be deployed, one replica per region</li>\n<li>3 replicas of Data Flow should be deployed, one replica per region, co-located on the same node as Skipper</li>\n<li>MySQL will be used as the database and will be placed in a specific zone</li>\n<li>RabbitMQ will be used as the messaging middleware and be placed in a specific zone</li>\n</ul>\n<h3 id=\"deploying-mysql\" style=\"position:relative;\"><a href=\"#deploying-mysql\" aria-label=\"deploying mysql permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploying MySQL</h3>\n<div class=\"admonition note\"><p>In this recipe, an instance of MySQL is being deployed to a single zone. Please see the relevant high availability documentation of the <a href=\"https://dev.mysql.com/doc/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">MySQL</a> product for more details. In the event of a zone failure, MySQL may be unavailable. Setting up MySQL for HA is outside the scope of SCDF and this recipe.</p></div>\n<p>The deployment of MySQL will consist of 1 replica. MySQL uses persistent storage and the creation/access of that storage is governed by the rules outlined in <a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/regional-clusters#pd\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Persistent storage in regional clusters</a>. Unless a <code class=\"language-text\">StorageClass</code> is defined referencing a specific zone which it should be created, GKE will choose a random zone. A custom <code class=\"language-text\">StorageClass</code> would then be referenced in the <code class=\"language-text\">PVC</code> configuration for MySQL.</p>\n<p>A default StorageClass is automatically created by GKE, which we will use for simplicity. Any pods referencing a provisioned disk will be automatically scheduled in that same zone the disk is provisioned in. Since we have 3 nodes in each zone, in the event of a node failure the MySQL pod will be rescheduled to another node in the zone.</p>\n<p>Deploy the manifests:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl create -f mysql/\ndeployment.apps/mysql created\npersistentvolumeclaim/mysql created\nsecret/mysql created\nservice/mysql created</code></pre></div>\n      </div>\n<p>Get the volume name:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get pvc/mysql\nNAME    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nmysql   Bound    pvc-24f2acb5-17cd-45e1-8064-34bf602e408f   8Gi        RWO            standard       3m1s</code></pre></div>\n      </div>\n<p>Check the zone the volume is located in:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get pv/pvc-24f2acb5-17cd-45e1-8064-34bf602e408f -o jsonpath='{.metadata.labels.failure-domain\\.beta\\.kubernetes\\.io/zone}'\nus-east1-d</code></pre></div>\n      </div>\n<p>Check the MySQL pod to verify its running and the node allocated to:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get pod/mysql-b94654bd4-9zpt2 -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName\nNAME                    STATUS    NODE\nmysql-b94654bd4-9zpt2   Running   gke-regional-demo-default-pool-fb3e6608-0rcc</code></pre></div>\n      </div>\n<p>And finally, the zone the node resides in can be verified by:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get node gke-regional-demo-default-pool-fb3e6608-0rcc -o jsonpath='{.metadata.labels.failure-domain\\.beta\\.kubernetes\\.io/zone}'\nus-east1-d</code></pre></div>\n      </div>\n<h3 id=\"deploying-rabbitmq\" style=\"position:relative;\"><a href=\"#deploying-rabbitmq\" aria-label=\"deploying rabbitmq permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploying RabbitMQ</h3>\n<div class=\"admonition note\"><p>In this recipe, an instance of RabbitMQ is being deployed to a single zone. Please see the relevant high availability documentation of the <a href=\"https://www.rabbitmq.com/documentation.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">RabbitMQ</a> product for more details. In the event of a zone failure, RabbitMQ may be unavailable. Setting up RabbitMQ for HA is outside the scope of SCDF and this recipe.</p></div>\n<p>The deployment of RabbitMQ will consist of 1 replica. The provided manifests do not configure any persistent storage as with MySQL. In order to place RabbitMQ in a specific zone, we can use a simple <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">nodeSelector</a>.</p>\n<p>The node in which a the pod gets scheduled to may not be a concern, just that it resides in a specific zone. All nodes in the cluster automatically get labels assigned, one of those representing the zone the node resides which we will utilize.</p>\n<p>Make the following modification to the <code class=\"language-text\">rabbitmq/rabbitmq-deployment.yaml</code> file to place RabbitMQ on a node in the <code class=\"language-text\">us-east1-b</code> zone:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">    spec:\n      nodeSelector:\n        failure-domain.beta.kubernetes.io/zone: us-east1-b</code></pre></div>\n      </div>\n<p>Deploy the manifests:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl create -f rabbitmq/\ndeployment.apps/rabbitmq created\nservice/rabbitmq created</code></pre></div>\n      </div>\n<p>Get the node the pod is deployed to:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get pod/rabbitmq-6d65f675d9-4vksj -o jsonpath='{.spec.nodeName}'\ngke-regional-demo-default-pool-ea10f422-5f72</code></pre></div>\n      </div>\n<p>Get the zone the node resides in:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get node gke-regional-demo-default-pool-ea10f422-5f72 -o jsonpath='{.metadata.labels.failure-domain\\.beta\\.kubernetes\\.io/zone}'\nus-east1-b</code></pre></div>\n      </div>\n<h3 id=\"deploying-skipper\" style=\"position:relative;\"><a href=\"#deploying-skipper\" aria-label=\"deploying skipper permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploying Skipper</h3>\n<p>he deployment of Skipper will consist of 3 replicas. No persistent storage is needed and its desired to have a replica running in each zone. Multiple replicas should not reside in the same zone as another. One way to do this would be using <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Pod Anti Affinity</a>.</p>\n<p>Make the following modifications to the <code class=\"language-text\">skipper/skipper-deployment.yaml</code> file bumping up the replica count and adding the pod anti-affinity:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spec:\n  replicas: 3</code></pre></div>\n      </div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - skipper\n            topologyKey: failure-domain.beta.kubernetes.io/zone</code></pre></div>\n      </div>\n<p>Deploy the manifests:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl create -f server/server-roles.yaml\n$ kubectl create -f server/server-rolebinding.yaml\n$ kubectl create -f server/service-account.yaml\n$ kubectl create -f skipper/skipper-config-rabbit.yaml\n$ kubectl create -f skipper/skipper-deployment.yaml\n$ kubectl create -f skipper/skipper-svc.yaml</code></pre></div>\n      </div>\n<p>Get the nodes the pods are deployed to:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get pods -l app=skipper -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName\nNAME                       STATUS    NODE\nskipper-6fd7bb796c-flm44   Running   gke-regional-demo-default-pool-e121c001-zhrt\nskipper-6fd7bb796c-l99dj   Running   gke-regional-demo-default-pool-ea10f422-5f72\nskipper-6fd7bb796c-vrf9m   Running   gke-regional-demo-default-pool-fb3e6608-0lx2</code></pre></div>\n      </div>\n<p>Get the zones the nodes reside in:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get node gke-regional-demo-default-pool-e121c001-zhrt -o jsonpath='{.metadata.labels.failure-domain\\.beta\\.kubernetes\\.io/zone}'\nus-east1-c\n$ kubectl get node gke-regional-demo-default-pool-ea10f422-5f72 -o jsonpath='{.metadata.labels.failure-domain\\.beta\\.kubernetes\\.io/zone}'\nus-east1-b\n$ kubectl get node gke-regional-demo-default-pool-fb3e6608-0lx2 -o jsonpath='{.metadata.labels.failure-domain\\.beta\\.kubernetes\\.io/zone}'\nus-east1-d</code></pre></div>\n      </div>\n<h3 id=\"deploying-data-flow\" style=\"position:relative;\"><a href=\"#deploying-data-flow\" aria-label=\"deploying data flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploying Data Flow</h3>\n<p>The deployment of Data Flow will consist of 3 replicas. No persistent storage is needed and its desired to have a replica running in each zone. Multiple replica's should not reside in the same zone as another. Additionally since Data Flow makes calls to Skipper often, co-locate it on the same node in each region. One way to do this would be using <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Pod Affinity</a>.</p>\n<p>Make the following modifications to the <code class=\"language-text\">server/server-deployment.yaml</code> file bumping up the replica count and adding the pod affinity:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spec:\n  replicas: 3</code></pre></div>\n      </div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">  affinity:\n    podAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n      - labelSelector:\n          matchExpressions:\n          - key: app\n            operator: In\n            values:\n            - skipper\n        topologyKey: kubernetes.io/hostname</code></pre></div>\n      </div>\n<p>Deploy the manifests:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl create -f server/server-config.yaml\n$ kubectl create -f server/server-svc.yaml\n$ kubectl create -f server/server-deployment.yaml</code></pre></div>\n      </div>\n<p>Get the nodes the pods are deployed to:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get pods -l app=scdf-server -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName\nNAME                           STATUS    NODE\nscdf-server-5ddf7bbd4f-dpnmm   Running   gke-regional-demo-default-pool-fb3e6608-0lx2\nscdf-server-5ddf7bbd4f-hlf9h   Running   gke-regional-demo-default-pool-e121c001-zhrt\nscdf-server-5ddf7bbd4f-vnjh6   Running   gke-regional-demo-default-pool-ea10f422-5f72</code></pre></div>\n      </div>\n<p>Verify the pods are deployed to the same nodes as Skipper:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl get pods -l app=skipper -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName\nNAME                       STATUS    NODE\nskipper-6fd7bb796c-flm44   Running   gke-regional-demo-default-pool-e121c001-zhrt\nskipper-6fd7bb796c-l99dj   Running   gke-regional-demo-default-pool-ea10f422-5f72\nskipper-6fd7bb796c-vrf9m   Running   gke-regional-demo-default-pool-fb3e6608-0lx2</code></pre></div>\n      </div>\n<p>Verify connectivity to Data Flow:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ SCDF_IP=$(kubectl get svc/scdf-server -o jsonpath='{.status.loadBalancer.ingress[*].ip}')\n$ curl -s http://$SCDF_IP/about | jq\n{\n  \"featureInfo\": {\n    \"analyticsEnabled\": true,\n    \"streamsEnabled\": true,\n    \"tasksEnabled\": true,\n    \"schedulesEnabled\": true,\n    \"grafanaEnabled\": true\n  },\n  \"versionInfo\": {\n    \"implementation\": {\n      \"name\": \"spring-cloud-dataflow-server\",\n      \"version\": \"2.7.0-SNAPSHOT\"\n    },\n...\n...\n...</code></pre></div>\n      </div>\n<h2 id=\"deploying-streams-and-tasks\" style=\"position:relative;\"><a href=\"#deploying-streams-and-tasks\" aria-label=\"deploying streams and tasks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploying Streams and Tasks</h2>\n<p>Streams and Tasks deployed through Data Flow can also benefit from various placement options, just as with server components. There may be situations where certain streams or tasks should only be deployed to specific zones or even nodes themselves. Deployed streams and tasks are applications just like any others, so they also benefit from Kubernetes re-scheduling them onto other nodes in the event of failures.</p>\n<p>Since streams and tasks are deployed to Kubernetes via Data Flow and Skipper, rather than applying these features to YAML manifests, they are set through deployer properties. See the <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#configuration-kubernetes-deployer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Deployer Property</a> section of the Spring Cloud Data Flow reference manual for a full list of available deployer properties.</p>\n<p>The deployer properties of interest are:</p>\n<p>Node selector:</p>\n<ul>\n<li>deployment.nodeSelector</li>\n</ul>\n<p>Tolerations:</p>\n<ul>\n<li>tolerations.key</li>\n<li>tolerations.effect</li>\n<li>tolerations.operator</li>\n<li>tolerations.tolerationSeconds</li>\n<li>tolerations.value</li>\n</ul>\n<p>Node Affinity:</p>\n<ul>\n<li>affinity.nodeAffinity</li>\n</ul>\n<p>Pod Affinity:</p>\n<ul>\n<li>affinity.podAffinity</li>\n</ul>\n<p>Pod Anti-Affinity:</p>\n<ul>\n<li>affinity.podAntiAffinity</li>\n</ul>\n<p>For a concrete example of how to set deployment properties at the application or server level, see the <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#_tolerations\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Tolerations</a> section of the reference manual. The same pattern applies to other properties, using different property names and values.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>In this recipe, we have set up a Regional cluster in GKE, providing the infrastructure to provide high availability control planes and workers across multiple zones in a region. We explored different options for application placement using constructs such as node selector, pod affinity, and pod anti-affinity. Each application and environment will have their own specialized needs, but this recipe should provide a starting point on how standard Kubernetes constructs can be used with Data Flow.</p>","headings":[{"value":"Deploying Spring Cloud Data Flow to a GKE Regional Cluster","depth":1},{"value":"Prerequisites","depth":2},{"value":"Creating the Cluster","depth":2},{"value":"Verify the Cluster Creation","depth":2},{"value":"Deploying Spring Cloud Data Flow","depth":2},{"value":"Deploying MySQL","depth":3},{"value":"Deploying RabbitMQ","depth":3},{"value":"Deploying Skipper","depth":3},{"value":"Deploying Data Flow","depth":3},{"value":"Deploying Streams and Tasks","depth":2},{"value":"Conclusion","depth":2}],"fields":{"path":"/docs/2.6.x/recipes/cloud-providers/gke-regional-clusters/","version":"2.6.x","category":"recipes","sourcePath":"pages/6-recipes/9-cloud-providers/1-gke-regional-clusters.md"},"frontmatter":{"title":"GKE Regional Clusters","summary":null,"path":"recipes/cloud-providers/gke-regional-clusters/","toc":null,"prevNext":null}}},"pageContext":{"slug":"/docs/2.6.x/recipes/cloud-providers/gke-regional-clusters/","version":"2.6.x","versionPath":""}},"staticQueryHashes":["2044043181"]}