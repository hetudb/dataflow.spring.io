{"componentChunkName":"component---src-templates-documentation-js","path":"/docs/2.6.x/resources/faq/","result":{"data":{"pages":{"edges":[{"node":{"id":"e9021eeb-a6bb-59ff-ac01-48c86eabd4a0","fields":{"path":"/docs/2.6.x/installation/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Installation","description":"How to install Data Flow","path":"installation/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4d2ef486-b1d3-5021-b5ba-42ec362b1562","fields":{"path":"/docs/2.6.x/installation/local/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Local Machine","description":"Local Machine Installation Guide","path":"installation/local/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5677e8b5-0bd6-5e56-86b2-885107a13e1b","fields":{"path":"/docs/2.6.x/installation/local/docker/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Docker Compose","description":"Installation using Docker Compose","path":"installation/local/docker","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f8b9d584-3559-5744-beba-9e5d2ca30de6","fields":{"path":"/docs/2.6.x/installation/local/docker-customize/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Docker Compose Customization","description":"Customize the Docker Compose installation","path":"installation/local/docker-customize","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1e019f6e-b12c-5dfb-af9f-0ee64023c52c","fields":{"path":"/docs/2.6.x/installation/local/manual/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Manual","description":"Manual installation","path":"installation/local/manual","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"90cc84da-bf5e-51a4-8bf1-27e4f643ba6e","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry","description":"Data Flow Cloud Foundry Installation Guide","path":"installation/cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dcde0625-3190-504f-a1a6-f56e72fdc7ae","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/cf-cli/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry CLI","description":"Install using the Cloud Foundry CLI","path":"installation/cloudfoundry/cf-cli","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a5ffaf9e-68c1-57e6-82d6-6164f5f93c0b","fields":{"path":"/docs/2.6.x/installation/cloudfoundry/cf-local/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Running locally","description":"Configure the local servers to deploy to Cloud Foundry","path":"installation/cloudfoundry/cf-local","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4477369a-b2fe-5745-b092-e3b67713d013","fields":{"path":"/docs/2.6.x/installation/kubernetes/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Kubernetes","description":"Data Flow Kubernetes Installation Guide","path":"installation/kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"119f4320-d2f6-5cbf-a9a9-8284623dd171","fields":{"path":"/docs/2.6.x/installation/kubernetes/creating-a-cluster/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Creating a Cluster","description":"Creating a Kubernetes Cluster","path":"installation/kubernetes/creating-a-cluster","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"db871ceb-3a12-5869-ae62-719e896b1db0","fields":{"path":"/docs/2.6.x/installation/kubernetes/helm/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Helm","description":"Installation using Helm","path":"installation/kubernetes/helm","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"caf737ab-3988-5332-8aff-f4623ff1bd1f","fields":{"path":"/docs/2.6.x/installation/kubernetes/kubectl/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"kubectl","description":"Installation using kubectl","path":"installation/kubernetes/kubectl","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c5fa77bd-d62a-5098-bcca-70542ab0c26e","fields":{"path":"/docs/2.6.x/installation/kubernetes/compatibility/","version":"2.6.x","category":"installation"},"frontmatter":{"title":"Kubernetes Compatibility","description":"Compatibility with Kubernetes Versions","path":"installation/kubernetes/compatibility","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"929fcfcf-1990-5367-af35-a9e781a72e6b","fields":{"path":"/docs/2.6.x/concepts/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Concepts","description":"Core Concepts in Spring Cloud Data Flow","path":"concepts/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"99224add-aea3-5da9-b131-c7f449c8d48e","fields":{"path":"/docs/2.6.x/concepts/architecture/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Architecture","description":"Introduction to Data Flow's Architecture.","path":"concepts/architecture/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d61c129f-87f4-5650-96ef-5c4d102df471","fields":{"path":"/docs/2.6.x/concepts/streams/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Stream Processing","description":"Stream Processing Framework and Concepts","path":"concepts/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"89ecf7e1-75c6-5d48-a6cc-ce96d27828d2","fields":{"path":"/docs/2.6.x/concepts/batch-jobs/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Batch Processing","description":"Batch Processing Framework and Concepts","path":"concepts/batch-jobs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3c0c3e30-fbef-5bc9-a751-9a98ce2623c3","fields":{"path":"/docs/2.6.x/concepts/monitoring/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Monitoring","description":"Runtime monitoring of Stream data pipelines","path":"concepts/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f42c5920-63af-5427-8ec4-da4cec31d9d3","fields":{"path":"/docs/2.6.x/concepts/tooling/","version":"2.6.x","category":"concepts"},"frontmatter":{"title":"Tooling","description":"Dashboard and Shell","path":"concepts/tooling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"de52e1a6-ded9-53a7-9880-1912d060def0","fields":{"path":"/docs/2.6.x/stream-developer-guides/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Developer guides ","description":"Learn how to create Streaming data pipelines using prebuilt microservices or create your own.","path":"stream-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"25aa7b2c-d0a7-594b-b2e8-5688e30d9b2e","fields":{"path":"/docs/2.6.x/stream-developer-guides/getting-started/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Stream Processing","path":"stream-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"662bc53d-bfe5-573e-aff6-90c1ac01c219","fields":{"path":"/docs/2.6.x/stream-developer-guides/getting-started/stream/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing","description":"Create and deploy a streaming data pipeline using prebuilt applications on your Local Machine","path":"stream-developer-guides/getting-started/stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5e286ba1-bf9e-5bef-b317-439cee0dad6a","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Development","description":"Stream Processing Developer Guide","path":"stream-developer-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"330b159e-9210-5f4d-9df0-7975a8b80df3","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/standalone-stream-rabbitmq/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on RabbitMQ","description":"Create your own microservices for Stream processing using RabbitMQ and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f4886ff1-ae23-51fe-a76c-c5d8a688dd5b","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/standalone-stream-kafka/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on Apache Kafka","description":"Create your own microservices for Stream processing using Apache Kafka and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cabf8341-e0bf-5bb2-afa0-4d99e24ce1e8","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/data-flow-stream/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing using Spring Cloud Data Flow","description":"Create and Deploy a Stream Processing Pipeline using Spring Cloud Data Flow","path":"stream-developer-guides/streams/data-flow-stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e5aceaf2-0ade-5d25-8c07-46dc78c41596","fields":{"path":"/docs/2.6.x/stream-developer-guides/streams/stream-other-binders/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Spring Application Development on other Messaging Middleware","description":"Create your own microservices for Stream processing using other messaging middleware such as Google Pub/Sub, Amazon Kinesis, and Solace JMS","path":"stream-developer-guides/streams/stream-other-binders/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5cf102aa-7ea7-56e2-9efd-6d9ecca536fe","fields":{"path":"/docs/2.6.x/stream-developer-guides/programming-models/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Programming Models","description":"Programming models","path":"stream-developer-guides/programming-models/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cb665729-22e1-5fc3-9022-c0dd45f194cb","fields":{"path":"/docs/2.6.x/stream-developer-guides/continuous-delivery/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery","description":"CD using Skipper","path":"stream-developer-guides/continuous-delivery/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a11a49c7-beb0-591c-9eb3-edb64c83c6b1","fields":{"path":"/docs/2.6.x/stream-developer-guides/continuous-delivery/cd-basics/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery of streaming applications","description":"Continuous Delivery of Streaming applications","path":"stream-developer-guides/continuous-delivery/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"26860f37-faed-5b74-b92b-26fb867505ca","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Streams","path":"stream-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"48779233-7811-551b-bb00-1bc1a9729927","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/debugging-stream-apps/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream Applications","description":"Debugging Stream Applications outside of Data Flow","path":"stream-developer-guides/troubleshooting/debugging-stream-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5f57c55d-32e4-59fc-91c1-8a52bcbb48ee","fields":{"path":"/docs/2.6.x/stream-developer-guides/troubleshooting/debugging-scdf-streams/","version":"2.6.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream applications deployed by Data Flow","description":"Debugging Data Flow Stream deployments","path":"stream-developer-guides/troubleshooting/debugging-scdf-streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"37a22652-17b0-5d93-8ca8-bca78334ea76","fields":{"path":"/docs/2.6.x/batch-developer-guides/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"batch-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"801a3829-0592-5238-a423-a7401fda6d75","fields":{"path":"/docs/2.6.x/batch-developer-guides/getting-started/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Batch","path":"batch-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6d3eaaf0-06a0-5b15-9e34-22e5a3bc3c4a","fields":{"path":"/docs/2.6.x/batch-developer-guides/getting-started/task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Task Processing","description":"Create and deploy a simple Task pipeline using a prebuilt Task application on your local machine","path":"batch-developer-guides/getting-started/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1c467d57-4330-57b5-a082-ce1d66c7b97d","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Development","description":"Batch Developer Guide","path":"batch-developer-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0bc43ff5-11dc-538a-8a22-dccbbb01b166","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/spring-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"batch-developer-guides/batch/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"07cab399-4800-5892-b85c-2a7458c18d5f","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/spring-batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"batch-developer-guides/batch/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c82bad2b-2e5d-5771-bce6-27066ff3ef82","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cec2f163-1cd9-5052-981e-89a5e085cb84","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-spring-batch/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"batch-developer-guides/batch/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d100d3c9-ac7e-578d-9707-d7af65827827","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-composed-task/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"batch-developer-guides/batch/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c1352ada-7f61-57d2-976d-3f49bd2b3ab6","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task-kubernetes/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d903c65f-f587-5023-ad49-d9a2da203603","fields":{"path":"/docs/2.6.x/batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"db6a5270-4b1c-550c-ab60-345a6cb8e8bd","fields":{"path":"/docs/2.6.x/batch-developer-guides/continuous-deployment/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"batch-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"27640e7d-20c3-5857-a9f7-e5e74e56a98d","fields":{"path":"/docs/2.6.x/batch-developer-guides/continuous-deployment/cd-basics/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"batch-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1044acb3-91f1-5a91-9187-d6e5d33133e4","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"batch-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"460d5979-e8e4-5a5c-bbf6-db7ee54a471f","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/debugging-task-apps/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"batch-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b0663c20-e821-5837-a799-a53686f5c67b","fields":{"path":"/docs/2.6.x/batch-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"2.6.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"batch-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0db0658d-b083-5c3d-b43c-f33701394dbc","fields":{"path":"/docs/2.6.x/feature-guides/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Feature guides","description":"High level overview of Data Flow Features","path":"feature-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3d4a79f7-bc01-57f4-8fee-1ec7f8038396","fields":{"path":"/docs/2.6.x/feature-guides/general/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"General","description":"General Features in Data Flow","path":"feature-guides/general/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"72147749-774f-5535-83d3-d0237da98171","fields":{"path":"/docs/2.6.x/feature-guides/general/application-metadata/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Application Metadata","description":"Create and use application properties metadata","path":"feature-guides/general/application-metadata/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bdb03de9-49e7-54cc-9c78-012a7d62f551","fields":{"path":"/docs/2.6.x/feature-guides/streams/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Streams","description":"Stream Features in Data Flow","path":"feature-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9e46d55d-12bb-5dfb-8ae8-1eb0cd5af0d4","fields":{"path":"/docs/2.6.x/feature-guides/streams/deployment-properties/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a stream deployment with deployment property overrides","path":"feature-guides/streams/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9cfa8e02-c993-57f5-9b80-79ac6b30bacd","fields":{"path":"/docs/2.6.x/feature-guides/streams/function-composition/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Composing Functions","description":"Daisy-chain Java functions in an existing Spring Cloud Stream application","path":"feature-guides/streams/function-composition/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4bf293a4-98e7-5e83-ba2f-d691ea4ea8e7","fields":{"path":"/docs/2.6.x/feature-guides/streams/named-destinations/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Named Destinations","description":"Use the Named Destinations to interact with the Topics/Queues directly","path":"feature-guides/streams/named-destinations/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f2492bb6-cf38-56b7-a5b0-7b480d93831b","fields":{"path":"/docs/2.6.x/feature-guides/streams/monitoring/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Stream Monitoring","description":"Monitoring streaming data pipelines with Prometheus and InfluxDB","path":"feature-guides/streams/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ea8d17bc-832b-5010-8493-0057ce1e3c9e","fields":{"path":"/docs/2.6.x/feature-guides/streams/stream-application-dsl/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Stream Application DSL","description":"Learn how to use the Stream Application DSL","path":"feature-guides/streams/stream-application-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7e0c92af-5ac0-525e-886d-24ef860121cc","fields":{"path":"/docs/2.6.x/feature-guides/streams/labels/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Labeling Applications","description":"Label the stream applications to uniquely interact with them","path":"feature-guides/streams/labels/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c434626b-145c-511f-8591-9c3ddcb282a3","fields":{"path":"/docs/2.6.x/feature-guides/streams/application-count/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Application Count","description":"Initiate stream deployment with multiple application instances","path":"feature-guides/streams/application-count/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1f734409-9f01-5699-8906-d4b81b4fc7df","fields":{"path":"/docs/2.6.x/feature-guides/streams/fanin-fanout/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Fan-in and Fan-out","description":"Publish and subscribe to multiple destinations using the fan-in and fan-out capabilities","path":"feature-guides/streams/fanin-fanout/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8a34cc56-301c-5298-8be5-5aa9a712d156","fields":{"path":"/docs/2.6.x/feature-guides/streams/partitioning/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Data Partitioning","description":"Learn more about data partitioning support to build stateful streaming data pipelines","path":"feature-guides/streams/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3e10f1c9-14b7-50e3-b295-7fac6fd8de79","fields":{"path":"/docs/2.6.x/feature-guides/streams/scaling/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Scaling","description":"Scaling streaming data pipeline with Spring Cloud Data Flow","path":"feature-guides/streams/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5c27a2e4-32bb-5f8c-8a71-120c286b8c70","fields":{"path":"/docs/2.6.x/feature-guides/streams/java-dsl/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Java DSL","description":"Programmatically create streams using the Java DSL","path":"feature-guides/streams/java-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"531c7f03-b972-5bb7-a252-a7a584fc8ef5","fields":{"path":"/docs/2.6.x/feature-guides/streams/taps/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Tapping a Stream","description":"Create a stream from another stream without interrupting the data processing","path":"feature-guides/streams/taps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"76e86fcf-b096-55af-b668-54a9ee785297","fields":{"path":"/docs/2.6.x/feature-guides/batch/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Batch","description":"Batch Features in Data Flow","path":"feature-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dd3f1828-4361-5163-ac19-dfc79b6feeff","fields":{"path":"/docs/2.6.x/feature-guides/batch/deployment-properties/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a Batch deployment with deployment property overrides","path":"feature-guides/batch/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"db544e92-6c62-5c3e-b630-b1a8a0a65300","fields":{"path":"/docs/2.6.x/feature-guides/batch/scheduling/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Scheduling Batch Jobs","description":"Learn how to schedule Batch Jobs","path":"feature-guides/batch/scheduling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"939b3288-80cc-5c8c-b608-6d3e6a3566fa","fields":{"path":"/docs/2.6.x/feature-guides/batch/partitioning/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Remote Partitioned Batch Job","description":"Learn more about partitioning support for Batch Jobs","path":"feature-guides/batch/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3b6f6285-0025-58ac-a678-507000366895","fields":{"path":"/docs/2.6.x/feature-guides/batch/monitoring/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Task Monitoring","description":"Monitoring task data pipelines with InfluxDB","path":"feature-guides/batch/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"88baffea-f888-5470-990b-3ae96079720a","fields":{"path":"/docs/2.6.x/feature-guides/batch/restarting/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Restarting Batch Jobs","description":"Learn how to restart Batch Jobs","path":"feature-guides/batch/restarting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5ccd8a85-54c4-5734-960d-61cd737d976c","fields":{"path":"/docs/2.6.x/feature-guides/batch/composed-task/","version":"2.6.x","category":"feature-guides"},"frontmatter":{"title":"Composed Tasks","description":"Learn how to create and manage composed tasks","path":"feature-guides/batch/composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cf488e7a-a79a-58a1-84c7-f239b00f0a36","fields":{"path":"/docs/2.6.x/recipes/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Recipes","description":"Recipes that help solve some common use-cases","path":"recipes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"832b2669-96c0-5acf-955f-a8092425bd75","fields":{"path":"/docs/2.6.x/recipes/polyglot/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Polyglot","description":"Using multiple programming languages","path":"recipes/polyglot/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4c7ade10-63e9-5c59-b33c-dc10405cb8bc","fields":{"path":"/docs/2.6.x/recipes/polyglot/processor/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Stream Processor","description":"Python Application as a Data Flow Stream Processor","path":"recipes/polyglot/processor/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8b17d791-bab2-56cc-adfc-cf2ce3ebc3c8","fields":{"path":"/docs/2.6.x/recipes/polyglot/task/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Task","description":"Create and Deploy a Python Task","path":"recipes/polyglot/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e6de6439-cf64-56a5-aad3-35e69c5f0ede","fields":{"path":"/docs/2.6.x/recipes/polyglot/app/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Python Application","description":"Create and Deploy a Python Application in a Stream","path":"recipes/polyglot/app/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f0245349-2811-5319-a15e-049eb69ead0a","fields":{"path":"/docs/2.6.x/recipes/rabbitmq/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ","description":"RabbitMQ","path":"recipes/rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"040ded45-231f-5c98-a3ee-b79f3e463adf","fields":{"path":"/docs/2.6.x/recipes/rabbitmq/rabbit-source-sink/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ as Source and Sink","description":"RabbitMQ as Source and Sink + RabbitMQ binder","path":"recipes/rabbitmq/rabbit-source-sink/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"58377b55-b637-5353-aad8-ea5634b5ba70","fields":{"path":"/docs/2.6.x/recipes/kafka/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Apache Kafka","description":"Kafka","path":"recipes/kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"96d36967-fb2f-5188-99c1-1ab07a5669dd","fields":{"path":"/docs/2.6.x/recipes/kafka/ext-kafka-cluster-cf/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"External Kafka Cluster","description":"Connect to an external Kafka Cluster from Cloud Foundry","path":"recipes/kafka/ext-kafka-cluster-cf/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f8d244b8-35e6-5dd1-8c0e-a0f2683cc8f1","fields":{"path":"/docs/2.6.x/recipes/kinesis/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis","description":"Amazon Kinesis","path":"recipes/kinesis/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4dd53e72-e7ae-5ff7-a3c0-f45db20dffdd","fields":{"path":"/docs/2.6.x/recipes/kinesis/simple-producer-consumer/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis Binder","description":"A sample of Spring Cloud Stream + Amazon Kinesis Binder in action","path":"recipes/kinesis/simple-producer-consumer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"44ad6f69-e0bf-5a2c-b1e0-6e44c4f32960","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform Deployments","description":"Multiple Platform Deployments","path":"recipes/multi-platform-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e151daf9-0907-5888-a264-fd1225e70752","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/multiple-platform-accounts/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Role of Multiple Platform Deployments","description":"A walk-through of multiple platform requirements and the configurations for Cloud Foundry and Kubernetes","path":"recipes/multi-platform-deployment/multiple-platform-accounts","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7d0b675d-d227-5eae-8e6a-bcdfe22e24a1","fields":{"path":"/docs/2.6.x/recipes/multi-platform-deployment/multi-platform-task/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform support for Tasks","description":"Learn how to launch and schedule tasks across multiple platforms","path":"recipes/multi-platform-deployment/multi-platform-task","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e2bb5e49-03c6-572d-909f-ba0175bac7a1","fields":{"path":"/docs/2.6.x/recipes/scaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Scaling","description":"Prometheus and Data Flow to autoscale streaming data pipelines","path":"recipes/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ebe9d02c-933f-575a-b6a2-70902f36adbb","fields":{"path":"/docs/2.6.x/recipes/scaling/manual-scaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Manual Scaling","description":"Scale applications using SCDF Shell","path":"recipes/scaling/manual-scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1a8da8d0-dc19-588e-842b-6753e5f680a3","fields":{"path":"/docs/2.6.x/recipes/scaling/autoscaling/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Autoscaling","description":"Autoscale streaming data pipeline with SCDF and Prometheus","path":"recipes/scaling/autoscaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"41246959-ff77-5531-8710-baa307c71cf3","fields":{"path":"/docs/2.6.x/recipes/batch/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Batch","description":"Using Spring Cloud Data Flow with Spring Batch","path":"recipes/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"376ac9e8-46be-5ea1-8ab7-a651e3d9acc4","fields":{"path":"/docs/2.6.x/recipes/batch/batch-only-mode/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Batch-only Mode","description":"Set up Spring Cloud Data Flow to use only batch and not streams","path":"recipes/batch/batch-only-mode/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a26aab98-8b26-5318-8b76-131c7c6c9fd6","fields":{"path":"/docs/2.6.x/recipes/batch/sftp-to-jdbc/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"SFTP to JDBC","description":"Ingest Files from SFTP to a JDBC data store using Data Flow and Spring Batch","path":"recipes/batch/sftp-to-jdbc/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"51203ff4-d111-57ea-bf53-15b3f24e38d0","fields":{"path":"/docs/2.6.x/recipes/functional-apps/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Using Functional Approach in Spring Cloud Stream applications","path":"recipes/functional-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b86a08d0-bac2-5780-b8e1-eb48f0a4f9da","fields":{"path":"/docs/2.6.x/recipes/functional-apps/scst-function-bindings/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Configuring the Spring Cloud Stream Functional applications","path":"recipes/functional-apps/scst-function-bindings/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0d4fc819-caeb-567e-98c1-703594e0a8f5","fields":{"path":"/docs/2.6.x/recipes/cloud-providers/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"Cloud Providers","description":"Using functionality provided by cloud providers","path":"recipes/cloud-providers/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6c4c5dda-3035-5a42-86a6-4f69957a5031","fields":{"path":"/docs/2.6.x/recipes/cloud-providers/gke-regional-clusters/","version":"2.6.x","category":"recipes"},"frontmatter":{"title":"GKE Regional Clusters","description":"Deploying Spring Cloud Data Flow to a GKE Regional Cluster","path":"recipes/cloud-providers/gke-regional-clusters/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"861688d5-2c38-508d-978e-640323c6d6f8","fields":{"path":"/docs/2.6.x/resources/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Resources","description":"Sample Applications, References Docs, Videos, Blogs...","path":"resources/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ae36aa66-bfc0-5e25-a8d5-fadf9923ab74","fields":{"path":"/docs/2.6.x/resources/reference-docs/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Reference Documentation","description":"Collection of reference guides for Spring Cloud Data Flow","path":"resources/reference-docs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4c5f2c8b-1d31-5ae4-a8b6-72ce57ccbfb0","fields":{"path":"/docs/2.6.x/resources/samples/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Samples","description":"Collection of samples","path":"resources/samples/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6338daa2-c819-5f7d-80c8-544b0f84079d","fields":{"path":"/docs/2.6.x/resources/faq/","version":"2.6.x","category":"resources"},"frontmatter":{"title":"Frequently Asked Questions","description":"","path":"resources/faq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9ceb4a4c-e3d7-51ce-ad2b-92062de9b87b","fields":{"path":"/docs/2.6.x/applications/","version":"2.6.x","category":"applications"},"frontmatter":{"title":"Applications","description":"Using stream and task applications","path":"applications/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ad96a136-c832-5548-ad1d-fa05028763c0","fields":{"path":"/docs/2.6.x/applications/pre-packaged/","version":"2.6.x","category":"applications"},"frontmatter":{"title":"Pre-packaged Applications","description":"Pre-packaged stream and task applications","path":"applications/pre-packaged","meta_title":null,"meta_description":null,"keywords":["application","pre-packaged"]}}}]},"page":{"html":"<h1 id=\"frequently-asked-questions\" style=\"position:relative;\"><a href=\"#frequently-asked-questions\" aria-label=\"frequently asked questions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Frequently Asked Questions</h1>\n<h2 id=\"application-starters\" style=\"position:relative;\"><a href=\"#application-starters\" aria-label=\"application starters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Application Starters</h2>\n<div class=\"question-block\" id=\"findtaskapps\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Where can I find the latest Spring Cloud Stream and Spring Cloud Task application starters?</p></div><div class=\"answer \"><p>The latest releases of the Stream and Task application starters are published to Maven Central and Docker Hub.\nYou can find the latest release versions from the <a href=\"https://cloud.spring.io/spring-cloud-stream-app-starters/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spring Cloud Stream App Starters</a> and <a href=\"https://cloud.spring.io/spring-cloud-task-app-starters/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spring Cloud Task App Starters</a> project sites.</p></div></div>\n<div class=\"question-block\" id=\"appreleases\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Where can I find the documentation for the latest application releases?</p></div><div class=\"answer \"><p>See the <a href=\"https://cloud.spring.io/spring-cloud-stream-app-starters/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spring Cloud Stream App Starters</a> and <a href=\"https://cloud.spring.io/spring-cloud-task-app-starters/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spring Cloud Task App Starters</a> project sites.</p></div></div>\n<div class=\"question-block\" id=\"extendapps\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Can I patch and extend the out-of-the-box applications?</p></div><div class=\"answer \"><p>Yes. You can find more details in the reference guide section on <a href=\"https://docs.spring.io/spring-cloud-stream-app-starters/docs/Einstein.SR7/reference/htmlsingle/#_patching_pre_built_applications\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Patching Application Starters</a> as well as documentation on <a href=\"/docs/2.6.x/feature-guides/streams/function-composition/\">Functional Composition</a>.</p></div></div>\n<div class=\"question-block\" id=\"buildappstarters\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Can I build a new application based on the same infrastructure as the out-of-the-box applications?</p></div><div class=\"answer \"><p>Yes. You can find more details in the Spring Cloud Stream App Starter's reference guide section <a href=\"https://docs.spring.io/spring-cloud-stream-app-starters/docs/Einstein.SR7/reference/htmlsingle/#_general_faq_on_spring_cloud_stream_app_starters\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">FAQ on Spring Cloud Stream App Starters</a>.</p></div></div>\n<div class=\"question-block\" id=\"downloadapps\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Where can I download the latest applications?</p></div><div class=\"answer \"><p>See the <a href=\"https://cloud.spring.io/spring-cloud-stream-app-starters/#http-repository-location-for-apps\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">stream</a> and <a href=\"https://cloud.spring.io/spring-cloud-task-app-starters/#http-repository-location-for-apps\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">task</a> apps project sites.</p></div></div>\n<div class=\"question-block\" id=\"appdockerimages\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Where are the Docker images hosted?</p></div><div class=\"answer \"><p>See <a href=\"https://hub.docker.com/u/springcloudstream\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">stream</a> and <a href=\"https://hub.docker.com/u/springcloudtask\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">task</a> apps in Docker Hub.</p></div></div>\n<h2 id=\"data-flow\" style=\"position:relative;\"><a href=\"#data-flow\" aria-label=\"data flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Flow</h2>\n<div class=\"question-block\" id=\"appsandscdf\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How are streaming applications and Spring Cloud Data Flow (SCDF) related?</p></div><div class=\"answer \"><p>Streaming applications are standalone, and they communicate with other applications through message brokers, such as RabbitMQ or Apache Kafka.\nThey run independently and no runtime dependency between applications and SCDF exists.\nHowever, based on user actions, SCDF interacts with the platform runtime to update the currently running application, query the current status, or stop the application from running.</p></div></div>\n<div class=\"question-block\" id=\"batchandscdf\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How are task and batch applications and Spring Cloud Data FLow (SCDF) related?</p></div><div class=\"answer \"><p>Though batch and task applications are standalone Spring Boot applications, to record the execution status of batch and task applications, you <em>must</em> connect both SCDF and the batch applications to the same database. The individual batch applications (deployed by SCDF), in turn, attempt to update their execution status to the shared database. The database, in turn, is used by SCDF to show the execution history and other details about the batch applications in SCDF's dashboard. You can also construct your batch and task applications to connect to the SCDF Database only for recording execution status but perform the work in another database.</p></div></div>\n<div class=\"question-block\" id=\"ctrandscdf\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>What is the relationship of <a href=\"https://github.com/spring-cloud-task-app-starters/composed-task-runner\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Composed Task Runner</a> and SCDF?</p></div><div class=\"answer \"><p><a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.3/reference/htmlsingle/#spring-cloud-dataflow-composed-tasks\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Composed tasks</a> delegate the running of the collection of tasks to a separate application, named the Composed Task Runner (CTR).\nThe CTR orchestrates the launching of Tasks defined in the composed task graph.\nTo use composed tasks, you must connect SCDF, CTR, and batch applications to a shared database. Only then can you track all of their execution history from SCDFâ€™s dashboard.</p></div></div>\n<div class=\"question-block\" id=\"brokerandscdf\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Does SCDF use message broker?</p></div><div class=\"answer \"><p>No. The Data Flow and Skipper servers do not interact with the message broker.\nStreaming applications deployed by Data flow connect to the message broker to publish and consume messages.</p></div></div>\n<div class=\"question-block\" id=\"skipperandscdf\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>What is the role of Skipper in Spring Cloud Data Flow (SCDF)?</p></div><div class=\"answer \"><p>SCDF delegates and relies on Skipper for the life cycle management of streaming applications. With Skipper, applications contained within the streaming data pipelines are versioned and can be updated (on a rolling basis) and rolled back to previous versions.</p></div></div>\n<div class=\"question-block\" id=\"scdftools\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>What tools are available to interact with Spring Cloud Data Flow (SCDF)?</p></div><div class=\"answer \"><p>You can use the following tools to interact with Spring Cloud Data Flow:</p><ul>\n<li><a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.3/reference/htmlsingle/#shell\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Shell</a></li>\n<li><a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.3/reference/htmlsingle/#dashboard\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Dashboard</a></li>\n<li><a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.3/reference/htmlsingle/#spring-cloud-dataflow-stream-java-dsl\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Java DSL</a></li>\n<li><a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.3/reference/htmlsingle/#api-guide-resources\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">REST-APIs</a>.</li>\n</ul></div></div>\n<div class=\"question-block\" id=\"intializrandscdf\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Why is Spring Cloud Data Flow (SCDF) not in Spring Initializr?</p></div><div class=\"answer \"><p>Initializr's goal is to provide a getting started experience for creating a Spring Boot Application.\nIt is not the goal of Initializr to create a production-ready server application.\nWe had tried this in the past, but we were not able to succeed because of the need for us to have very fine grained control over dependent libraries.\nAs such, we ship the binaries directly instead. We expect the users to either use the binaries as-is or extend them by building SCDF locally from the source.</p></div></div>\n<div class=\"question-block\" id=\"oracleandscdf\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Can Spring Cloud Data Flow (SCDF) work with an Oracle database?</p></div><div class=\"answer \"><p>Yes. You can read more about the <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.3/reference/htmlsingle/#configuration-local-rdbms\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">supported databases here.</a>.</p></div></div>\n<div class=\"question-block\" id=\"propsvsargs\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>When and where should I use Task properties versus arguments?</p></div><div class=\"answer \"><p>If the configuration for each task execution remains the same across all task launches, you can set the properties at the time in which you create the task definition. The following example shows how to do so:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">task create myTaskDefinition --definition \"timestamp --format='yyyy'\"</code></pre></div>\n      </div><p>If the configuration for each task execution changes for each task launch, you can use the arguments at task launch time, as the following example shows:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">task launch myTaskDefinition \"--server.port=8080\"</code></pre></div>\n      </div><div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>When you use Spring Cloud Data Flow to orchestrate the launches of a task application that uses Spring Batch, you should use arguments to set the Job Parameters required for your batch job.</p><p>Remember: If your argument is a non-identifying parameter, suffix the argument with <code class=\"language-text\">--</code>.</p></div></div></div></div>\n<div class=\"question-block\" id=\"ctrargs\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How do I pass command line arguments to the child tasks of a Composed Task graph?\nThis is done by using the <code class=\"language-text\">composedTaskArguments</code> property of the Composed Task Runner.</p></div><div class=\"answer \"><p>In the example below the command line argument <code class=\"language-text\">--timestamp.format=YYYYMMDD</code> will be applied to all child tasks in the composed task graph.</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">task launch myComposedTask --arguments \"--composedTaskArguments=--timestamp.format=YYYYMMDD\"</code></pre></div>\n      </div></div></div>\n<div class=\"question-block\" id=\"mavenconfig\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How to configure remote Maven repositories?</p></div><div class=\"answer \"><p>You can set the maven properties such as local maven repository location, remote maven repositories, authentication credentials, and proxy server properties through command line properties when starting the Data Flow server.\nAlternatively, you can set the properties using <code class=\"language-text\">SPRING_APPLICATION_JSON</code> environment property for the Data Flow server.</p><p>The remote maven repositories need to be configured explicitly if the apps are resolved using maven repository, except for a <code class=\"language-text\">local</code> Data Flow server.\nThe other Data Flow server implementations (that use maven resources for app artifacts resolution) have no default value for remote repositories.\nThe <code class=\"language-text\">local</code> server has <code class=\"language-text\">https://repo.spring.io/libs-snapshot</code> as the default remote repository.</p><p>To pass the properties as commandline options, run the server with a command similar to the following:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">java -jar <span class=\"token operator\">&lt;</span>dataflow-server<span class=\"token operator\">></span>.jar --maven.localRepository<span class=\"token operator\">=</span>mylocal\n--maven.remote-repositories.repo1.url<span class=\"token operator\">=</span>https://repo1\n--maven.remote-repositories.repo1.auth.username<span class=\"token operator\">=</span>repo1user\n--maven.remote-repositories.repo1.auth.password<span class=\"token operator\">=</span>repo1pass\n--maven.remote-repositories.repo2.url<span class=\"token operator\">=</span>https://repo2 --maven.proxy.host<span class=\"token operator\">=</span>proxyhost\n--maven.proxy.port<span class=\"token operator\">=</span><span class=\"token number\">9018</span> --maven.proxy.auth.username<span class=\"token operator\">=</span>proxyuser\n--maven.proxy.auth.password<span class=\"token operator\">=</span>proxypass</code></pre></div>\n      </div><p>You can also use the <code class=\"language-text\">SPRING_APPLICATION_JSON</code> environment property:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">SPRING_APPLICATION_JSON</span><span class=\"token operator\">=</span><span class=\"token string\">'{ \"maven\": { \"local-repository\": \"local\",\"remote-repositories\": { \"repo1\": { \"url\": \"https://repo1\", \"auth\": { \"username\": \"repo1user\", \"password\": \"repo1pass\" } },\n\"repo2\": { \"url\": \"https://repo2\" } }, \"proxy\": { \"host\": \"proxyhost\", \"port\": 9018, \"auth\": { \"username\": \"proxyuser\", \"password\": \"proxypass\" } } } }'</span></code></pre></div>\n      </div><p>Here is the same content in nicely formatted JSON:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\">export SPRING_APPLICATION_JSON='<span class=\"token punctuation\">{</span>\n  <span class=\"token key atrule\">\"maven\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token key atrule\">\"local-repository\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"local\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token key atrule\">\"remote-repositories\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token key atrule\">\"repo1\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token key atrule\">\"url\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"https://repo1\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token key atrule\">\"auth\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token key atrule\">\"username\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"repo1user\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token key atrule\">\"password\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"repo1pass\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token key atrule\">\"repo2\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token key atrule\">\"url\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"https://repo2\"</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token key atrule\">\"proxy\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token key atrule\">\"host\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"proxyhost\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token key atrule\">\"port\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">9018</span><span class=\"token punctuation\">,</span>\n      <span class=\"token key atrule\">\"auth\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token key atrule\">\"username\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"proxyuser\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token key atrule\">\"password\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"proxypass\"</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>'</code></pre></div>\n      </div><div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>Depending on the Spring Cloud Data Flow server implementation, you may have to pass the environment properties by using the platform specific environment-setting capabilities. For instance, in Cloud Foundry,\nyou would pass them as <code class=\"language-text\">cf set-env &lt;your app> SPRING_APPLICATION_JSON '{...</code>.</p></div></div></div></div>\n<div class=\"question-block\" id=\"debuglogs\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How do I enable DEBUG logs for platform deployments?</p></div><div class=\"answer \"><p>Spring Cloud Data Flow builds upon <a href=\"https://github.com/spring-cloud/spring-cloud-deployer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spring Cloud Deployer</a> SPI, and the platform-specific dataflow server uses the respective <a href=\"https://github.com/spring-cloud?utf8=%E2%9C%93&#x26;q=spring-cloud-deployer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">SPI implementations</a>.\nSpecifically, if we were to troubleshoot deployment specific issues, such as network errors, it would be useful to enable the DEBUG logs at the underlying deployer and the libraries used by it.</p><p>To enable DEBUG logs for the <a href=\"https://github.com/spring-cloud/spring-cloud-deployer-local\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">local-deployer</a>, start the server as follows:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">java -jar <span class=\"token operator\">&lt;</span>dataflow-server<span class=\"token operator\">></span>.jar --logging.level.org.springframework.cloud.deployer.spi.local<span class=\"token operator\">=</span>DEBUG</code></pre></div>\n      </div><p>(where <code class=\"language-text\">org.springframework.cloud.deployer.spi.local</code> is the global package for everything local-deployer\nrelated.)</p><p>To enable DEBUG logs for the <a href=\"https://github.com/spring-cloud/spring-cloud-deployer-cloudfoundry\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">cloudfoundry-deployer</a>, set the following environment variable and, after restaging the dataflow server, you can see more logs around request and response and see detailed stack traces for failures.\nThe cloudfoundry deployer uses <a href=\"https://github.com/cloudfoundry/cf-java-client\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">cf-java-client</a>, so you must also enable DEBUG logs for this library.</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cf set-env dataflow-server JAVA_OPTS <span class=\"token string\">'-Dlogging.level.cloudfoundry-client=DEBUG'</span>\ncf restage dataflow-server</code></pre></div>\n      </div><p>(where <code class=\"language-text\">cloudfoundry-client</code> is the global package for everything <code class=\"language-text\">cf-java-client</code> related.)</p><p>To review Reactor logs, which are used by the <code class=\"language-text\">cf-java-client</code>, then the following commad would be helpful:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cf set-env dataflow-server JAVA_OPTS <span class=\"token string\">'-Dlogging.level.cloudfoundry-client=DEBUG -Dlogging.level.reactor.ipc.netty=DEBUG'</span>\ncf restage dataflow-server</code></pre></div>\n      </div><p>(where <code class=\"language-text\">reactor.ipc.netty</code> is the global package for everything <code class=\"language-text\">reactor-netty</code> related.)</p><div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>Similar to the <code class=\"language-text\">local-deployer</code> and <code class=\"language-text\">cloudfoundry-deployer</code> options as discussed above, there are equivalent settings available for Kubernetes.\nSee the respective link:<a href=\"https://github.com/spring-cloud?utf8=%E2%9C%93&#x26;q=spring-cloud-deployer%5BSPI\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/spring-cloud?utf8=%E2%9C%93&#x26;q=spring-cloud-deployer[SPI</a> implementations] for more detail about the packages to configure for logging.</p></div></div></div></div>\n<div class=\"question-block\" id=\"debugapps\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How do I enable DEBUG logs for application deployments?</p></div><div class=\"answer \"><p>The streaming applications in Spring Cloud Data Flow are Spring Cloud Stream applications, which are in turn based on Spring Boot. They can be independently setup with logging configurations.</p><p>For instance, if you must troubleshoot the <code class=\"language-text\">header</code> and <code class=\"language-text\">payload</code> specifics that are being passed around source, processor, and sink channels, you should deploy the stream with the following options:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>stream create foo --definition <span class=\"token string\">\"http --logging.level.org.springframework.integration=DEBUG | transform --logging.level.org.springframework.integration=DEBUG | log --logging.level.org.springframework.integration=DEBUG\"</span> --deploy</code></pre></div>\n      </div><p>(where <code class=\"language-text\">org.springframework.integration</code> is the global package for everything Spring Integration related,\nwhich is responsible for messaging channels.)</p><p>These properties can also be specified with <code class=\"language-text\">deployment</code> properties when deploying the stream, as follows:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>stream deploy foo --properties <span class=\"token string\">\"app.*.logging.level.org.springframework.integration=DEBUG\"</span></code></pre></div>\n      </div></div></div>\n<div class=\"question-block\" id=\"remotedebug\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How do I remote debug deployed applications?</p></div><div class=\"answer \"><p>The Data Flow local server lets you debug the deployed applications.\nThis is accomplished by enabling the remote debugging feature of the JVM through deployment properties, as shown in the following example:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">stream deploy --name mystream --properties <span class=\"token string\">\"deployer.fooApp.local.debugPort=9999\"</span></code></pre></div>\n      </div><p>The preceding example starts the <code class=\"language-text\">fooApp</code> application in debug mode, allowing a remote debugger to be attached on port 9999.\nBy default, the application starts in a â€™suspendâ€™ mode and waits for the remote debug session to be attached (started). Otherwise, you can provide an additional <code class=\"language-text\">debugSuspend</code> property with value <code class=\"language-text\">n</code>.</p><p>Also, when there is more then one instance of the application, the debug port for each instance is the value of <code class=\"language-text\">debugPort</code> + instanceId.</p><div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>Unlike other properties you must NOT use a wildcard for the application name, since each application must use a unique debug port.</p></div></div></div></div>\n<div class=\"question-block\" id=\"aggregatelogs\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Is it possible to aggregate Local deployments into a single log?</p></div><div class=\"answer \"><p>Given that each application is a separate process that maintains its own set of logs, accessing individual logs could be a bit inconvenient, especially in the early stages of development, when logs are accessed more often.\nSince it is also a common pattern to rely on a local SCDF Server that deploys each application as a local JVM process, you can redirect the stdout and stdin from the deployed applications to the parent process.\nThus, with a local SCDF Server, the application logs appear in the logs of the running local SCDF Server.</p><p>Typically when you deploy the stream, you see something resembling the following in the server logs:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">017-06-28 09:50:16.372  INFO <span class=\"token number\">41161</span> --- <span class=\"token punctuation\">[</span>nio-9393-exec-7<span class=\"token punctuation\">]</span> o.s.c.d.spi.local.LocalAppDeployer       <span class=\"token builtin class-name\">:</span> Deploying app with deploymentId mystream.myapp instance <span class=\"token number\">0</span>.\n   Logs will be <span class=\"token keyword\">in</span> /var/folders/l2/63gcnd9d7g5dxxpjbgr0trpw0000gn/T/spring-cloud-dataflow-5939494818997196225/mystream-1498661416369/mystream.myapp</code></pre></div>\n      </div><p>However, by setting <code class=\"language-text\">local.inheritLogging=true</code> as a deployment property, you can see the following:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">017-06-28 09:50:16.372  INFO <span class=\"token number\">41161</span> --- <span class=\"token punctuation\">[</span>nio-9393-exec-7<span class=\"token punctuation\">]</span> o.s.c.d.spi.local.LocalAppDeployer       <span class=\"token builtin class-name\">:</span> Deploying app with deploymentId mystream.myapp instance <span class=\"token number\">0</span>.\n   Logs will be inherited.</code></pre></div>\n      </div><p>After that, the application logs appear alongside the server logs, as shown in the following example:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">stream deploy --name mystream --properties <span class=\"token string\">\"deployer.*.local.inheritLogging=true\"</span></code></pre></div>\n      </div><p>The preceding stream definition enables log redirection for each application in the stream.\nThe following stream definition enables log redirection for only the application named â€˜my appâ€™.</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">stream deploy --name mystream --properties <span class=\"token string\">\"deployer.myapp.local.inheritLogging=true\"</span></code></pre></div>\n      </div><p>Likewise, you can use the same option to redirect and aggregate all logs for the launched Task applications as well. The property is the same for Tasks, too.</p><p>NOTE: Log redirect is only supported with <a href=\"https://github.com/spring-cloud/spring-cloud-deployer-local\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">local-deployer</a>.</p></div></div>\n<div class=\"question-block\" id=\"predictableIP\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How can I get predictable Route/URL/IPAddress for a given streaming application?</p></div><div class=\"answer \"><p>To get a static and predictable IP Address for a given application, you can define an explicit service of type <code class=\"language-text\">LoadBalancer</code>\nand leverage the label selector feature in Kubernetes to route the traffic through the assigned static IP Address.</p><p>Here's an example of the <code class=\"language-text\">LoadBalancer</code> deployment:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Service\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> foo<span class=\"token punctuation\">-</span>lb\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> kafkazone\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token number\">80</span>\n      <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> http\n      <span class=\"token key atrule\">targetPort</span><span class=\"token punctuation\">:</span> <span class=\"token number\">8080</span>\n  <span class=\"token key atrule\">selector</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">FOOZ</span><span class=\"token punctuation\">:</span> BAR<span class=\"token punctuation\">-</span>APP\n  <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> LoadBalancer</code></pre></div>\n      </div><p>This deployment would produce a static IP Address. Let's say, for example, the IP address of <code class=\"language-text\">foo-lb</code> is: \"10.20.30.40\".</p><p>Now when you deploy the stream, you can attach a label selector to the desired application [e.g., deployer.<yourapp>.kubernetes.deploymentLabels=FOOZ: BAR-APP],\nso all the incoming traffic to \"10.20.30.40\" will automatically be received by the \"yourapp\".</p><p>In this setup, even if the app is rolling-upgraded or when the stream is redeployed/updated in SCDF, the static IP Address\nwill remain unchanged, and the upstream or downstream traffic can rely on that.</p></div></div>\n<h2 id=\"streaming\" style=\"position:relative;\"><a href=\"#streaming\" aria-label=\"streaming permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Streaming</h2>\n<div class=\"question-block\" id=\"connectexistingrabbit\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Can I connect to existing RabbitMQ queues?</p></div><div class=\"answer \"><p>Follow the steps in the <a href=\"https://cloud.spring.io/spring-cloud-static/spring-cloud-stream-binder-rabbit/2.2.0.RC1/spring-cloud-stream-binder-rabbit.html#_using_existing_queuesexchanges\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">reference guide</a> to connect with existing RabbitMQ queues.</p></div></div>\n<div class=\"question-block\" id=\"kafkacompatibility\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>What is the Apache Kafka versus Spring Cloud Stream compatibility?</p></div><div class=\"answer \"><p>See the <a href=\"https://github.com/spring-cloud/spring-cloud-stream/wiki/Kafka-Client-Compatibility\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">compatibility matrix</a> in the Wiki.</p></div></div>\n<div class=\"question-block\" id=\"lifecycle\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Can I manage binding lifecycles?</p></div><div class=\"answer \"><p>By default, bindings are started automatically when the application is initialized.\nBindings implement the Spring <code class=\"language-text\">SmartLifecycle</code> interface.\n<code class=\"language-text\">SmartLifecycle</code> allows beans to be started in phases.\nProducer bindings are started in an early phase (<code class=\"language-text\">Integer.MIN_VALUE + 1000</code>).\nConsumer bindings are started in a late phase (<code class=\"language-text\">Integer.MAX_VALUE - 1000</code>).\nThis leaves room in the spectrum such that user beans implementing <code class=\"language-text\">SmartLifecycle</code> can be started before producer bindings, after consumer bindings, or anywhere in between.</p><p>You can disable auto-startup by setting the consumer or producer <code class=\"language-text\">autoStartup</code> property to <code class=\"language-text\">false</code>.</p><p>Binding lifecycles can be visualized and controlled using Boot actuators; see <a href=\"https://cloud.spring.io/spring-cloud-static/spring-cloud-stream/current/reference/html/spring-cloud-stream.html#binding_visualization_control\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Binding visualization and control</a>.</p><p>You can also invoke the actuator endpoint programmatically, using the binding name, as follows:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\"><span class=\"token annotation punctuation\">@Autowired</span>\n<span class=\"token keyword\">private</span> <span class=\"token class-name\">BindingsEndpoint</span> endpoint<span class=\"token punctuation\">;</span>\n\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n    bindings<span class=\"token punctuation\">.</span><span class=\"token function\">changeState</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"myFunction-in-0\"</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">State</span><span class=\"token punctuation\">.</span>STARTED<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n      </div><p>This will start a previously stopped (or <code class=\"language-text\">autoStartup=false</code>) binding called <code class=\"language-text\">myFunction-in-0</code>.\nTo stop a running binding, use <code class=\"language-text\">State.STOPPED</code>.\nSome binders, e.g. Kafka, also support <code class=\"language-text\">State.PAUSED</code> and <code class=\"language-text\">State.RESUMED</code> for consumer bindings.</p><p>Since the <code class=\"language-text\">BindingsEndpoint</code> is part of the actuator infrastructure, you must enable actuator support as described in <a href=\"https://cloud.spring.io/spring-cloud-static/spring-cloud-stream/current/reference/html/spring-cloud-stream.html#binding_visualization_control\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Binding visualization and control</a>.</p></div></div>\n<h2 id=\"batch\" style=\"position:relative;\"><a href=\"#batch\" aria-label=\"batch permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Batch</h2>\n<div class=\"question-block\" id=\"ctr\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>What is a Composed Task Runner (CTR)?</p></div><div class=\"answer \"><p>The <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.3/reference/htmlsingle/#spring-cloud-dataflow-composed-tasks\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Composed Tasks</a> feature in Spring Cloud Data Flow (SCDF) delegates the running of the composed task to a separate application, named the Composed Task Runner (CTR).\nThe CTR orchestrates the launching of tasks (which are defined in the composed task graph).\nThe Composed Task Runner (CTR) parses the graph DSL and, for each node in the graph, runs a RESTful call against a specified Spring Cloud Data Flow instance to launch the associated task definition.\nFor each task definition that is run, the Composed Task Runner polls the database to verify that the task completed.\nOnce a task is complete, the Composed Task Runner either continues to the next task in the graph or fails based on how the DSL specified that the sequence of tasks should be run.</p></div></div>\n<div class=\"question-block\" id=\"restartjob\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>How do I restart a Spring Batch Job from the beginning rather than from where it failed?</p></div><div class=\"answer \"><p>In short, you need to create a new Job Instance for the new task launch. You can do so by changing an existing identifying job parameter or by adding a new identifying job parameter on the next task launch. The following example shows a typical task launch:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">task launch myBatchApp --arguments=\"team=yankees\"</code></pre></div>\n      </div><p>Assuming that the preceding task launch fails, we can launch the task again, and a new job instance is created if we change the value of the <code class=\"language-text\">team</code> parameter, as the following example shows:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">task launch myBatchApp --arguments=\"team=cubs\"</code></pre></div>\n      </div><p>However, the preferred way is to write your task or batch application such that it can handle being restarted with a new job instance. One way to do this is to set a <code class=\"language-text\">JobParamsIncrementer</code> for your batch job, as discussed in the Spring Batch <a href=\"https://docs.spring.io/spring-batch/trunk/reference/html/configureJob.html#JobParametersIncrementer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">reference guide</a>.</p></div></div>\n<div class=\"question-block\" id=\"taskdidnotterminate\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>Why doesn't my task execution show an end time?</p></div><div class=\"answer \"><p>There are 3 reasons that this may occur:</p><ol>\n<li>Your application is in fact still running. You can view the task's log via the task execution detail page for that task execution, to check the status.</li>\n<li>Your application was terminated using a SIG-KILL. In that case Spring Cloud Task did not get a signal that the application was terminating, rather the task's process was killed.</li>\n<li>You are running a Spring Cloud Task application where the context is held open (for example: if you are using a TaskExecutor). In these cases you can set the <code class=\"language-text\">spring.cloud.task.closecontext_enabled</code> property to <code class=\"language-text\">true</code> when launching your task. This will close the application's context once the task is complete. Thus allowing the application to terminate and record the end time.</li>\n</ol></div></div>\n<div class=\"question-block\" id=\"useexistingbatchtables\"><div class=\"question \" onClick=\"toggleQuestion(event)\"><p>I want to migrate from Spring Batch Admin to Spring Cloud Data Flow. Can I use the existing database that is already used by the Spring Batch jobs?</p></div><div class=\"answer \"><p>No. Spring Cloud Data Flow creates its own schema including the Spring Batch tables.\nTo allow Spring Cloud Data Flow to show the status of Spring Batch Job executions via the dashboard or shell, your Spring Batch Apps need to use the same \"datasource\" configuration as Spring Cloud Data Flow.</p></div></div>","headings":[{"value":"Frequently Asked Questions","depth":1},{"value":"Application Starters","depth":2},{"value":"Data Flow","depth":2},{"value":"Streaming","depth":2},{"value":"Batch","depth":2}],"fields":{"path":"/docs/2.6.x/resources/faq/","version":"2.6.x","category":"resources","sourcePath":"pages/7-resources/3-faq.md"},"frontmatter":{"title":"Frequently Asked Questions","summary":null,"path":"resources/faq/","toc":null,"prevNext":null}}},"pageContext":{"slug":"/docs/2.6.x/resources/faq/","version":"2.6.x","versionPath":""}},"staticQueryHashes":["2044043181"]}