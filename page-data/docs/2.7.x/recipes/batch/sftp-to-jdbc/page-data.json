{"componentChunkName":"component---src-templates-documentation-js","path":"/docs/2.7.x/recipes/batch/sftp-to-jdbc/","result":{"data":{"pages":{"edges":[{"node":{"id":"eee3a014-9771-5453-a01c-87ed393da8db","fields":{"path":"/docs/2.7.x/installation/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Installation","description":"How to install Data Flow","path":"installation/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"eab5ffe2-52cd-5634-8941-f029ef123151","fields":{"path":"/docs/2.7.x/installation/local/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Local Machine","description":"Local Machine Installation Guide","path":"installation/local/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"196e8bc2-bad4-5240-98b1-67583cc214cc","fields":{"path":"/docs/2.7.x/installation/local/docker/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Docker Compose","description":"Installation using Docker Compose","path":"installation/local/docker","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7c174605-0ab0-505a-929a-c1baf712e81c","fields":{"path":"/docs/2.7.x/installation/local/docker-customize/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Docker Compose Customization","description":"Customize the Docker Compose installation","path":"installation/local/docker-customize","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3a4b5691-3d82-5916-9eca-a4c612a4f2d4","fields":{"path":"/docs/2.7.x/installation/local/manual/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Manual","description":"Manual installation","path":"installation/local/manual","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3857707f-5c3d-54db-aa5f-0bb8e821916c","fields":{"path":"/docs/2.7.x/installation/cloudfoundry/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry","description":"Data Flow Cloud Foundry Installation Guide","path":"installation/cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"291cc3d8-dd50-5fbf-a7f4-750046cc1f9b","fields":{"path":"/docs/2.7.x/installation/cloudfoundry/cf-cli/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry CLI","description":"Install using the Cloud Foundry CLI","path":"installation/cloudfoundry/cf-cli","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"26e2959e-8c69-5564-8e8b-b0b8c3a2ae50","fields":{"path":"/docs/2.7.x/installation/cloudfoundry/cf-local/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Running locally","description":"Configure the local servers to deploy to Cloud Foundry","path":"installation/cloudfoundry/cf-local","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8bc9e681-dfbf-5d7c-9ffa-451fd0e05124","fields":{"path":"/docs/2.7.x/installation/kubernetes/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Kubernetes","description":"Data Flow Kubernetes Installation Guide","path":"installation/kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1425f3ce-7c80-5aca-8c27-0907f18ea218","fields":{"path":"/docs/2.7.x/installation/kubernetes/creating-a-cluster/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Creating a Cluster","description":"Creating a Kubernetes Cluster","path":"installation/kubernetes/creating-a-cluster","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"28bd9f2a-a434-5ad9-9894-3da440ce0bad","fields":{"path":"/docs/2.7.x/installation/kubernetes/helm/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Helm","description":"Installation using Helm","path":"installation/kubernetes/helm","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"975d68c5-4136-50a3-af13-8c0ea5ad374a","fields":{"path":"/docs/2.7.x/installation/kubernetes/kubectl/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"kubectl","description":"Installation using kubectl","path":"installation/kubernetes/kubectl","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3a393f33-ed0b-5cc3-9615-bb190b8c4608","fields":{"path":"/docs/2.7.x/installation/kubernetes/compatibility/","version":"2.7.x","category":"installation"},"frontmatter":{"title":"Kubernetes Compatibility","description":"Compatibility with Kubernetes Versions","path":"installation/kubernetes/compatibility","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d04dc89e-ba92-5163-9ad4-260014426f50","fields":{"path":"/docs/2.7.x/concepts/","version":"2.7.x","category":"concepts"},"frontmatter":{"title":"Concepts","description":"Core Concepts in Spring Cloud Data Flow","path":"concepts/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b0a3794a-5e81-5866-b6d7-3869a20ff935","fields":{"path":"/docs/2.7.x/concepts/architecture/","version":"2.7.x","category":"concepts"},"frontmatter":{"title":"Architecture","description":"Introduction to Data Flow's Architecture.","path":"concepts/architecture/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"973f8359-4e8f-55fa-8520-d5af94988795","fields":{"path":"/docs/2.7.x/concepts/streams/","version":"2.7.x","category":"concepts"},"frontmatter":{"title":"Stream Processing","description":"Stream Processing Framework and Concepts","path":"concepts/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c66b31b6-7429-5524-a17c-814d15654c08","fields":{"path":"/docs/2.7.x/concepts/batch-jobs/","version":"2.7.x","category":"concepts"},"frontmatter":{"title":"Batch Processing","description":"Batch Processing Framework and Concepts","path":"concepts/batch-jobs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3b107fb2-db29-521b-9e74-5f7548a3839a","fields":{"path":"/docs/2.7.x/concepts/monitoring/","version":"2.7.x","category":"concepts"},"frontmatter":{"title":"Monitoring","description":"Runtime monitoring of Servers, Stream and Task data pipelines","path":"concepts/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f0aae70b-27d8-57ed-bf41-46ae254e126d","fields":{"path":"/docs/2.7.x/concepts/tooling/","version":"2.7.x","category":"concepts"},"frontmatter":{"title":"Tooling","description":"Dashboard and Shell","path":"concepts/tooling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"757ef177-f20e-52ac-b6fc-ac63c7e298ab","fields":{"path":"/docs/2.7.x/stream-developer-guides/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Developer guides ","description":"Learn how to create Streaming data pipelines using prebuilt microservices or create your own.","path":"stream-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"135a71fe-1dcb-579e-b7b3-479fcff9babb","fields":{"path":"/docs/2.7.x/stream-developer-guides/getting-started/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Stream Processing","path":"stream-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b7b2f7a3-15b3-5e7c-a39b-e4bfc4c01269","fields":{"path":"/docs/2.7.x/stream-developer-guides/getting-started/stream/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing","description":"Create and deploy a streaming data pipeline using prebuilt applications on your Local Machine","path":"stream-developer-guides/getting-started/stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"92f0c90c-3fcb-5ca7-be88-1ba5e867d899","fields":{"path":"/docs/2.7.x/stream-developer-guides/streams/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Development","description":"Stream Processing Developer Guide","path":"stream-developer-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5c624675-7855-5787-a7cb-d22c170de3bf","fields":{"path":"/docs/2.7.x/stream-developer-guides/streams/standalone-stream-rabbitmq/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on RabbitMQ","description":"Create your own microservices for Stream processing using RabbitMQ and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"646d872f-8e19-5d51-bfb6-430129dac79f","fields":{"path":"/docs/2.7.x/stream-developer-guides/streams/standalone-stream-kafka/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on Apache Kafka","description":"Create your own microservices for Stream processing using Apache Kafka and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dd262d5e-7732-5037-81f1-5308c29ae1ba","fields":{"path":"/docs/2.7.x/stream-developer-guides/streams/data-flow-stream/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing using Spring Cloud Data Flow","description":"Create and Deploy a Stream Processing Pipeline using Spring Cloud Data Flow","path":"stream-developer-guides/streams/data-flow-stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3331aa76-d835-58ac-9752-9fad2feda6d6","fields":{"path":"/docs/2.7.x/stream-developer-guides/streams/stream-other-binders/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Spring Application Development on other Messaging Middleware","description":"Create your own microservices for Stream processing using other messaging middleware such as Google Pub/Sub, Amazon Kinesis, and Solace JMS","path":"stream-developer-guides/streams/stream-other-binders/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7ba6206e-09fa-5ecb-9b2c-4814fd901b24","fields":{"path":"/docs/2.7.x/stream-developer-guides/programming-models/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Programming Models","description":"Programming models","path":"stream-developer-guides/programming-models/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"81d9c588-e70e-5125-b79c-68579c80e47b","fields":{"path":"/docs/2.7.x/stream-developer-guides/continuous-delivery/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery","description":"CD using Skipper","path":"stream-developer-guides/continuous-delivery/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2001ffac-0690-517e-9796-f05510da006b","fields":{"path":"/docs/2.7.x/stream-developer-guides/continuous-delivery/cd-basics/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery of streaming applications","description":"Continuous Delivery of Streaming applications","path":"stream-developer-guides/continuous-delivery/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0a1cd47e-78a6-5a46-9568-16fd5ea3a301","fields":{"path":"/docs/2.7.x/stream-developer-guides/troubleshooting/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Streams","path":"stream-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"69f9787c-3518-5fc5-bb49-77d8f311be07","fields":{"path":"/docs/2.7.x/stream-developer-guides/troubleshooting/debugging-stream-apps/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream Applications","description":"Debugging Stream Applications outside of Data Flow","path":"stream-developer-guides/troubleshooting/debugging-stream-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d34cbb97-01ac-5155-a492-394fd525205f","fields":{"path":"/docs/2.7.x/stream-developer-guides/troubleshooting/debugging-scdf-streams/","version":"2.7.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream applications deployed by Data Flow","description":"Debugging Data Flow Stream deployments","path":"stream-developer-guides/troubleshooting/debugging-scdf-streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"797b83f0-93d0-5f1c-ac20-97cfbfde9096","fields":{"path":"/docs/2.7.x/batch-developer-guides/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"batch-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8be5a7cb-a318-5615-8e8b-c6cefe64f1df","fields":{"path":"/docs/2.7.x/batch-developer-guides/getting-started/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Batch","path":"batch-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ca18515a-426f-5684-b59c-d0e98cafee31","fields":{"path":"/docs/2.7.x/batch-developer-guides/getting-started/task/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Task Processing","description":"Create and deploy a simple Task pipeline using a prebuilt Task application on your local machine","path":"batch-developer-guides/getting-started/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d6a825cb-16a7-5363-9dd5-60479109422e","fields":{"path":"/docs/2.7.x/batch-developer-guides/batch/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Development","description":"Batch Developer Guide","path":"batch-developer-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e1d9be36-cd72-5295-8959-d2b38c016724","fields":{"path":"/docs/2.7.x/batch-developer-guides/batch/spring-task/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"batch-developer-guides/batch/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4ee00a15-65b0-5eff-9c60-f803bf908888","fields":{"path":"/docs/2.7.x/batch-developer-guides/batch/spring-batch/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"batch-developer-guides/batch/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c164828f-9e76-5158-9492-a7317fba07da","fields":{"path":"/docs/2.7.x/batch-developer-guides/batch/data-flow-simple-task/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b3e03f06-4e2f-5042-b1af-0aa432ccbd19","fields":{"path":"/docs/2.7.x/batch-developer-guides/batch/data-flow-spring-batch/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"batch-developer-guides/batch/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"06fa5d76-6423-5ec1-9296-0a092763291c","fields":{"path":"/docs/2.7.x/batch-developer-guides/batch/data-flow-composed-task/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"batch-developer-guides/batch/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"348f0cd0-bcc4-5cad-abc9-c394c2d3f02e","fields":{"path":"/docs/2.7.x/batch-developer-guides/batch/data-flow-simple-task-kubernetes/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"108f22ab-68b4-5a82-a67a-d9abc59704de","fields":{"path":"/docs/2.7.x/batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"80bd557d-4f2c-5073-abcc-46a73be56f00","fields":{"path":"/docs/2.7.x/batch-developer-guides/continuous-deployment/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"batch-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4cdfa41c-c91b-57d4-97a6-9c33955392fd","fields":{"path":"/docs/2.7.x/batch-developer-guides/continuous-deployment/cd-basics/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"batch-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cf58f7e3-b865-517f-b1a8-87fa9d384fea","fields":{"path":"/docs/2.7.x/batch-developer-guides/troubleshooting/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"batch-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ced7ce6b-4247-524c-bf2a-19f80f1fbf86","fields":{"path":"/docs/2.7.x/batch-developer-guides/troubleshooting/debugging-task-apps/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"batch-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4d9a3964-bded-588e-9dfb-38eedaffe33d","fields":{"path":"/docs/2.7.x/batch-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"2.7.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"batch-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1280021a-9058-5ce9-9867-6e1b5d34bf09","fields":{"path":"/docs/2.7.x/feature-guides/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Feature guides","description":"High level overview of Data Flow Features","path":"feature-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"15ae5986-ba38-5226-a08e-a77737c4a827","fields":{"path":"/docs/2.7.x/feature-guides/general/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"General","description":"General Features in Data Flow","path":"feature-guides/general/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"442ed7a6-1f8f-56aa-939b-ece49479d3be","fields":{"path":"/docs/2.7.x/feature-guides/general/application-metadata/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Application Metadata","description":"Create and use application properties metadata","path":"feature-guides/general/application-metadata/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e8e4210e-5f26-5868-9dcd-a78f9c7b22b5","fields":{"path":"/docs/2.7.x/feature-guides/general/server-monitoring/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Server Monitoring","description":"Monitoring Data Flow and Skipper servers","path":"feature-guides/general/server-monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8bb14d4b-d140-5827-86a2-e55376e58fdb","fields":{"path":"/docs/2.7.x/feature-guides/streams/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Streams","description":"Stream Features in Data Flow","path":"feature-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5d22cd0c-309d-5cde-927f-d706450de472","fields":{"path":"/docs/2.7.x/feature-guides/streams/deployment-properties/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a stream deployment with deployment property overrides","path":"feature-guides/streams/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"068535bc-e005-5e5e-876f-aa74b5f8ae78","fields":{"path":"/docs/2.7.x/feature-guides/streams/function-composition/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Composing Functions","description":"Daisy-chain Java functions in an existing Spring Cloud Stream application","path":"feature-guides/streams/function-composition/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c6447503-7c39-5bda-96c0-d1a80eee31de","fields":{"path":"/docs/2.7.x/feature-guides/streams/named-destinations/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Named Destinations","description":"Use the Named Destinations to interact with the Topics/Queues directly","path":"feature-guides/streams/named-destinations/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a4f60c5d-8a33-5575-afd1-d71f8113bcf0","fields":{"path":"/docs/2.7.x/feature-guides/streams/monitoring/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Stream Monitoring","description":"Monitoring streaming data pipelines with Prometheus and InfluxDB","path":"feature-guides/streams/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c36a23d4-ad9b-5fa4-bb73-42924be993f8","fields":{"path":"/docs/2.7.x/feature-guides/streams/stream-application-dsl/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Stream Application DSL","description":"Learn how to use the Stream Application DSL","path":"feature-guides/streams/stream-application-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d9e9e114-49ef-5c91-9451-494e6eecde82","fields":{"path":"/docs/2.7.x/feature-guides/streams/labels/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Labeling Applications","description":"Label the stream applications to uniquely interact with them","path":"feature-guides/streams/labels/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"471e8b01-2d04-5515-b325-bd7daa4741a5","fields":{"path":"/docs/2.7.x/feature-guides/streams/application-count/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Application Count","description":"Initiate stream deployment with multiple application instances","path":"feature-guides/streams/application-count/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4afa37d5-01c1-5ba0-898c-20c724b792f9","fields":{"path":"/docs/2.7.x/feature-guides/streams/fanin-fanout/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Fan-in and Fan-out","description":"Publish and subscribe to multiple destinations using the fan-in and fan-out capabilities","path":"feature-guides/streams/fanin-fanout/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"245052fa-6adb-5e68-bf88-c8213cea1d82","fields":{"path":"/docs/2.7.x/feature-guides/streams/partitioning/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Data Partitioning","description":"Learn more about data partitioning support to build stateful streaming data pipelines","path":"feature-guides/streams/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"087c59c2-9ccd-534e-9ab3-57f551f1de1c","fields":{"path":"/docs/2.7.x/feature-guides/streams/scaling/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Scaling","description":"Scaling streaming data pipeline with Spring Cloud Data Flow","path":"feature-guides/streams/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1628d58f-9211-5852-9e24-d10a7e9c7045","fields":{"path":"/docs/2.7.x/feature-guides/streams/java-dsl/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Stream Java DSL","description":"Programmatically create streams using the Java DSL","path":"feature-guides/streams/java-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2c775a63-fff1-5b6c-bb6a-65a0563eb2de","fields":{"path":"/docs/2.7.x/feature-guides/streams/taps/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Tapping a Stream","description":"Create a stream from another stream without interrupting the data processing","path":"feature-guides/streams/taps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"68787153-aabb-56d9-b945-1d8402f3ec6e","fields":{"path":"/docs/2.7.x/feature-guides/batch/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Batch","description":"Batch Features in Data Flow","path":"feature-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e81852b5-fbdb-52f8-a7b3-8dbb43102833","fields":{"path":"/docs/2.7.x/feature-guides/batch/deployment-properties/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a Batch deployment with deployment property overrides","path":"feature-guides/batch/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4ef63856-08b0-5334-8ef0-cef7ac4b0935","fields":{"path":"/docs/2.7.x/feature-guides/batch/scheduling/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Scheduling Batch Jobs","description":"Learn how to schedule Batch Jobs","path":"feature-guides/batch/scheduling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"60012f0d-502f-532c-90fb-3aac85eec3d2","fields":{"path":"/docs/2.7.x/feature-guides/batch/partitioning/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Remote Partitioned Batch Job","description":"Learn more about partitioning support for Batch Jobs","path":"feature-guides/batch/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"99a70bd6-3401-5f98-92f5-8c069e41054c","fields":{"path":"/docs/2.7.x/feature-guides/batch/monitoring/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Task Monitoring","description":"Monitoring task data pipelines with InfluxDB","path":"feature-guides/batch/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9fd7195d-14b3-56a5-899c-a99d0f424f81","fields":{"path":"/docs/2.7.x/feature-guides/batch/restarting/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Restarting Batch Jobs","description":"Learn how to restart Batch Jobs","path":"feature-guides/batch/restarting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2b63a28d-7084-52e1-aaab-a996b89dcb6b","fields":{"path":"/docs/2.7.x/feature-guides/batch/composed-task/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Composed Tasks","description":"Learn how to create and manage composed tasks","path":"feature-guides/batch/composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e67c2daa-d275-540d-92de-10204a3c2c41","fields":{"path":"/docs/2.7.x/feature-guides/batch/java-dsl/","version":"2.7.x","category":"feature-guides"},"frontmatter":{"title":"Task Java DSL","description":"Programmatically create tasks using the Java DSL","path":"feature-guides/batch/java-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b4d63a13-d924-5860-b20d-8f226547c05c","fields":{"path":"/docs/2.7.x/recipes/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Recipes","description":"Recipes that help solve some common use-cases","path":"recipes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5f667296-10d7-5e27-99b8-e7272c2eb2ca","fields":{"path":"/docs/2.7.x/recipes/polyglot/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Polyglot","description":"Using multiple programming languages","path":"recipes/polyglot/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6877270c-cdea-5172-ba08-dc52957d9885","fields":{"path":"/docs/2.7.x/recipes/polyglot/processor/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Python Stream Processor","description":"Python Application as a Data Flow Stream Processor","path":"recipes/polyglot/processor/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"21be56a8-d3ce-584d-a6ca-75bf15d9b949","fields":{"path":"/docs/2.7.x/recipes/polyglot/task/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Python Task","description":"Create and Deploy a Python Task","path":"recipes/polyglot/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"af927f6a-0437-55db-909f-6088f2b1bcd4","fields":{"path":"/docs/2.7.x/recipes/polyglot/app/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Python Application","description":"Create and Deploy a Python Application in a Stream","path":"recipes/polyglot/app/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8409e91b-adec-59c4-be46-dcefecae3184","fields":{"path":"/docs/2.7.x/recipes/rabbitmq/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ","description":"RabbitMQ","path":"recipes/rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ac39e2be-74b5-55f4-a342-59faed10fda2","fields":{"path":"/docs/2.7.x/recipes/rabbitmq/rabbit-source-sink/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ as Source and Sink","description":"RabbitMQ as Source and Sink + RabbitMQ binder","path":"recipes/rabbitmq/rabbit-source-sink/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"227dbc1c-5e56-5b18-9325-d35866927cfe","fields":{"path":"/docs/2.7.x/recipes/kafka/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Apache Kafka","description":"Kafka","path":"recipes/kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"adbed07d-1f6c-5eba-94db-b9e8237f275c","fields":{"path":"/docs/2.7.x/recipes/kafka/ext-kafka-cluster-cf/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"External Kafka Cluster","description":"Connect to an external Kafka Cluster from Cloud Foundry","path":"recipes/kafka/ext-kafka-cluster-cf/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8d97f04c-755b-5137-9a3f-180c224f53db","fields":{"path":"/docs/2.7.x/recipes/kinesis/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis","description":"Amazon Kinesis","path":"recipes/kinesis/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"159b1fd2-70ed-56fc-a43e-8081173b1c4c","fields":{"path":"/docs/2.7.x/recipes/kinesis/simple-producer-consumer/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis Binder","description":"A sample of Spring Cloud Stream + Amazon Kinesis Binder in action","path":"recipes/kinesis/simple-producer-consumer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"06a64367-86c0-593c-a382-69ff62bcc957","fields":{"path":"/docs/2.7.x/recipes/multi-platform-deployment/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform Deployments","description":"Multiple Platform Deployments","path":"recipes/multi-platform-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8f4a8933-47bc-516a-832f-7211beb7dff3","fields":{"path":"/docs/2.7.x/recipes/multi-platform-deployment/multiple-platform-accounts/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Role of Multiple Platform Deployments","description":"A walk-through of multiple platform requirements and the configurations for Cloud Foundry and Kubernetes","path":"recipes/multi-platform-deployment/multiple-platform-accounts","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"466fec49-9d10-57b0-9716-133dbd517de5","fields":{"path":"/docs/2.7.x/recipes/multi-platform-deployment/multi-platform-task/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform support for Tasks","description":"Learn how to launch and schedule tasks across multiple platforms","path":"recipes/multi-platform-deployment/multi-platform-task","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ccec9f06-1632-54ba-933d-3bfaf05068d3","fields":{"path":"/docs/2.7.x/recipes/scaling/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Scaling","description":"Prometheus and Data Flow to autoscale streaming data pipelines","path":"recipes/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"213ff2ec-3b71-5717-9307-19dd3afd2d48","fields":{"path":"/docs/2.7.x/recipes/scaling/manual-scaling/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Manual Scaling","description":"Scale applications using SCDF Shell","path":"recipes/scaling/manual-scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e2fa5292-9260-572a-abec-665fe8c520ad","fields":{"path":"/docs/2.7.x/recipes/scaling/autoscaling/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Autoscaling","description":"Autoscale streaming data pipeline with SCDF and Prometheus","path":"recipes/scaling/autoscaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"43864d11-5c71-5601-9c83-5ef1ec7fbd04","fields":{"path":"/docs/2.7.x/recipes/batch/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Batch","description":"Using Spring Cloud Data Flow with Spring Batch","path":"recipes/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"03c3680a-a5d7-5e49-a573-2e8054dd0909","fields":{"path":"/docs/2.7.x/recipes/batch/batch-only-mode/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Batch-only Mode","description":"Set up Spring Cloud Data Flow to use only batch and not streams","path":"recipes/batch/batch-only-mode/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ab8b2b1e-42cc-5e98-bc84-12832e6a0491","fields":{"path":"/docs/2.7.x/recipes/batch/sftp-to-jdbc/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"SFTP to JDBC","description":"Ingest Files from SFTP to a JDBC data store using Data Flow and Spring Batch","path":"recipes/batch/sftp-to-jdbc/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ea424e0e-2a61-5fbb-9fa8-e3bc8df42090","fields":{"path":"/docs/2.7.x/recipes/functional-apps/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Using Functional Approach in Spring Cloud Stream applications","path":"recipes/functional-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b2c58aa7-eb00-5ec7-b919-f4f9755b9003","fields":{"path":"/docs/2.7.x/recipes/functional-apps/scst-function-bindings/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Configuring the Spring Cloud Stream Functional applications","path":"recipes/functional-apps/scst-function-bindings/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"66a6e478-a873-54f4-91ca-d331246bc08a","fields":{"path":"/docs/2.7.x/recipes/cloud-providers/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"Cloud Providers","description":"Using functionality provided by cloud providers","path":"recipes/cloud-providers/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8221dc2c-0823-5522-85bc-f080d6595544","fields":{"path":"/docs/2.7.x/recipes/cloud-providers/gke-regional-clusters/","version":"2.7.x","category":"recipes"},"frontmatter":{"title":"GKE Regional Clusters","description":"Deploying Spring Cloud Data Flow to a GKE Regional Cluster","path":"recipes/cloud-providers/gke-regional-clusters/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c3d0f438-9305-5c33-86cd-e25dcb88c393","fields":{"path":"/docs/2.7.x/resources/","version":"2.7.x","category":"resources"},"frontmatter":{"title":"Resources","description":"Sample Applications, References Docs, Videos, Blogs...","path":"resources/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7be3f83f-a55e-5dba-8957-611082e0cf47","fields":{"path":"/docs/2.7.x/resources/reference-docs/","version":"2.7.x","category":"resources"},"frontmatter":{"title":"Reference Documentation","description":"Collection of reference guides for Spring Cloud Data Flow","path":"resources/reference-docs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"75788cad-5d40-540b-ae73-4c271606e59c","fields":{"path":"/docs/2.7.x/resources/samples/","version":"2.7.x","category":"resources"},"frontmatter":{"title":"Samples","description":"Collection of samples","path":"resources/samples/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"96d2e185-f235-57f4-9085-fca1e2fe96e7","fields":{"path":"/docs/2.7.x/resources/faq/","version":"2.7.x","category":"resources"},"frontmatter":{"title":"Frequently Asked Questions","description":"","path":"resources/faq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ff401c6e-b2bf-54a3-896f-28830d14b829","fields":{"path":"/docs/2.7.x/applications/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"Applications","description":"Using stream and task applications","path":"applications/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0134982f-ed84-5daa-8b56-6395ecbafe3b","fields":{"path":"/docs/2.7.x/applications/migration/aggregator-processor/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"aggregator-processor Migration","description":"aggregator-processor Migration","path":"applications/migration/aggregator-processor","meta_title":null,"meta_description":null,"keywords":["application","migration","aggregator-processor"]}}},{"node":{"id":"0ae53cf4-61cf-5b5f-aafb-93faab40a61d","fields":{"path":"/docs/2.7.x/applications/migration/ftp-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"ftp-source Migration","description":"ftp-source Migration","path":"applications/migration/ftp-source","meta_title":null,"meta_description":null,"keywords":["application","migration","ftp-source"]}}},{"node":{"id":"b86953d3-06b4-511e-8ddb-f4c097eff246","fields":{"path":"/docs/2.7.x/applications/migration/header-enricher-processor/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"header-enricher-processor Migration","description":"header-enricher-processor Migration","path":"applications/migration/header-enricher-processor","meta_title":null,"meta_description":null,"keywords":["application","migration","header-enricher-processor"]}}},{"node":{"id":"1c5e2f11-d32f-50f4-a4b6-31d89a4d1e36","fields":{"path":"/docs/2.7.x/applications/migration/http-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"http-source Migration","description":"http-source Migration","path":"applications/migration/http-source","meta_title":null,"meta_description":null,"keywords":["application","migration","http-source"]}}},{"node":{"id":"64176607-5ec9-505c-a469-e78fe95325b8","fields":{"path":"/docs/2.7.x/applications/migration/cassandra-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"cassandra-sink Migration","description":"cassandra-sink Migration","path":"applications/migration/cassandra-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","cassandra-sink"]}}},{"node":{"id":"8431e91a-9a1e-5c13-ab20-1606beaea425","fields":{"path":"/docs/2.7.x/applications/migration/image-recognition-processor/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"image-recognition-processor Migration","description":"image-recognition-processor Migration","path":"applications/migration/image-recognition-processor","meta_title":null,"meta_description":null,"keywords":["application","migration","image-recognition-processor"]}}},{"node":{"id":"42ca2951-2f16-5ad9-b928-87c1fc2babf5","fields":{"path":"/docs/2.7.x/applications/migration/jdbc-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"jdbc-sink Migration","description":"jdbc-sink Migration","path":"applications/migration/jdbc-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","jdbc-sink"]}}},{"node":{"id":"08ccb87f-0822-5279-8535-955cc89f6e9d","fields":{"path":"/docs/2.7.x/applications/migration/jdbc-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"jdbc-source Migration","description":"jdbc-source Migration","path":"applications/migration/jdbc-source","meta_title":null,"meta_description":null,"keywords":["application","migration","jdbc-source"]}}},{"node":{"id":"031189cb-d78f-59a3-bc20-9f8907d61d9a","fields":{"path":"/docs/2.7.x/applications/migration/jms-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"jms-source Migration","description":"jms-source Migration","path":"applications/migration/jms-source","meta_title":null,"meta_description":null,"keywords":["application","migration","jms-source"]}}},{"node":{"id":"0c28079e-9858-51b4-8d3b-1897b8934273","fields":{"path":"/docs/2.7.x/applications/migration/load-generator-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"load-generator-source Migration","description":"load-generator-source Migration","path":"applications/migration/load-generator-source","meta_title":null,"meta_description":null,"keywords":["application","migration","load-generator-source"]}}},{"node":{"id":"ee0695a5-bb84-5352-b534-6531f3536888","fields":{"path":"/docs/2.7.x/applications/migration/log-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"log-sink Migration","description":"log-sink Migration","path":"applications/migration/log-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","log-sink"]}}},{"node":{"id":"54c6eadd-cbce-5c5b-bc4b-2af386fb18a1","fields":{"path":"/docs/2.7.x/applications/migration/mail-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"mail-source Migration","description":"mail-source Migration","path":"applications/migration/mail-source","meta_title":null,"meta_description":null,"keywords":["application","migration","mail-source"]}}},{"node":{"id":"d81cc5ca-6fbf-5c17-b6bf-84061d52e68d","fields":{"path":"/docs/2.7.x/applications/migration/mongodb-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"mongodb-sink Migration","description":"mongodb-sink Migration","path":"applications/migration/mongodb-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","mongodb-sink"]}}},{"node":{"id":"d2fe10eb-a007-5be7-9a5a-0b753575ed5f","fields":{"path":"/docs/2.7.x/applications/migration/cdc-debezium-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"cdc-debezium-source Migration","description":"cdc-debezium-source Migration","path":"applications/migration/cdc-debezium-source","meta_title":null,"meta_description":null,"keywords":["application","migration","cdc-debezium-source"]}}},{"node":{"id":"05fb3aa1-c140-52ad-8e2c-f3f655ebeb99","fields":{"path":"/docs/2.7.x/applications/migration/mongodb-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"mongodb-source Migration","description":"mongodb-source Migration","path":"applications/migration/mongodb-source","meta_title":null,"meta_description":null,"keywords":["application","migration","mongodb-source"]}}},{"node":{"id":"ffc14ad7-1acd-5a45-8f8e-c4ec5ea6dee4","fields":{"path":"/docs/2.7.x/applications/migration/mqtt-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"mqtt-sink Migration","description":"mqtt-sink Migration","path":"applications/migration/mqtt-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","mqtt-sink"]}}},{"node":{"id":"5da8ddcd-633b-5052-bfa2-382c21fab7ce","fields":{"path":"/docs/2.7.x/applications/migration/mqtt-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"mqtt-source Migration","description":"mqtt-source Migration","path":"applications/migration/mqtt-source","meta_title":null,"meta_description":null,"keywords":["application","migration","mqtt-source"]}}},{"node":{"id":"8ca34f6e-f1ea-50ad-af24-94f8a2937e5f","fields":{"path":"/docs/2.7.x/applications/migration/object-detection-processor/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"object-detection-processor Migration","description":"object-detection-processor Migration","path":"applications/migration/object-detection-processor","meta_title":null,"meta_description":null,"keywords":["application","migration","object-detection-processor"]}}},{"node":{"id":"e165eec4-4e9b-5758-ad8b-6fc9621fef73","fields":{"path":"/docs/2.7.x/applications/migration/pgcopy-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"pgcopy-sink Migration","description":"pgcopy-sink Migration","path":"applications/migration/pgcopy-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","pgcopy-sink"]}}},{"node":{"id":"dc2ee4d5-074d-51ed-916c-9522b43fe436","fields":{"path":"/docs/2.7.x/applications/migration/rabbit-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"rabbit-sink Migration","description":"rabbit-sink Migration","path":"applications/migration/rabbit-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","rabbit-sink"]}}},{"node":{"id":"0c72bc15-f7dc-5599-b721-f708db80ee08","fields":{"path":"/docs/2.7.x/applications/migration/rabbit-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"rabbit-source Migration","description":"rabbit-source Migration","path":"applications/migration/rabbit-source","meta_title":null,"meta_description":null,"keywords":["application","migration","rabbit-source"]}}},{"node":{"id":"4886adb1-8ab4-575f-8b42-6781f68241a1","fields":{"path":"/docs/2.7.x/applications/migration/router-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"router-sink Migration","description":"router-sink Migration","path":"applications/migration/router-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","router-sink"]}}},{"node":{"id":"ce0ca597-dcaf-58a8-928b-af1b46d5e88b","fields":{"path":"/docs/2.7.x/applications/migration/s3-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"s3-sink Migration","description":"s3-sink Migration","path":"applications/migration/s3-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","s3-sink"]}}},{"node":{"id":"e48485f8-b88e-55f5-9955-86ab65976980","fields":{"path":"/docs/2.7.x/applications/migration/s3-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"s3-source Migration","description":"s3-source Migration","path":"applications/migration/s3-source","meta_title":null,"meta_description":null,"keywords":["application","migration","s3-source"]}}},{"node":{"id":"30513c59-e110-5379-a21b-3cbeebb0cfb7","fields":{"path":"/docs/2.7.x/applications/migration/sftp-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"sftp-sink Migration","description":"sftp-sink Migration","path":"applications/migration/sftp-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","sftp-sink"]}}},{"node":{"id":"11f8e4d2-7cf8-5cc2-8529-85a5f635eb15","fields":{"path":"/docs/2.7.x/applications/migration/sftp-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"sftp-source Migration","description":"sftp-source Migration","path":"applications/migration/sftp-source","meta_title":null,"meta_description":null,"keywords":["application","migration","sftp-source"]}}},{"node":{"id":"f645343f-f8e9-5bab-97cc-0e6de8de4bac","fields":{"path":"/docs/2.7.x/applications/migration/splitter-processor/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"splitter-processor Migration","description":"splitter-processor Migration","path":"applications/migration/splitter-processor","meta_title":null,"meta_description":null,"keywords":["application","migration","splitter-processor"]}}},{"node":{"id":"cd104a49-1fc9-5624-b371-db21b9baf473","fields":{"path":"/docs/2.7.x/applications/migration/syslog-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"syslog-source Migration","description":"syslog-source Migration","path":"applications/migration/syslog-source","meta_title":null,"meta_description":null,"keywords":["application","migration","syslog-source"]}}},{"node":{"id":"67a1c503-c2f0-555b-8956-c6893e59808e","fields":{"path":"/docs/2.7.x/applications/migration/tcp-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"tcp-sink Migration","description":"tcp-sink Migration","path":"applications/migration/tcp-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","tcp-sink"]}}},{"node":{"id":"18d8139e-6b5a-541d-b944-f5b5a5dde24c","fields":{"path":"/docs/2.7.x/applications/migration/tcp-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"tcp-source Migration","description":"tcp-source Migration","path":"applications/migration/tcp-source","meta_title":null,"meta_description":null,"keywords":["application","migration","tcp-source"]}}},{"node":{"id":"7db36bfc-df1a-579a-8a6c-2f43ae1b8e49","fields":{"path":"/docs/2.7.x/applications/migration/throughput-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"throughput-sink Migration","description":"throughput-sink Migration","path":"applications/migration/throughput-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","throughput-sink"]}}},{"node":{"id":"dbea10b2-0fbe-5f30-b5ae-2652e1f0a508","fields":{"path":"/docs/2.7.x/applications/migration/time-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"time-source Migration","description":"time-source Migration","path":"applications/migration/time-source","meta_title":null,"meta_description":null,"keywords":["application","migration","time-source"]}}},{"node":{"id":"f7a812ab-dd6a-5596-93d0-6dad1d1727a4","fields":{"path":"/docs/2.7.x/applications/migration/file-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"file-sink Migration","description":"file-sink Migration","path":"applications/migration/file-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","file-sink"]}}},{"node":{"id":"1e680f43-7e42-59f7-b6ea-a8b629531699","fields":{"path":"/docs/2.7.x/applications/migration/websocket-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"websocket-sink Migration","description":"websocket-sink Migration","path":"applications/migration/websocket-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","websocket-sink"]}}},{"node":{"id":"cb431e0e-b782-57db-a577-48c85f9b3490","fields":{"path":"/docs/2.7.x/applications/migration/file-source/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"file-source Migration","description":"file-source Migration","path":"applications/migration/file-source","meta_title":null,"meta_description":null,"keywords":["application","migration","file-source"]}}},{"node":{"id":"648b1c0d-c150-5117-8799-238e845e4cb4","fields":{"path":"/docs/2.7.x/applications/migration/filter-processor/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"filter-processor Migration","description":"filter-processor Migration","path":"applications/migration/filter-processor","meta_title":null,"meta_description":null,"keywords":["application","migration","filter-processor"]}}},{"node":{"id":"cf8068d7-79fa-5e96-a19c-cfa9cd2a4088","fields":{"path":"/docs/2.7.x/applications/migration/ftp-sink/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"ftp-sink Migration","description":"ftp-sink Migration","path":"applications/migration/ftp-sink","meta_title":null,"meta_description":null,"keywords":["application","migration","ftp-sink"]}}},{"node":{"id":"971773b9-6df4-5731-8adf-91bf39086d2e","fields":{"path":"/docs/2.7.x/applications/pre-packaged/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"Pre-packaged Applications","description":"Pre-packaged stream and task applications","path":"applications/pre-packaged","meta_title":null,"meta_description":null,"keywords":["application","pre-packaged"]}}},{"node":{"id":"dad8e070-59e6-5577-bfc5-2d7dbb523966","fields":{"path":"/docs/2.7.x/applications/pre-packaged-3x/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"Pre-packaged Applications (3.x)","description":"Pre-packaged stream applications version 3.x","path":"applications/pre-packaged-3x","meta_title":null,"meta_description":null,"keywords":["application","pre-packaged"]}}},{"node":{"id":"6fd89ef9-ab72-5bca-ad7a-966cf9e2867f","fields":{"path":"/docs/2.7.x/applications/migration/","version":"2.7.x","category":"applications"},"frontmatter":{"title":"Migration Guide for Pre-packaged Stream Applications","description":"Guide for migrating fom 2.x to 3.x Stream Applications","path":"applications/migration","meta_title":null,"meta_description":null,"keywords":["application","migration","pre-packaged"]}}}]},"page":{"html":"<h1 id=\"sftp-to-jdbc-file-ingest\" style=\"position:relative;\"><a href=\"#sftp-to-jdbc-file-ingest\" aria-label=\"sftp to jdbc file ingest permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SFTP to JDBC File Ingest</h1>\n<p>This recipe provides step by step instructions to build a Data Flow pipeline to ingest files from an SFTP source and save the contents to a JDBC data store.\nThe pipeline is designed to launch a task whenever a new file is detected by the SFTP source.\nIn this case, the task is a Spring Batch job that processes the file, converting the contents of each line to uppercase, and inserting it into a table.</p>\n<p>The <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/tree/master/dataflow-website/recipes/file-ingest/file-to-jdbc\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">file ingest</a> batch job reads from a CSV text file with lines formatted as <code class=\"language-text\">first_name,last_name</code> and writes each entry to a database table using a <a href=\"https://docs.spring.io/spring-batch/trunk/apidocs/org/springframework/batch/item/database/JdbcBatchItemWriter.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">JdbcBatchItemWriter</a>] that executes <code class=\"language-text\">INSERT INTO people (first_name, last_name) VALUES (:firstName, :lastName)</code> for each line.</p>\n<p>You can <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/file-ingest/file-to-jdbc/file-to-jdbc.zip?raw=true\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">download the project</a> that contains the source code and sample data from your browser, or from the command line:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/file-ingest/file-to-jdbc/file-to-jdbc.zip?raw<span class=\"token operator\">=</span>true -O file-to-jdbc.zip</code></pre></div>\n      </div>\n<div class=\"admonition tip\"><p>If you choose not to build the task application yourself, the executable jar is published to the <a href=\"https://repo.spring.io/libs-snapshot-local/io/spring/cloud/dataflow/ingest/ingest/1.0.0.BUILD-SNAPSHOT/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spring Maven repository</a> and to the <a href=\"https://hub.docker.com/r/springcloud/ingest/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">springcloud/ingest</a> Docker repository.</p></div>\n<p>The pipeline is built using the following pre-packaged Spring Cloud Stream applications:</p>\n<ul>\n<li><a href=\"https://github.com/spring-cloud-stream-app-starters/sftp/tree/master/spring-cloud-starter-stream-source-sftp-dataflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">sftp-dataflow-source</a> an SFTP source configured to emit a Task Launch Request whenever it detects a new file in one or more polled SFTP directories.</li>\n<li><a href=\"https://github.com/spring-cloud-stream-app-starters/tasklauncher-dataflow/tree/master/spring-cloud-starter-stream-sink-task-launcher-dataflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">dataflow-task-launcher-sink</a> a sink that acts as a REST client to the Data Flow server to launch a Data Flow task.</li>\n</ul>\n<p>This pipeline runs on all supported Data Flow platforms.\nThe SFTP source downloads each file from the SFTP server to a local directory before sending the task launch request.\nThe request sets <code class=\"language-text\">localFilePath</code> as a command line argument for the task. When running on a cloud platform, we need to mount a shared directory available to the SFTP source container and the task container.\nFor this example, we will set up an NFS mounted directory.\nConfiguring the environment and containers for NFS is platform specific and is described here for Cloud Foundry v2.3+ and minikube.</p>\n<h2 id=\"prerequisites\" style=\"position:relative;\"><a href=\"#prerequisites\" aria-label=\"prerequisites permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Prerequisites</h2>\n<h3 id=\"data-flow-installation\" style=\"position:relative;\"><a href=\"#data-flow-installation\" aria-label=\"data flow installation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Flow Installation</h3>\n<p>Make sure you have installed Spring Cloud Data Flow to the platform of your choice:</p>\n<ul>\n<li><a href=\"/docs/2.7.x/installation/local/\">Local</a></li>\n<li><a href=\"/docs/2.7.x/installation/cloudfoundry/\">Cloud Foundry</a></li>\n<li><a href=\"/docs/2.7.x/installation/kubernetes/\">Kubernetes</a></li>\n</ul>\n<!-- TODO: Support for Postgres -->\n<div class=\"admonition note\"><p><strong>NOTE</strong>: For kubernetes, the sample task application is configured to use <code class=\"language-text\">mysql</code>. The Data Flow server must also be configured for mysql.</p></div>\n<h3 id=\"using-data-flow\" style=\"position:relative;\"><a href=\"#using-data-flow\" aria-label=\"using data flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Using Data Flow</h3>\n<p>This example assumes that you know how to use Spring Cloud Data Flow to register and deploy applications using the Spring Cloud Data Flow dashboard or the Spring Cloud Data Flow shell. If you need further instructions on using Data Flow please refer to <a href=\"/docs/2.7.x/stream-developer-guides/streams/data-flow-stream/\">Stream Processing using Spring Cloud Data Flow</a> and <a href=\"/docs/2.7.x/batch-developer-guides/batch/data-flow-spring-batch/\">Register and launch a batch application using Spring Cloud Data Flow</a>.</p>\n<h3 id=\"sftp-server\" style=\"position:relative;\"><a href=\"#sftp-server\" aria-label=\"sftp server permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SFTP server</h3>\n<p>This example requires access to an SFTP server. For running on a <code class=\"language-text\">local</code> machine and <code class=\"language-text\">minikube</code>, we will use the host machine as the SFTP server. For <code class=\"language-text\">Cloud Foundry</code>, and <code class=\"language-text\">Kubernetes</code> in general, an external SFTP server is required.\nOn the SFTP server, create a <code class=\"language-text\">/remote-files</code> directory. This is where we will drop files to trigger the pipeline.</p>\n<h3 id=\"nfs-configuration\" style=\"position:relative;\"><a href=\"#nfs-configuration\" aria-label=\"nfs configuration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>NFS configuration</h3>\n<div class=\"admonition tip\"><p>NFS is not required when running locally.</p></div>\n<h4 id=\"cloud-foundry-nfs-configuration\" style=\"position:relative;\"><a href=\"#cloud-foundry-nfs-configuration\" aria-label=\"cloud foundry nfs configuration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cloud Foundry NFS configuration</h4>\n<p>This feature is provided in Pivotal Cloud Foundry by <a href=\"https://docs.pivotal.io/pivotalcf/2-5/devguide/services/using-vol-services.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">NFS Volume Services</a></p>\n<p>To run this example, we will need:</p>\n<ul>\n<li>a Cloud Foundry instance v2.3+ with NFS Volume Services <a href=\"https://docs.pivotal.io/pivotalcf/2-5/opsguide/enable-vol-services.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">enabled</a></li>\n<li>An NFS server accessible from the Cloud Foundry instance</li>\n<li>An <code class=\"language-text\">nfs</code> service instance properly configured</li>\n</ul>\n<div class=\"admonition note\"><p><strong>NOTE:</strong> For simplicity, this example assumes the <code class=\"language-text\">nfs</code> service is created with common configuration as follows with a common mount point <code class=\"language-text\">/var/scdf</code> for all bound apps. It is also possible to set these parameters when binding the nfs service to an application using <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#configure-service-binding-parameters\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">deployment propterties</a>:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cf create-service nfs Existing nfs -c <span class=\"token string\">'{\"share\":&lt;nfs-host>/staging\",\"uid\":&lt;uid>,\"gid\":&lt;gid>, \"mount\":\"/var/scdf\"}'</span></code></pre></div>\n      </div></div>\n<h4 id=\"kubernetes-nfs-configuration\" style=\"position:relative;\"><a href=\"#kubernetes-nfs-configuration\" aria-label=\"kubernetes nfs configuration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kubernetes NFS configuration</h4>\n<p>Kubernetes provides many options for configuring and sharing persistent volumes. For this example, we will use <code class=\"language-text\">minikube</code> and use the host machine as the NFS server. The following instructions works for <code class=\"language-text\">OS/X</code> and should be similar for Linux hosts:</p>\n<p>Make sure minikube is started. The commands below provide NFS access to the minikube VM. The minikube IP is subject to change each time it is started, so these steps should be performed after each start.</p>\n<p>Here we will expose a shared directory called <code class=\"language-text\">/staging</code>.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">mkdir</span> /staging\n<span class=\"token function\">sudo</span> <span class=\"token function\">chmod</span> <span class=\"token number\">777</span> /staging\n<span class=\"token function\">sudo</span> <span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"/staging -alldirs -mapall=\"</span><span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">id</span> -u<span class=\"token variable\">)</span></span><span class=\"token string\">\":\"</span><span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">id</span> -g<span class=\"token variable\">)</span></span><span class=\"token string\">\" <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube <span class=\"token function\">ip</span><span class=\"token variable\">)</span></span>\"</span> <span class=\"token operator\">>></span> /etc/exports\n<span class=\"token function\">sudo</span> nfsd restart</code></pre></div>\n      </div>\n<p>Verify the nfs mounts:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">showmount -e <span class=\"token number\">127.0</span>.0.1\nExports list on <span class=\"token number\">127.0</span>.0.1:\n/staging <span class=\"token number\">192.168</span>.99.105</code></pre></div>\n      </div>\n<p>Configure persistent volume and persistent volume claim resources. Copy the following and save it to a file named <code class=\"language-text\">nfs-config.yml</code>:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token punctuation\">---</span>\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> PersistentVolume\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> nfs<span class=\"token punctuation\">-</span>volume\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">capacity</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span> 4Gi\n  <span class=\"token key atrule\">accessModes</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> ReadWriteMany\n  <span class=\"token key atrule\">persistentVolumeReclaimPolicy</span><span class=\"token punctuation\">:</span> Retain\n  <span class=\"token key atrule\">storageClassName</span><span class=\"token punctuation\">:</span> standard\n  <span class=\"token key atrule\">nfs</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># The address 192.168.99.1 is the Minikube gateway to the host for VirtualBox. This way</span>\n    <span class=\"token comment\"># not the container IP will be visible by the NFS server on the host machine,</span>\n    <span class=\"token comment\"># but the IP address of the `minikube ip` command. You will need to</span>\n    <span class=\"token comment\"># grant access to the `minikube ip` IP address.</span>\n    <span class=\"token key atrule\">server</span><span class=\"token punctuation\">:</span> 192.168.99.1\n    <span class=\"token key atrule\">path</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'/staging'</span>\n\n<span class=\"token punctuation\">---</span>\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> PersistentVolumeClaim\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> nfs<span class=\"token punctuation\">-</span>volume<span class=\"token punctuation\">-</span>claim\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> default\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">storageClassName</span><span class=\"token punctuation\">:</span> standard\n  <span class=\"token key atrule\">accessModes</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> ReadWriteMany\n  <span class=\"token key atrule\">resources</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">requests</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span> 4Gi</code></pre></div>\n      </div>\n<p>Create the resources:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">kubectl apply -f nfs-config.yml</code></pre></div>\n      </div>\n<h2 id=\"deployment\" style=\"position:relative;\"><a href=\"#deployment\" aria-label=\"deployment permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deployment</h2>\n<h3 id=\"local\" style=\"position:relative;\"><a href=\"#local\" aria-label=\"local permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Local</h3>\n<p>For local deployment, this example uses Kafka as the message broker.\nCreate directories for the remote and local files:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">mkdir</span> -p /tmp/remote-files /tmp/local-files</code></pre></div>\n      </div>\n<h4 id=\"register-the-applications\" style=\"position:relative;\"><a href=\"#register-the-applications\" aria-label=\"register the applications permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Register the applications</h4>\n<p>If you downloaded and built the <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/file-ingest/file-to-jdbc/file-to-jdbc.zip?raw=true\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">sample project</a>, you can register it using a <code class=\"language-text\">file://</code> url, e.g. <code class=\"language-text\">file://&lt;path-to-project>/target/ingest-1.0.0-SNAPSHOT.jar</code>\nOtherwise use the published maven jar:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name fileIngest --type task --uri maven://io.spring.cloud.dataflow.ingest:ingest:1.0.0.BUILD-SNAPSHOT</code></pre></div>\n      </div>\n<p>Register the prepackaged <code class=\"language-text\">sftp</code> source and <code class=\"language-text\">task-launcher</code> sink applications:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name <span class=\"token function\">sftp</span> --type <span class=\"token builtin class-name\">source</span>  --uri maven://org.springframework.cloud.stream.app:sftp-dataflow-source-kafka:2.1.0.RELEASE</code></pre></div>\n      </div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name task-launcher --type sink --uri maven://org.springframework.cloud.stream.app:task-launcher-dataflow-sink-kafka:1.0.1.RELEASE</code></pre></div>\n      </div>\n<h4 id=\"create-the-task\" style=\"position:relative;\"><a href=\"#create-the-task\" aria-label=\"create the task permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Create the task</h4>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">task create fileIngestTask --definition fileIngest</code></pre></div>\n      </div>\n<h4 id=\"create-and-deploy-the-stream\" style=\"position:relative;\"><a href=\"#create-and-deploy-the-stream\" aria-label=\"create and deploy the stream permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Create and deploy the stream</h4>\n<div class=\"admonition note\"><p><strong>NOTE</strong>: Replace <code class=\"language-text\">&lt;user></code> and <code class=\"language-text\">&lt;pass></code> below.\nThe <code class=\"language-text\">username</code> and <code class=\"language-text\">password</code> are the credentials for the local (or remote) user.\nIf you are not using a local SFTP server, specify the host using the <code class=\"language-text\">host</code>,\nand optionally <code class=\"language-text\">port</code>, parameters. If not defined, <code class=\"language-text\">host</code> defaults to <code class=\"language-text\">127.0.0.1</code>\nand <code class=\"language-text\">port</code> defaults to <code class=\"language-text\">22</code>.</p></div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">stream create --name inboundSftp --definition <span class=\"token string\">\"sftp --username=&lt;user> --password=&lt;pass> --allow-unknown-keys=true --task.launch.request.taskName=fileIngestTask --remote-dir=/tmp/remote-files/ --local-dir=/tmp/local-files/ | task-launcher\"</span> --deploy</code></pre></div>\n      </div>\n<div class=\"admonition tip\"><p>The <a href=\"https://github.com/spring-cloud-stream-app-starters/tasklauncher-dataflow/tree/master/spring-cloud-starter-stream-sink-task-launcher-dataflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">dataflow-task-launcher-sink</a> uses a <a href=\"https://docs.spring.io/spring-cloud-stream/docs/Elmhurst.BUILD-SNAPSHOT/api/org/springframework/cloud/stream/binder/PollableMessageSource.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">PollableMessageSource</a> controlled by a dynamic trigger with exponential backoff. By default, the sink polls its input destination every 1 second. If there are no task launch requests, the polling period will continue to double up to a maximum of 30 seconds. If a task launch request is present, the trigger resets to 1 second. The trigger parameters may be configured by setting the <code class=\"language-text\">task-launcher</code> sink properties <code class=\"language-text\">trigger.period</code> and <code class=\"language-text\">trigger.max-period</code> in the stream definition.</p></div>\n<h4 id=\"verify-stream-deployment\" style=\"position:relative;\"><a href=\"#verify-stream-deployment\" aria-label=\"verify stream deployment permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Verify Stream deployment</h4>\n<p>We can see the status of the streams to be deployed with <code class=\"language-text\">stream list</code>, for example:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>stream list\n╔═══════════╤════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╤════════════════════════════╗\n║Stream Name│                                                         Stream Definition                                                          │           Status           ║\n╠═══════════╪════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪════════════════════════════╣\n║inboundSftp│sftp --password<span class=\"token operator\">=</span><span class=\"token string\">'******'</span> --remote-dir<span class=\"token operator\">=</span>/tmp/remote-files/ --local-dir<span class=\"token operator\">=</span>/tmp/local-files/ --task.launch.request.taskName<span class=\"token operator\">=</span>fileIngestTask│The stream has been         ║\n║           │--allow-unknown-keys<span class=\"token operator\">=</span>true --username<span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>user<span class=\"token operator\">></span> <span class=\"token operator\">|</span> task-launcher                                                                         │successfully deployed       ║\n╚═══════════╧════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╧════════════════════════════╝</code></pre></div>\n      </div>\n<h4 id=\"inspect-the-application-logs\" style=\"position:relative;\"><a href=\"#inspect-the-application-logs\" aria-label=\"inspect the application logs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inspect the application logs</h4>\n<p>In the event the stream failed to deploy, or you would like to inspect the logs for any reason, you can get the location of the logs to applications created for the <code class=\"language-text\">inboundSftp</code> stream using the <code class=\"language-text\">runtime apps</code> command:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>runtime apps\n╔═══════════════════════════╤═══════════╤════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n║   App Id / Instance Id    │Unit Status│                                                                     No. of Instances / Attributes                                                                      ║\n╠═══════════════════════════╪═══════════╪════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n║inboundSftp.sftp           │ deployed  │                                                                                   <span class=\"token number\">1</span>                                                                                    ║\n║                           │           │       guid <span class=\"token operator\">=</span> <span class=\"token number\">23057</span>                                                                                                                                                     ║\n║                           │           │        pid <span class=\"token operator\">=</span> <span class=\"token number\">71927</span>                                                                                                                                                     ║\n║                           │           │       port <span class=\"token operator\">=</span> <span class=\"token number\">23057</span>                                                                                                                                                     ║\n╟───────────────────────────┼───────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╢\n║inboundSftp.sftp-0         │ deployed  │     stderr <span class=\"token operator\">=</span> /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-deployer-120915912946760306/inboundSftp-1540821009913/inboundSftp.sftp/stderr_0.log         ║\n║                           │           │     stdout <span class=\"token operator\">=</span> /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-deployer-120915912946760306/inboundSftp-1540821009913/inboundSftp.sftp/stdout_0.log         ║\n║                           │           │        url <span class=\"token operator\">=</span> http://192.168.64.1:23057                                                                                                                                 ║\n║                           │           │working.dir <span class=\"token operator\">=</span> /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-deployer-120915912946760306/inboundSftp-1540821009913/inboundSftp.sftp                      ║\n╟───────────────────────────┼───────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╢\n║inboundSftp.task-launcher  │ deployed  │                                                                                   <span class=\"token number\">1</span>                                                                                    ║\n╟───────────────────────────┼───────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╢\n║                           │           │       guid <span class=\"token operator\">=</span> <span class=\"token number\">60081</span>                                                                                                                                                     ║\n║                           │           │        pid <span class=\"token operator\">=</span> <span class=\"token number\">71926</span>                                                                                                                                                     ║\n║                           │           │       port <span class=\"token operator\">=</span> <span class=\"token number\">60081</span>                                                                                                                                                     ║\n║inboundSftp.task-launcher-0│ deployed  │     stderr <span class=\"token operator\">=</span> /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-deployer-120915912946760306/inboundSftp-1540820991695/inboundSftp.task-launcher/stderr_0.log║\n║                           │           │     stdout <span class=\"token operator\">=</span> /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-deployer-120915912946760306/inboundSftp-1540820991695/inboundSftp.task-launcher/stdout_0.log║\n║                           │           │        url <span class=\"token operator\">=</span> http://192.168.64.1:60081                                                                                                                                 ║\n║                           │           │working.dir <span class=\"token operator\">=</span> /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-deployer-120915912946760306/inboundSftp-1540820991695/inboundSftp.task-launcher             ║\n╚═══════════════════════════╧═══════════╧════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝</code></pre></div>\n      </div>\n<h4 id=\"drop-a-file-into-the-remote-directory\" style=\"position:relative;\"><a href=\"#drop-a-file-into-the-remote-directory\" aria-label=\"drop a file into the remote directory permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Drop a file into the remote directory</h4>\n<p>Normally data would be uploaded to an SFTP server.\nWe will simulate this by copying a file into the directory specified by <code class=\"language-text\">--remote-dir</code>.\nSample data can be found in the <code class=\"language-text\">data/</code> directory of the <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/file-ingest/file-to-jdbc/file-to-jdbc.zip?raw=true\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">sample project</a>.</p>\n<p>Copy <code class=\"language-text\">data/name-list.csv</code> into the <code class=\"language-text\">/tmp/remote-files</code> directory which the SFTP source is monitoring.\nWhen this file is detected, the <code class=\"language-text\">sftp</code> source will download it to the <code class=\"language-text\">/tmp/local-files</code> directory specified by <code class=\"language-text\">--local-dir</code>, and emit a Task Launch Request.\nThe Task Launch Request includes the name of the task to launch along with the local file path, given as a command line argument.\nSpring Batch binds each command line argument to a corresponding JobParameter.\nThe FileIngestTask job processes the file given by the JobParameter named <code class=\"language-text\">localFilePath</code>.\nSince there have not been any recent requests, the task will launch within 30 seconds after the request is published (see tip above about configuring the launch trigger).</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">cp</span> data/name-list.csv /tmp/remote-files</code></pre></div>\n      </div>\n<p>When the batch job launches, you will see something like this in the SCDF console log:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token number\">2018</span>-10-26 <span class=\"token number\">16</span>:47:24.879  INFO <span class=\"token number\">86034</span> --- <span class=\"token punctuation\">[</span>nio-9393-exec-7<span class=\"token punctuation\">]</span> o.s.c.d.spi.local.LocalTaskLauncher      <span class=\"token builtin class-name\">:</span> Command to be executed: /Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/jre/bin/java -jar <span class=\"token operator\">&lt;</span>path-to<span class=\"token operator\">></span>/batch/file-ingest/target/ingest-1.0.0.jar <span class=\"token assign-left variable\">localFilePath</span><span class=\"token operator\">=</span>/tmp/local-files/name-list.csv --spring.cloud.task.executionid<span class=\"token operator\">=</span><span class=\"token number\">1</span>\n<span class=\"token number\">2018</span>-10-26 <span class=\"token number\">16</span>:47:25.100  INFO <span class=\"token number\">86034</span> --- <span class=\"token punctuation\">[</span>nio-9393-exec-7<span class=\"token punctuation\">]</span> o.s.c.d.spi.local.LocalTaskLauncher      <span class=\"token builtin class-name\">:</span> launching task fileIngestTask-8852d94d-9dd8-4760-b0e4-90f75ee028de\n   Logs will be <span class=\"token keyword\">in</span> /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/fileIngestTask3100511340216074735/1540586844871/fileIngestTask-8852d94d-9dd8-4760-b0e4-90f75ee028de</code></pre></div>\n      </div>\n<h4 id=\"inspect-job-executions\" style=\"position:relative;\"><a href=\"#inspect-job-executions\" aria-label=\"inspect job executions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inspect Job Executions</h4>\n<p>After data is received and the batch job runs, it will be recorded as a Job Execution. We can view job executions by for example issuing the following command in the Spring Cloud Data Flow shell:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>job execution list\n╔═══╤═══════╤═════════╤════════════════════════════╤═════════════════════╤══════════════════╗\n║ID │Task ID│Job Name │         Start Time         │Step Execution Count │Definition Status ║\n╠═══╪═══════╪═════════╪════════════════════════════╪═════════════════════╪══════════════════╣\n║1  │1      │ingestJob│Tue May 01 <span class=\"token number\">23</span>:34:05 EDT <span class=\"token number\">2018</span>│1                    │Created           ║\n╚═══╧═══════╧═════════╧════════════════════════════╧═════════════════════╧══════════════════╝</code></pre></div>\n      </div>\n<p>As well as list more details about that specific job execution:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>job execution display --id <span class=\"token number\">1</span>\n╔═══════════════════════════════════════╤══════════════════════════════╗\n║                  Key                  │            Value             ║\n╠═══════════════════════════════════════╪══════════════════════════════╣\n║Job Execution Id                       │1                             ║\n║Task Execution Id                      │1                             ║\n║Task Instance Id                       │1                             ║\n║Job Name                               │ingestJob                     ║\n║Create Time                            │Fri Oct <span class=\"token number\">26</span> <span class=\"token number\">16</span>:57:51 EDT <span class=\"token number\">2018</span>  ║\n║Start Time                             │Fri Oct <span class=\"token number\">26</span> <span class=\"token number\">16</span>:57:51 EDT <span class=\"token number\">2018</span>  ║\n║End Time                               │Fri Oct <span class=\"token number\">26</span> <span class=\"token number\">16</span>:57:53 EDT <span class=\"token number\">2018</span>  ║\n║Running                                │false                         ║\n║Stopping                               │false                         ║\n║Step Execution Count                   │1                             ║\n║Execution Status                       │COMPLETED                     ║\n║Exit Status                            │COMPLETED                     ║\n║Exit Message                           │                              ║\n║Definition Status                      │Created                       ║\n║Job Parameters                         │                              ║\n║-spring.cloud.task.executionid<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span> │1                             ║\n║run.id<span class=\"token punctuation\">(</span>LONG<span class=\"token punctuation\">)</span>                           │1                             ║\n║localFilePath<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span>                  │/tmp/local-files/name-list.csv║\n╚═══════════════════════════════════════╧══════════════════════════════╝</code></pre></div>\n      </div>\n<h4 id=\"verify-data\" style=\"position:relative;\"><a href=\"#verify-data\" aria-label=\"verify data permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Verify data</h4>\n<p>When the the batch job runs, it processes the file in the local directory <code class=\"language-text\">/tmp/local-files</code> and transforms each item to uppercase names and inserts it into the database.</p>\n<p>You may use any database tool that supports the H2 database to inspect the data.\nIn this example we use the database tool <code class=\"language-text\">DBeaver</code>.\nLets inspect the table to ensure our data was processed correctly.</p>\n<p>Within DBeaver, create a connection to the database using the JDBC URL <code class=\"language-text\">jdbc:h2:tcp://localhost:19092/mem:dataflow</code>, and user <code class=\"language-text\">sa</code> with no password.\nWhen connected, expand the <code class=\"language-text\">PUBLIC</code> schema, then expand <code class=\"language-text\">Tables</code> and then double click on the table <code class=\"language-text\">PEOPLE</code>.\nWhen the table data loads, click the \"Data\" tab to view the data.</p>\n<h3 id=\"cloud-foundry\" style=\"position:relative;\"><a href=\"#cloud-foundry\" aria-label=\"cloud foundry permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cloud Foundry</h3>\n<h4 id=\"prerequisites-1\" style=\"position:relative;\"><a href=\"#prerequisites-1\" aria-label=\"prerequisites 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Prerequisites</h4>\n<p>Running this example on Cloud Foundry requires configuring an NFS server and creating an <code class=\"language-text\">nfs</code> service to access it as discribed in the <a href=\"/docs/2.7.x/recipes/batch/sftp-to-jdbc/#cloud-foundry-nfs-configuration\">Cloud Foundry NFS Configuration</a> section.\nWe also require an external SFTP server with a <code class=\"language-text\">/remote-files</code> directory.</p>\n<p>This also requires:</p>\n<ul>\n<li>A <code class=\"language-text\">mysql</code> service instance</li>\n<li>A <code class=\"language-text\">rabbit</code> service instance</li>\n<li><a href=\"https://github.com/pivotal-cf/PivotalMySQLWeb\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">PivotalMySQLWeb</a> or another database tool to view the data</li>\n</ul>\n<h4 id=\"register-the-applications-1\" style=\"position:relative;\"><a href=\"#register-the-applications-1\" aria-label=\"register the applications 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Register the applications</h4>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name fileIngest --type task --uri maven://io.spring.cloud.dataflow.ingest:ingest:1.0.0.BUILD-SNAPSHOT</code></pre></div>\n      </div>\n<p>Register the prepackaged <code class=\"language-text\">sftp</code> source and <code class=\"language-text\">task-launcher</code> sink applications:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name <span class=\"token function\">sftp</span> --type <span class=\"token builtin class-name\">source</span>  --uri maven://org.springframework.cloud.stream.app:sftp-dataflow-source-kafka:2.1.0.RELEASE</code></pre></div>\n      </div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name task-launcher --type sink --uri maven://org.springframework.cloud.stream.app:task-launcher-dataflow-sink-kafka:1.0.1.RELEASE</code></pre></div>\n      </div>\n<h4 id=\"create-the-task-1\" style=\"position:relative;\"><a href=\"#create-the-task-1\" aria-label=\"create the task 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Create the task</h4>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">task create fileIngestTask --definition fileIngest</code></pre></div>\n      </div>\n<h4 id=\"create-the-stream\" style=\"position:relative;\"><a href=\"#create-the-stream\" aria-label=\"create the stream permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Create the stream</h4>\n<p>The <code class=\"language-text\">sftp</code> source is configured to publish a task launch request to launch the <code class=\"language-text\">fileIngestTask</code> task.\nThe launch request binds the <code class=\"language-text\">nfs</code> service to the task container using deployment properties <code class=\"language-text\">task.launch.request.deployment-properties=deployer.*.cloudfoundry.services=nfs</code>.</p>\n<div class=\"admonition note\"><p><strong>NOTE</strong>: Replace <code class=\"language-text\">&lt;user></code>, <code class=\"language-text\">&lt;pass></code>,<code class=\"language-text\">&lt;host></code> and <code class=\"language-text\">&lt;data-flow-server-uri></code> in the stream definition below.</p></div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">stream create --name inboundSftp --definition <span class=\"token string\">\"sftp --username=&lt;user> --password=&lt;pass> --host=&lt;host>  --allow-unknown-keys=true --remote-dir=/remote-files/ --local-dir=/var/scdf/shared-files/ --task.launch.request.taskName=fileIngestTask --task.launch.request.deployment-properties=deployer.*.cloudfoundry.services=nfs | task-launcher --spring.cloud.dataflow.client.server-uri=&lt;data-flow-server-uri>\"</span></code></pre></div>\n      </div>\n<div class=\"admonition tip\"><p>The <a href=\"https://github.com/spring-cloud-stream-app-starters/tasklauncher-dataflow/tree/master/spring-cloud-starter-stream-sink-task-launcher-dataflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">dataflow-task-launcher-sink</a> uses a <a href=\"https://docs.spring.io/spring-cloud-stream/docs/Elmhurst.BUILD-SNAPSHOT/api/org/springframework/cloud/stream/binder/PollableMessageSource.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">PollableMessageSource</a> controlled by a dynamic trigger with exponential backoff. By default, the sink polls its input destination every 1 second. If there are no task launch requests, the polling period will continue to double up to a maximum of 30 seconds. If a task launch request is present, the trigger resets to 1 second. The trigger parameters may be configured by setting the <code class=\"language-text\">task-launcher</code> sink properties <code class=\"language-text\">trigger.period</code> and <code class=\"language-text\">trigger.max-period</code> in the stream definition.</p></div>\n<h4 id=\"deploy-the-stream\" style=\"position:relative;\"><a href=\"#deploy-the-stream\" aria-label=\"deploy the stream permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploy the stream</h4>\n<p>When we deploy the stream we must also configure the <code class=\"language-text\">sftp</code> pod with the</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">stream deploy inboundSftp --properties <span class=\"token string\">\"deployer.sftp.cloudfoundry.services=nfs\"</span></code></pre></div>\n      </div>\n<h4 id=\"verify-stream-deployment-1\" style=\"position:relative;\"><a href=\"#verify-stream-deployment-1\" aria-label=\"verify stream deployment 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Verify Stream deployment</h4>\n<p>We can see the status of the streams to be deployed with <code class=\"language-text\">stream list</code>, for example:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>stream list\n╔═══════════╤═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╤═══════════════════╗\n║Stream Name│                                                                                     Stream Definition                                                                                     │      Status       ║\n╠═══════════╪═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪═══════════════════╣\n║inboundSftp│sftp --task.launch.request.deployment-properties<span class=\"token operator\">=</span><span class=\"token string\">'deployer.*.cloudfoundry.services=nfs'</span> --sftp.factory.password<span class=\"token operator\">=</span><span class=\"token string\">'******'</span> --sftp.local-dir<span class=\"token operator\">=</span>/var/scdf/shared-files/                          │The stream has been║\n║           │--sftp.factory.allow-unknown-keys<span class=\"token operator\">=</span>true --sftp.factory.username<span class=\"token operator\">=</span><span class=\"token string\">'******'</span> --sftp.remote-dir<span class=\"token operator\">=</span>/remote-files/ --sftp.factory.host<span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>host<span class=\"token operator\">></span> --task.launch.request.taskName<span class=\"token operator\">=</span>fileIngestTask <span class=\"token operator\">|</span>        │successfully       ║\n║           │task-launcher --spring.cloud.dataflow.client.server-uri<span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>data-flow-server-uri                                                                                                              │deployed           ║\n╚═══════════╧═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╧═══════════════════╝</code></pre></div>\n      </div>\n<h4 id=\"inspect-the-application-logs-1\" style=\"position:relative;\"><a href=\"#inspect-the-application-logs-1\" aria-label=\"inspect the application logs 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inspect the application logs</h4>\n<p>Use the Cloud Foundry CLI to list the apps. The <code class=\"language-text\">source</code> and <code class=\"language-text\">sink</code> applications should be in a started state.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cf apps\nGetting apps <span class=\"token keyword\">in</span> org myorg / space myspace as someuser<span class=\"token punctuation\">..</span>.\nOK\n\nname                                   requested state   instances   memory   disk   urls\n<span class=\"token punctuation\">..</span>.\nKy7Uk6q-inboundSftp-sftp-v1            started           <span class=\"token number\">1</span>/1         2G       1G     Ky7Uk6q-inboundSftp-sftp-v1.apps.hayward.cf-app.com\nKy7Uk6q-inboundSftp-task-launcher-v1   started           <span class=\"token number\">1</span>/1         2G       1G     Ky7Uk6q-inboundSftp-task-launcher-v1.apps.hayward.cf-app.com\n<span class=\"token punctuation\">..</span>.</code></pre></div>\n      </div>\n<p>The log files of the <code class=\"language-text\">sftp</code> source would be useful to debug issues such as SFTP connection failures and to verify SFTP downloads.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cf logs Ky7Uk6q-inboundSftp-sftp-v1 --recent</code></pre></div>\n      </div>\n<p>The logs for the <code class=\"language-text\">task-launcher</code> application would be useful to debug data flow connection issues and verify task launch requests:</p>\n<h4 id=\"drop-a-file-into-the-remote-directory-1\" style=\"position:relative;\"><a href=\"#drop-a-file-into-the-remote-directory-1\" aria-label=\"drop a file into the remote directory 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Drop a file into the remote directory</h4>\n<p>Sample data can be found in the <code class=\"language-text\">data/</code> directory of the <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/file-ingest/file-to-jdbc/file-to-jdbc.zip?raw=true\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">sample project</a>.</p>\n<p>Connect to the SFTP server and upload <code class=\"language-text\">data/name-list.csv</code> into the <code class=\"language-text\">remote-files</code> directory:</p>\n<p>When this file is detected, the <code class=\"language-text\">sftp</code> source will download it to the <code class=\"language-text\">/var/scdf/shared-files</code> directory specified by <code class=\"language-text\">--local-dir</code>. Here we are using the shared mount path <code class=\"language-text\">/var/scdf</code> that we configured for the <code class=\"language-text\">nfs</code> service. When the file is downloaded, the source emits a Task Launch Request.\nThe Task Launch Request includes the name of the task to launch along with the local file path, given as a command line argument.\nSpring Batch binds each command line argument to a corresponding JobParameter.\nThe FileIngestTask job processes the file given by the JobParameter named <code class=\"language-text\">localFilePath</code>.\nSince there have not been any recent requests, the task will launch within 30 seconds after the request is published (see tip above about configuring the launch trigger).</p>\n<h4 id=\"inspect-job-executions-1\" style=\"position:relative;\"><a href=\"#inspect-job-executions-1\" aria-label=\"inspect job executions 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inspect Job Executions</h4>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>job execution list\n╔═══╤═══════╤═════════╤════════════════════════════╤═════════════════════╤══════════════════╗\n║ID │Task ID│Job Name │         Start Time         │Step Execution Count │Definition Status ║\n╠═══╪═══════╪═════════╪════════════════════════════╪═════════════════════╪══════════════════╣\n║1  │1      │ingestJob│Tue Jun <span class=\"token number\">11</span> <span class=\"token number\">15</span>:56:27 EDT <span class=\"token number\">2019</span>│1                    │Created           ║\n╚═══╧═══════╧═════════╧════════════════════════════╧═════════════════════╧══════════════════╝</code></pre></div>\n      </div>\n<p>As well as list more details about that specific job execution:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>job execution display --id <span class=\"token number\">1</span>\n╔═══════════════════════════════════════╤════════════════════════════════════╗\n║                  Key                  │               Value                ║\n╠═══════════════════════════════════════╪════════════════════════════════════╣\n║Job Execution Id                       │6                                   ║\n║Task Execution Id                      │6                                   ║\n║Task Instance Id                       │6                                   ║\n║Job Name                               │ingestJob                           ║\n║Create Time                            │Thu Jun <span class=\"token number\">13</span> <span class=\"token number\">17</span>:06:28 EDT <span class=\"token number\">2019</span>        ║\n║Start Time                             │Thu Jun <span class=\"token number\">13</span> <span class=\"token number\">17</span>:06:29 EDT <span class=\"token number\">2019</span>        ║\n║End Time                               │Thu Jun <span class=\"token number\">13</span> <span class=\"token number\">17</span>:06:57 EDT <span class=\"token number\">2019</span>        ║\n║Running                                │false                               ║\n║Stopping                               │false                               ║\n║Step Execution Count                   │1                                   ║\n║Execution Status                       │COMPLETED                           ║\n║Exit Status                            │COMPLETED                           ║\n║Exit Message                           │                                    ║\n║Definition Status                      │Created                             ║\n║Job Parameters                         │                                    ║\n║-spring.cloud.task.executionid<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span> │1                                   ║\n║run.id<span class=\"token punctuation\">(</span>LONG<span class=\"token punctuation\">)</span>                           │1                                   ║\n║localFilePath<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span>                  │/var/scdf/shared-files/name-list.csv║\n╚═══════════════════════════════════════╧════════════════════════════════════╝</code></pre></div>\n      </div>\n<h4 id=\"verify-data-1\" style=\"position:relative;\"><a href=\"#verify-data-1\" aria-label=\"verify data 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Verify data</h4>\n<p>When the the batch job runs, it processes the file in the local directory <code class=\"language-text\">/var/scdf/shared-files</code> and transforms each item to uppercase names and inserts it into the database.</p>\n<p>Use <a href=\"https://github.com/pivotal-cf/PivotalMySQLWeb\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">PivotalMySQLWeb</a> to inspect the data.</p>\n<h3 id=\"kubernetes\" style=\"position:relative;\"><a href=\"#kubernetes\" aria-label=\"kubernetes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kubernetes</h3>\n<h4 id=\"prerequisites-2\" style=\"position:relative;\"><a href=\"#prerequisites-2\" aria-label=\"prerequisites 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Prerequisites</h4>\n<p>This example assumes Data Flow is installed on minikube with <code class=\"language-text\">kafka</code> and <code class=\"language-text\">mysql</code>. It is recommended to use the <a href=\"/docs/2.7.x/installation/kubernetes/helm/\">helm chart</a>.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">helm <span class=\"token function\">install</span> --name my-release --set kafka.enabled<span class=\"token operator\">=</span>true,rabbitmq.enabled<span class=\"token operator\">=</span>false,server.service.type<span class=\"token operator\">=</span>NodePort stable/spring-cloud-data-flow</code></pre></div>\n      </div>\n<p>Running this example on Kubernetes requires configuring an NFS server and creating an corresponding <code class=\"language-text\">persistent volume</code> and <code class=\"language-text\">persistent volume claim</code> resources as described in the <a href=\"/docs/2.7.x/recipes/batch/sftp-to-jdbc/#kubernetes-nfs-configuration\">Kubernetes NFS Configuration</a> section.\nWe also require an external SFTP server with a <code class=\"language-text\">/remote-files</code> directory.</p>\n<h4 id=\"register-the-applications-2\" style=\"position:relative;\"><a href=\"#register-the-applications-2\" aria-label=\"register the applications 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Register the applications</h4>\n<p>If you downloaded the <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/file-ingest/file-to-jdbc/file-to-jdbc.zip?raw=true\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">sample project</a> you can build and publish the docker image to the minikube registry:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">eval</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube docker-env<span class=\"token variable\">)</span></span>\n./mvnw clean package docker:build -Pkubernetes</code></pre></div>\n      </div>\n<p>Otherwise, you can skip this step to pull the image from dockerhub.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name fileIngest --type task --uri docker://springcloud/ingest</code></pre></div>\n      </div>\n<p>Register the prepackaged <code class=\"language-text\">sftp</code> source and <code class=\"language-text\">task-launcher</code> sink applications:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name <span class=\"token function\">sftp</span> --type <span class=\"token builtin class-name\">source</span>  --uri docker://springcloudstream/sftp-dataflow-source-kafka:2.1.0.RELEASE --metadata-uri maven://org.springframework.cloud.stream.app:sftp-dataflow-source-kafka:jar:metadata:2.1.0.RELEASE</code></pre></div>\n      </div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --name task-launcher --type sink --uri docker://springcloudstream/task-launcher-dataflow-sink-kafka:1.0.1.RELEASE --metadata-uri maven://org.springframework.cloud.stream.app:task-launcher-dataflow-sink-kafka:jar:metadata:1.0.1.RELEASE</code></pre></div>\n      </div>\n<h4 id=\"create-the-task-2\" style=\"position:relative;\"><a href=\"#create-the-task-2\" aria-label=\"create the task 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Create the task</h4>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">task create fileIngestTask --definition fileIngest</code></pre></div>\n      </div>\n<h4 id=\"create-the-stream-1\" style=\"position:relative;\"><a href=\"#create-the-stream-1\" aria-label=\"create the stream 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Create the stream</h4>\n<p>The <code class=\"language-text\">sftp</code> source is configured to publish a task launch request to launch the <code class=\"language-text\">fileIngestTask</code> task.\nThe launch request mounts the nfs share to the task pod using deployment properties\n<code class=\"language-text\">deployer.*.kubernetes.volumes=[{'name':'staging','persistentVolumeClaim':{'claimName':'nfs-volume-claim'}}]</code> and\n<code class=\"language-text\">deployer.*.kubernetes.volumeMounts=[{'mountPath':'/staging/shared-files','name':'staging'}]</code>.</p>\n<div class=\"admonition note\"><p><strong>NOTE</strong>: Replace <code class=\"language-text\">&lt;user></code>, <code class=\"language-text\">&lt;pass></code> and <code class=\"language-text\">&lt;data-flow-server-uri></code> in the stream definition below. The <code class=\"language-text\">&lt;host></code> value here is the default minikube gateway for VirtualBox.</p><p>To get the <code class=\"language-text\">&lt;data-flow-server-uri></code> find the name of the service and use the <code class=\"language-text\">minikube service</code> command:</p><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash:\"><pre class=\"language-bash:\"><code class=\"language-bash:\">kubectl get svc\n...\nmy-release-data-flow-server     NodePort       10.97.74.123     &lt;none&gt;        80:30826/TCP\n\nminikube service my-release-data-flow-server --url\nhttp://192.168.99.105:30826</code></pre></div>\n      </div></div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">stream create inboundSftp --definition <span class=\"token string\">\"sftp --host=192.168.99.1 --username=&lt;user> --password=&lt;pass> --allow-unknown-keys=true --remote-dir=/remote-files --local-dir=/staging/shared-files --task.launch.request.taskName=fileIngestTask --task.launch.request.deployment-properties=deployer.*.kubernetes.volumes=[{'name':'staging','persistentVolumeClaim':{'claimName':'nfs-volume-claim'}}],deployer.*.kubernetes.volumeMounts=[{'mountPath':'/staging/shared-files','name':'staging'}] | task-launcher --spring.cloud.dataflow.client.server-uri=&lt;dataflow-uri>\"</span></code></pre></div>\n      </div>\n<div class=\"admonition tip\"><p>The <a href=\"https://github.com/spring-cloud-stream-app-starters/tasklauncher-dataflow/tree/master/spring-cloud-starter-stream-sink-task-launcher-dataflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">dataflow-task-launcher-sink</a> uses a <a href=\"https://docs.spring.io/spring-cloud-stream/docs/Elmhurst.BUILD-SNAPSHOT/api/org/springframework/cloud/stream/binder/PollableMessageSource.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">PollableMessageSource</a> controlled by a dynamic trigger with exponential backoff. By default, the sink polls its input destination every 1 second. If there are no task launch requests, the polling period will continue to double up to a maximum of 30 seconds. If a task launch request is present, the trigger resets to 1 second. The trigger parameters may be configured by setting the <code class=\"language-text\">task-launcher</code> sink properties <code class=\"language-text\">trigger.period</code> and <code class=\"language-text\">trigger.max-period</code> in the stream definition.</p></div>\n<h4 id=\"deploy-the-stream-1\" style=\"position:relative;\"><a href=\"#deploy-the-stream-1\" aria-label=\"deploy the stream 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploy the stream</h4>\n<p>When we deploy the stream we must also configure a volume mount for the <code class=\"language-text\">sftp</code> source.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">stream deploy inboundSftp --properties <span class=\"token string\">\"deployer.sftp.kubernetes.volumes=[{'name':'staging','persistentVolumeClaim':{'claimName':'nfs-volume-claim'}}],deployer.sftp.kubernetes.volumeMounts=[{'mountPath':'/staging/shared-files','name':'staging'}]\"</span></code></pre></div>\n      </div>\n<h4 id=\"verify-stream-deployment-2\" style=\"position:relative;\"><a href=\"#verify-stream-deployment-2\" aria-label=\"verify stream deployment 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Verify Stream deployment</h4>\n<p>We can see the status of the streams to be deployed with <code class=\"language-text\">stream list</code>, for example:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>stream list\n╔═══════════╤═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╤════════════╗\n║Stream Name│                                                                                                                  Stream Definition                                                                                                                  │   Status   ║\n╠═══════════╪═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪════════════╣\n║inboundSftp│sftp                                                                                                                                                                                                                                                 │The stream  ║\n║           │--task.launch.request.deployment-properties<span class=\"token operator\">=</span><span class=\"token string\">\"deployer.*.kubernetes.volumes=[{'name':'staging','persistentVolumeClaim':{'claimName':'nfs-volume-claim'}}],deployer.*.kubernetes.volumeMounts=[{'mountPath':'/staging/shared-files','name':'staging'}]\"</span>│has been    ║\n║           │--sftp.factory.password<span class=\"token operator\">=</span><span class=\"token string\">'******'</span> --sftp.local-dir<span class=\"token operator\">=</span>/staging/shared-files --sftp.factory.allow-unknown-keys<span class=\"token operator\">=</span>true --sftp.factory.username<span class=\"token operator\">=</span><span class=\"token string\">'******'</span> --sftp.remote-dir<span class=\"token operator\">=</span>/remote-files --sftp.factory.host<span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.99.1                                     │successfully║\n║           │--task.launch.request.taskName<span class=\"token operator\">=</span>fileIngestTask <span class=\"token operator\">|</span> task-launcher --spring.cloud.dataflow.client.server-uri<span class=\"token operator\">=</span>http://192.168.99.105:30826                                                                                                                  │deployed    ║\n╚═══════════╧═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╧════════════╝</code></pre></div>\n      </div>\n<h4 id=\"inspect-the-application-logs-2\" style=\"position:relative;\"><a href=\"#inspect-the-application-logs-2\" aria-label=\"inspect the application logs 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inspect the application logs</h4>\n<p>Use <code class=\"language-text\">kubectl</code> to list the apps. The <code class=\"language-text\">source</code> and <code class=\"language-text\">sink</code> applications should be in a started state.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">kubectl get pods\nNAME                                             READY   STATUS    RESTARTS   AGE\n<span class=\"token punctuation\">..</span>.\ninboundsftp-sftp-v12-6d55d469bd-t8znd            <span class=\"token number\">1</span>/1     Running   <span class=\"token number\">0</span>          6m24s\ninboundsftp-task-launcher-v12-555d4785c5-zjr6b   <span class=\"token number\">1</span>/1     Running   <span class=\"token number\">0</span>          6m24s\n<span class=\"token punctuation\">..</span>.</code></pre></div>\n      </div>\n<p>The log files of the <code class=\"language-text\">sftp</code> source would be useful to debug issues such as SFTP connection failures and to verify SFTP downloads.</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">kubectl logs inboundsftp-sftp-v12-6d55d469bd-t8znd</code></pre></div>\n      </div>\n<p>The logs for the <code class=\"language-text\">task-launcher</code> application would be useful to debug data flow connection issues and verify task launch requests:</p>\n<h4 id=\"drop-a-file-into-the-remote-directory-2\" style=\"position:relative;\"><a href=\"#drop-a-file-into-the-remote-directory-2\" aria-label=\"drop a file into the remote directory 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Drop a file into the remote directory</h4>\n<p>Sample data can be found in the <code class=\"language-text\">data/</code> directory of the <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow-samples/blob/master/dataflow-website/recipes/file-ingest/file-to-jdbc/file-to-jdbc.zip?raw=true\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">sample project</a>.</p>\n<p>Connect to the SFTP server and upload <code class=\"language-text\">data/name-list.csv</code> into the <code class=\"language-text\">remote-files</code> directory:</p>\n<p>When this file is detected, the <code class=\"language-text\">sftp</code> source will download it to the <code class=\"language-text\">/var/scdf/shared-files</code> directory specified by <code class=\"language-text\">--local-dir</code>. Here we are using the shared mount path <code class=\"language-text\">/var/scdf</code> that we configured for the <code class=\"language-text\">nfs</code> service. When the file is downloaded, the source emits a Task Launch Request.\nThe Task Launch Request includes the name of the task to launch along with the local file path, given as a command line argument.\nSpring Batch binds each command line argument to a corresponding JobParameter.\nThe FileIngestTask job processes the file given by the JobParameter named <code class=\"language-text\">localFilePath</code>.\nSince there have not been any recent requests, the task will launch within 30 seconds after the request is published (see tip above about configuring the launch trigger).</p>\n<h4 id=\"inspect-job-executions-2\" style=\"position:relative;\"><a href=\"#inspect-job-executions-2\" aria-label=\"inspect job executions 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inspect Job Executions</h4>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>job execution list\n╔═══╤═══════╤═════════╤════════════════════════════╤═════════════════════╤══════════════════╗\n║ID │Task ID│Job Name │         Start Time         │Step Execution Count │Definition Status ║\n╠═══╪═══════╪═════════╪════════════════════════════╪═════════════════════╪══════════════════╣\n║1  │1      │ingestJob│Thu Jun <span class=\"token number\">13</span> 08:39:59 EDT <span class=\"token number\">2019</span>│1                    │Created           ║\n╚═══╧═══════╧═════════╧════════════════════════════╧═════════════════════╧══════════════════╝</code></pre></div>\n      </div>\n<p>As well as list more details about that specific job execution:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow:<span class=\"token operator\">></span>job execution display --id <span class=\"token number\">1</span>\n╔═══════════════════════════════════════════╤═══════════════════════════════════╗\n║                    Key                    │               Value               ║\n╠═══════════════════════════════════════════╪═══════════════════════════════════╣\n║Job Execution Id                           │1                                  ║\n║Task Execution Id                          │424                                ║\n║Task Instance Id                           │1                                  ║\n║Job Name                                   │ingestJob                          ║\n║Create Time                                │Thu Jun <span class=\"token number\">13</span> 08:39:59 EDT <span class=\"token number\">2019</span>       ║\n║Start Time                                 │Thu Jun <span class=\"token number\">13</span> 08:39:59 EDT <span class=\"token number\">2019</span>       ║\n║End Time                                   │Thu Jun <span class=\"token number\">13</span> 08:40:07 EDT <span class=\"token number\">2019</span>       ║\n║Running                                    │false                              ║\n║Stopping                                   │false                              ║\n║Step Execution Count                       │1                                  ║\n║Execution Status                           │COMPLETED                          ║\n║Exit Status                                │COMPLETED                          ║\n║Exit Message                               │                                   ║\n║Definition Status                          │Created                            ║\n║Job Parameters                             │                                   ║\n║-spring.cloud.task.executionid<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span>     │424                                ║\n║run.id<span class=\"token punctuation\">(</span>LONG<span class=\"token punctuation\">)</span>                               │1                                  ║\n║-spring.datasource.username<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span>        │******                             ║\n║-spring.cloud.task.name<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span>            │fileIngestTask                     ║\n║-spring.datasource.password<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span>        │******                             ║\n║-spring.datasource.driverClassName<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span> │org.mariadb.jdbc.Driver            ║\n║localFilePath<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span>                      │/staging/shared-files/name-list.csv║\n║-spring.datasource.url<span class=\"token punctuation\">(</span>STRING<span class=\"token punctuation\">)</span>             │******                             ║\n╚═══════════════════════════════════════════╧═══════════════════════════════════╝</code></pre></div>\n      </div>\n<h4 id=\"verify-data-2\" style=\"position:relative;\"><a href=\"#verify-data-2\" aria-label=\"verify data 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Verify data</h4>\n<p>When the the batch job runs, it processes the file in the local directory <code class=\"language-text\">/staging/shared-files</code> and transforms each item to uppercase names and inserts it into the database.</p>\n<p>Open a shell in the <code class=\"language-text\">mysql</code> container to query the <code class=\"language-text\">people</code> table.:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">kubectl get pods\n<span class=\"token punctuation\">..</span>.\nmy-release-mysql-56f988dd6c-qlm8q                <span class=\"token number\">1</span>/1     Running\n<span class=\"token punctuation\">..</span>.</code></pre></div>\n      </div>\n<!-- Rolling my own to disable erroneous formating -->\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\">\n<pre class=\"language-bash\"><code>kubectl exec -it my-release-mysql-56f988dd6c-qlm8q -- /bin/bash\n# mysql -u root -p$MYSQL_ROOT_PASSWORD\nmysql&gt; select * from dataflow.people;\n</code></pre></div>\n      </div>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">+-----------+------------+-----------+\n| person_id | first_name | last_name |\n+-----------+------------+-----------+\n|         1 | AARON      | AABERG    |\n|         2 | AARON      | AABY      |\n|         3 | ABBEY      | AADLAND   |\n|         4 | ABBIE      | AAGAARD   |\n|         5 | ABBY       | AAKRE     |\n|         6 | ABDUL      | AALAND    |\n|         7 | ABE        | AALBERS   |\n|         8 | ABEL       | AALDERINK |\n|         9 | ABIGAIL    | AALUND    |\n|        10 | ABRAHAM    | AAMODT    |\n|      ...                           |\n+-----------+------------+-----------+</code></pre></div>\n      </div>\n<h2 id=\"limiting-concurrent-task-executions\" style=\"position:relative;\"><a href=\"#limiting-concurrent-task-executions\" aria-label=\"limiting concurrent task executions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Limiting concurrent task executions</h2>\n<p>This recipe processes a single file with 5000+ items. What if we drop 100 files to the remote directory?\nThe <code class=\"language-text\">sftp</code> source will process them immediately, generating 100 task launch requests. The Dataflow Server launches tasks asynchronously so this could potentially overwhelm the resources of the runtime platform.\nFor example, when running the Data Flow server on your local machine, each launched task creates a new JVM. In Cloud Foundry, each task creates a new container instance, and in Kubernetes a pod.</p>\n<p>Fortunately, Spring Cloud Data Flow provides configuration settings to <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#spring-cloud-dataflow-task-limit-concurrent-executions\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">limit the number of concurrently running tasks</a></p>\n<p>We can use this sample to see how this works.</p>\n<h3 id=\"lower-the-maximum-concurrent-task-executions\" style=\"position:relative;\"><a href=\"#lower-the-maximum-concurrent-task-executions\" aria-label=\"lower the maximum concurrent task executions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lower the maximum concurrent task executions</h3>\n<p>The sample project includes 20 files in the <code class=\"language-text\">data/spilt</code> directory. To observe the limit in action we can set the maximum concurrent tasks to 3.</p>\n<p>For running tasks on a local server, restart the server, adding a command line argument <code class=\"language-text\">spring.cloud.dataflow.task.platform.local.accounts[default].maximum-concurrent-tasks=3</code>.</p>\n<p>If running on Cloud Foundry:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cf set-env <span class=\"token operator\">&lt;</span>dataflow-server<span class=\"token operator\">></span> SPRING_CLOUD_DATAFLOW_TASK_PLATFORM_CLOUDFOUNDRY_ACCOUNTS<span class=\"token punctuation\">[</span>DEFAULT<span class=\"token punctuation\">]</span>_DEPLOYMENT_MAXIMUMCONCURRENTTASKS <span class=\"token number\">3</span></code></pre></div>\n      </div>\n<p>If running on Kubernetes, edit the Data Flow server <code class=\"language-text\">configmap</code>, for example:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl edit configmap my-release-data-flow-server</code></pre></div>\n      </div>\n<p>Add the 'maximum-concurrent-tasks` property as shown below:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">data</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">application.yaml</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">|</span><span class=\"token punctuation\">-</span>\n    <span class=\"token key atrule\">spring</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">cloud</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">dataflow</span><span class=\"token punctuation\">:</span>\n          <span class=\"token key atrule\">task</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">platform</span><span class=\"token punctuation\">:</span>\n              <span class=\"token key atrule\">kubernetes</span><span class=\"token punctuation\">:</span>\n                <span class=\"token key atrule\">accounts</span><span class=\"token punctuation\">:</span>\n                  <span class=\"token key atrule\">default</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token key atrule\">maximum-concurrent-tasks</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span>\n                    <span class=\"token key atrule\">limits</span><span class=\"token punctuation\">:</span>\n                      <span class=\"token key atrule\">memory</span><span class=\"token punctuation\">:</span> 1024Mi\n                      <span class=\"token key atrule\">cpu</span><span class=\"token punctuation\">:</span> 500m</code></pre></div>\n      </div>\n<p>After editing the configmap, delete the Data Flow server pod to force it to restart then wait for it to restart.</p>\n<h3 id=\"verify-maximum-concurrent-task-executions-is-enforced\" style=\"position:relative;\"><a href=\"#verify-maximum-concurrent-task-executions-is-enforced\" aria-label=\"verify maximum concurrent task executions is enforced permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Verify maximum concurrent task executions is enforced.</h3>\n<p>The task launcher sink polls the input destination. The polling period adjusts according to the presence of task launch requests and also to the number of currently running tasks reported via the Data Flow server's <code class=\"language-text\">tasks/executions/current</code> REST endpoint.\nThe sink queries this endpoint and will pause polling the input for new requests if the number of concurrent tasks for the task platform is at its limit.\nThis introduces a 1-30 second lag between the creation of the task launch request and the execution of the request, sacrificing some performance for resilience.\nTask launch requests will never be sent to a dead letter queue because the server is busy or unavailable.\nThe exponential backoff also prevents the app from querying the server excessively when there are no task launch requests.</p>\n<h3 id=\"monitor-the-task-executions\" style=\"position:relative;\"><a href=\"#monitor-the-task-executions\" aria-label=\"monitor the task executions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Monitor the task executions</h3>\n<p>Tail the <code class=\"language-text\">task-launcher</code> container logs.</p>\n<p>You can also monitor the Data Flow server for current task executions:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">watch</span> <span class=\"token function\">curl</span> <span class=\"token operator\">&lt;</span>dataflow-server-url<span class=\"token operator\">></span>/tasks/executions/current\nEvery <span class=\"token number\">2</span>.0s: <span class=\"token function\">curl</span> http://192.168.99.105:30826/tasks/executions/current\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  <span class=\"token number\">0</span>     <span class=\"token number\">0</span>    <span class=\"token number\">0</span>     <span class=\"token number\">0</span>    <span class=\"token number\">0</span>     <span class=\"token number\">0</span>      <span class=\"token number\">0</span>      <span class=\"token number\">0</span> --:--:-- --:--:-- --:--:--     0100    <span class=\"token number\">92</span>    <span class=\"token number\">0</span>    <span class=\"token number\">92</span>    <span class=\"token number\">0</span>     <span class=\"token number\">0</span>   <span class=\"token number\">1202</span>      <span class=\"token number\">0</span> --:--:-- --:--:-- --:--:\n--  <span class=\"token number\">1210</span>\n<span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"name\"</span><span class=\"token builtin class-name\">:</span><span class=\"token string\">\"default\"</span>,<span class=\"token string\">\"type\"</span><span class=\"token builtin class-name\">:</span><span class=\"token string\">\"Kubernetes\"</span>,<span class=\"token string\">\"maximumTaskExecutions\"</span>:3,<span class=\"token string\">\"runningExecutionCount\"</span>:0<span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span></code></pre></div>\n      </div>\n<h3 id=\"run-the-sample-with-multiple-files\" style=\"position:relative;\"><a href=\"#run-the-sample-with-multiple-files\" aria-label=\"run the sample with multiple files permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Run the sample with multiple files</h3>\n<p>With the sample stream deployed, upload the 20 files in <code class=\"language-text\">data/spilt</code> to <code class=\"language-text\">/remote-files</code> files. In the <code class=\"language-text\">task-launcher</code> logs, you should see the exponential backoff working:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">2019-06-14 15:00:48.247  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling period reset to 1000 ms.\n2019-06-14 15:00:49.265  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Launching Task fileIngestTask on platform default\n2019-06-14 15:00:50.433  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Launching Task fileIngestTask on platform default\n2019-06-14 15:00:51.686  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Launching Task fileIngestTask on platform default\n2019-06-14 15:00:52.929  WARN 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : The data Flow task platform default has reached its concurrent task execution limit: (3)\n2019-06-14 15:00:52.929  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling paused- increasing polling period to 2 seconds.\n2019-06-14 15:00:55.008  WARN 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : The data Flow task platform default has reached its concurrent task execution limit: (3)\n2019-06-14 15:00:55.008  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling paused- increasing polling period to 4 seconds.\n2019-06-14 15:00:59.039  WARN 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : The data Flow task platform default has reached its concurrent task execution limit: (3)\n2019-06-14 15:00:59.040  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling paused- increasing polling period to 8 seconds.\n2019-06-14 15:01:07.104  WARN 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : The data Flow task platform default has reached its concurrent task execution limit: (3)\n2019-06-14 15:01:07.104  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling paused- increasing polling period to 16 seconds.\n2019-06-14 15:01:23.127  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling resumed\n2019-06-14 15:01:23.128  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Launching Task fileIngestTask on platform default\n2019-06-14 15:01:23.232  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling period reset to 1000 ms.\n2019-06-14 15:01:24.277  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Launching Task fileIngestTask on platform default\n2019-06-14 15:01:25.483  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Launching Task fileIngestTask on platform default\n2019-06-14 15:01:26.743  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Launching Task fileIngestTask on platform default\n2019-06-14 15:01:28.035  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Launching Task fileIngestTask on platform default\n2019-06-14 15:01:29.324  WARN 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : The data Flow task platform default has reached its concurrent task execution limit: (3)\n2019-06-14 15:01:29.325  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling paused- increasing polling period to 2 seconds.\n2019-06-14 15:01:31.435  WARN 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : The data Flow task platform default has reached its concurrent task execution limit: (3)\n2019-06-14 15:01:31.436  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling paused- increasing polling period to 4 seconds.\n2019-06-14 15:01:35.531  WARN 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : The data Flow task platform default has reached its concurrent task execution limit: (3)\n2019-06-14 15:01:35.532  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling paused- increasing polling period to 8 seconds.\n2019-06-14 15:01:43.615  WARN 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : The data Flow task platform default has reached its concurrent task execution limit: (3)\n2019-06-14 15:01:43.615  INFO 1 --- [pool-2-thread-1] o.s.c.s.a.t.l.d.s.LaunchRequestConsumer  : Polling paused- increasing polling period to 16 seconds.</code></pre></div>\n      </div>\n<h2 id=\"avoiding-duplicate-processing\" style=\"position:relative;\"><a href=\"#avoiding-duplicate-processing\" aria-label=\"avoiding duplicate processing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Avoiding duplicate processing</h2>\n<p>The <code class=\"language-text\">sftp</code> source will not process files that it has already seen.\nIt uses a <a href=\"https://docs.spring.io/spring-integration/docs/current/reference/html/#jdbc-metadata-store\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Metadata Store</a> to keep track of files by extracting content from messages at runtime.\nOut of the box, it uses an in-memory Metadata Store, but it is pluggable to a persistent store used for production deployments\nThus, if we re-deploy the stream, or restart the <code class=\"language-text\">sftp</code> source, this state is lost and files will be reprocessed.</p>\n<p>Thanks to the magic of Spring, we can auto-configure one of the available persistent Metadata Stores to prevent duplicate processing.</p>\n<p>In this example, we will <a href=\"https://github.com/spring-cloud-stream-app-starters/core/tree/master/common/stream-apps-metadata-store-common#jdbc\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">auto configure the JDBC Metadata Store</a> since we are already using a JDBC database.</p>\n<h3 id=\"configure-and-build-the-sftp-source\" style=\"position:relative;\"><a href=\"#configure-and-build-the-sftp-source\" aria-label=\"configure and build the sftp source permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Configure and Build the SFTP source</h3>\n<p>For this we add some JDBC dependencies to the <code class=\"language-text\">sftp-dataflow</code> source.</p>\n<p>Clone the [sftp]<a href=\"https://github.com/spring-cloud-stream-app-starters/sftp\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/spring-cloud-stream-app-starters/sftp</a> stream app starter.\nFrom the sftp directory. Replace <code class=\"language-text\">&lt;binder></code> below with <code class=\"language-text\">kafka</code> or <code class=\"language-text\">rabbit</code> as appropriate for your configuration:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">./mvnw clean <span class=\"token function\">install</span> -DskipTests -PgenerateApps\n<span class=\"token builtin class-name\">cd</span> apps/sftp-dataflow-source-<span class=\"token operator\">&lt;</span>binder<span class=\"token operator\">></span></code></pre></div>\n      </div>\n<p>Add the following dependencies to <code class=\"language-text\">pom.xml</code>:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.springframework.integration<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>spring-integration-jdbc<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.springframework.boot<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>spring-boot-starter-jdbc<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>com.h2database<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>h2<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span></code></pre></div>\n      </div>\n<p>If you are running on Kubernetes use the mariadb driver instead of H2:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.mariadb.jdbc<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>mariadb-java-client<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>2.3.0<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span></code></pre></div>\n      </div>\n<p>If you are running on a local server with the in memory H2 database, set the JDBC url in <code class=\"language-text\">src/main/resources/application.properties</code> to use the Data Flow server's database:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spring.datasource.url=jdbc:h2:tcp://localhost:19092/mem:dataflow</code></pre></div>\n      </div>\n<p>If running on Kubernetes, set the datasource to use the internal IP of the <code class=\"language-text\">mysql</code> service, e.g.:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spring.datasource.url=jdbc:mysql://10.98.214.235:3306/dataflow</code></pre></div>\n      </div>\n<p>If you are running in Cloud Foundry or Kubernetes, add the following property to <code class=\"language-text\">src/main/resources/application.properties</code>:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spring.integration.jdbc.initialize-schema=always</code></pre></div>\n      </div>\n<p>Build the <code class=\"language-text\">sftp</code> source and register it with Data Flow.</p>\n<h3 id=\"run-the-sample-app\" style=\"position:relative;\"><a href=\"#run-the-sample-app\" aria-label=\"run the sample app permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Run the sample app</h3>\n<p>Follow the instructions for running the sample on your preferred platform, up to the <code class=\"language-text\">Drop file...</code> Step`.</p>\n<p>If you have already completed the main exercise, restore the data to its initial state, and redeploy the stream:</p>\n<ul>\n<li>Clean the local and remote data directories</li>\n<li>Execute the SQL command <code class=\"language-text\">DROP TABLE PEOPLE;</code> in the database</li>\n<li>Undeploy the stream, and deploy it again to run the updated <code class=\"language-text\">sftp</code> source</li>\n</ul>\n<p>If you are running in Cloud Foundry, set the deployment properties to bind <code class=\"language-text\">sftp</code> to the <code class=\"language-text\">mysql</code> service. For example:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dataflow<span class=\"token operator\">></span>stream deploy inboundSftp --properties <span class=\"token string\">\"deployer.sftp.cloudfoundry.services=nfs,mysql\"</span></code></pre></div>\n      </div>\n<h3 id=\"drop-a-file-into-the-remote-directory-3\" style=\"position:relative;\"><a href=\"#drop-a-file-into-the-remote-directory-3\" aria-label=\"drop a file into the remote directory 3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Drop a file into the remote directory</h3>\n<p>Let's use one small file for this.\nThe directory <code class=\"language-text\">data/split</code> in the sample project contains the contents of\n<code class=\"language-text\">data/name-list.csv</code> split into 20 files. Upload <code class=\"language-text\">names_aa.csv</code>:</p>\n<h3 id=\"inspect-the-database\" style=\"position:relative;\"><a href=\"#inspect-the-database\" aria-label=\"inspect the database permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inspect the database</h3>\n<p>Using a Database tool, as described above, view the contents of the <code class=\"language-text\">INT_METADATA_STORE</code> table.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 617px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 26%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAABMUlEQVQY0z2P20oCYRSFffkuoiB6h6BIiUihTEorNM3TqM04OkfHw3geHRBqRv36FfPiY7EXi7X3jpw82lzEqpzfVjiL1Ti9KXH5oBDNGTx/ViiUJFpmF70zwNjTPzA4otv9I5FErUP1u0ZRkSmZFsWmUM1Ckho0myrD0YTBcMTwHzHvcEdjXDGPhE5nHtO5x2w2J1K3+tQNFUkp01AlFL3BwHWYjHcFLr2uQ7/XpWU5yLqJKha3WiqG1kZta8hGB8u2sSwT3REX1mSNdLZI6jXHy1uezHuBQkUWxY4IDMWrLmZvTKVpEU2kiN3FubqOcR9/IpMrk/z4IpnOki83RLkolBQN3/cJN1uCcMNvuOYnCAnWW+FBeNBA+J63YL5YMhfqLXwWS5/VarXPrEVmu4U/ri5lT+m3fXwAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/b5225ae6c028be9ce4853b1afc998f90/507e6/metadata_store_1.webp 200w,\n/static/b5225ae6c028be9ce4853b1afc998f90/28a80/metadata_store_1.webp 400w,\n/static/b5225ae6c028be9ce4853b1afc998f90/0acf1/metadata_store_1.webp 617w\"\n          sizes=\"(max-width: 617px) 100vw, 617px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/b5225ae6c028be9ce4853b1afc998f90/36ca5/metadata_store_1.png 200w,\n/static/b5225ae6c028be9ce4853b1afc998f90/a3397/metadata_store_1.png 400w,\n/static/b5225ae6c028be9ce4853b1afc998f90/d7556/metadata_store_1.png 617w\"\n          sizes=\"(max-width: 617px) 100vw, 617px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/b5225ae6c028be9ce4853b1afc998f90/d7556/metadata_store_1.png\"\n          alt=\"JDBC Metadata Store\"\n          title=\"JDBC Metadata Store\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n    </span></p>\n<p>Note that there is a single key-value pair, where the key identies the file name (the prefix <code class=\"language-text\">sftpSource/</code> provides a namespace for the <code class=\"language-text\">sftp</code> source app) and the value is a timestamp indicating when the message was received.\nThe metadata store tracks files that have already been processed.\nThis prevents the same files from being pulled from the remote directory on every polling cycle.\nOnly new files, or files that have been updated will be processed.</p>\n<p>Since there are no uniqueness constraints on the <code class=\"language-text\">PEOPLE</code> table, a file processed multiple times by our batch job will result in duplicate table rows. Since we have configured a persistent metadata store, duplicate processing will be prevented across container restarts. You can verify this by undeploying and redeploying the stream, or simply restarting the <code class=\"language-text\">sftp</code> source.</p>\n<p>If we view the <code class=\"language-text\">PEOPLE</code> table, it should look something like this:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 439px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.50000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAAD9ElEQVQ4y21Ux3LjRhDFl7vKvvkvfHLtYWuPW9JKosQMgggMAAgm5EwADGCSZPu5ZyjZPvjQNWQnvH79ZoQ7M0RXmUIUB2h1RbTaXQwkGc2OCFlWsA5y/HQf4+cvY/zyu4pfv1n4rWFj7ScI4xR+lCLglvBT+KZ4+NHV8NQU8djo4HHioGW4GKpTfNfWuGsP8fVexJfvPdz1TPTNCF0jxngRwrIDzNY3s+yQn8KdkUBeWzDsEdzIRlaUKPcHlJsMXpIhikLEoYc0ClBtUuzKHHWV0+8MZVGQbbhtMhYrIIydHMvQheGvsHKXWK9W8F0HXphg7YWw6XQcB74fwLFt+AEhIWQ2jRgGATzP436XzrkbQjCXPqyZhZ6qo9nq4kejjW5PwmA8x5Ns4kGa4P6hgTb5Hp6aGGo6+S08ygb9f8bTcxtPL21I2hRNdQ6hp+iYTnWE2R5xcfywGn5aYUG8tDoD/HgR+f+kPCHKD4jzHX1giIeXHuZOgrQ6I6D6rDxAaA3GMM0ZdsdX7E+v/Dyc34jHE7wogyRrEOUJqsOF4m88h5kyMmDObRTbGtv6ymOsjjc0DAP59ozN7mbF/oKkOHBpPLf6kMcWqvqNck4Uv/CTNWz3VTRaIiE8cn9JddRwRA1N3qQkFOysDlekBH/txaRNCebCJeRvFDt/5Jwha9RQVGCtfV7DjCEVnnsqDNPkTZiDnWxsxsfaJc31h9AtGzsaiY3NckpqONbnRMUYXlzwcdmHdkdq2BlOOMK0OiGjsZnlBD/eHLB0YxpLJtHG3JdtbzlpWUObLvBISxmMZpwOVl/cRmZLMbFny/gg/N+lpBAlBWmxx/HyTjlXnrOrz9BnS0jKCP2BDD8pUVOcxWhkBTohZHJhsmCWEgo/3cJYeGgSh32SVkSImTxYnMlKJp12RFKAaiDc1IjJzxYrNLoKRqMRR1ATsvr8itP1DyR5CdePMVQ0DIYq8bgi9FfKI3kQUn22QFccYkFLub7/xdGxGOdQ00b8C9wIKUOyoldm4aaEcEjbVOkKFv/JqTGgm9XoSFj6OfdFVMc4Fl76GjXU/gdhBS9IoI51ejB2eH0HR8ByDoR0algQh8ShpCGIc15zpFqhSQ3Zu5d88lOyL12w8jPMVgFHp+r0aBBCL9ly9AyhRDpstGXadJ9UQNdvexM8NaQCVeWb5dfqeOVoo6yA7UVQRzrnUFLG5Lttc1dfMNHpQRlomBiLf64jm0547sqQFYWjYlpilu+vhDCFufRokyo3P6mwIf8t54g+cf9Aj8bEcrg2k+rEry2XDUP4yR/bFuMj/eBwas6xcnycX//k3H1yaC0dun4TKPRsVaRZxi/j8G8rV6nDa49N+wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/eff8ab7e482000b93d785d3c20b2b7e6/507e6/people_table_1.webp 200w,\n/static/eff8ab7e482000b93d785d3c20b2b7e6/28a80/people_table_1.webp 400w,\n/static/eff8ab7e482000b93d785d3c20b2b7e6/ba3b5/people_table_1.webp 439w\"\n          sizes=\"(max-width: 439px) 100vw, 439px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/eff8ab7e482000b93d785d3c20b2b7e6/36ca5/people_table_1.png 200w,\n/static/eff8ab7e482000b93d785d3c20b2b7e6/a3397/people_table_1.png 400w,\n/static/eff8ab7e482000b93d785d3c20b2b7e6/baa1b/people_table_1.png 439w\"\n          sizes=\"(max-width: 439px) 100vw, 439px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/eff8ab7e482000b93d785d3c20b2b7e6/baa1b/people_table_1.png\"\n          alt=\"People table\"\n          title=\"People table\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n    </span></p>\n<p>Now let's upload the same file to the SFTP server, or if you are logged into it, you can just update the timestamp:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">touch</span> /remote-files/names_aa.csv</code></pre></div>\n      </div>\n<p>Now the file will be reprocessed and the <code class=\"language-text\">PEOPLE</code> table will contain duplicate data. If you <code class=\"language-text\">ORDER BY FIRST_NAME</code>, you will see something like this:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 443px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 77.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsSAAALEgHS3X78AAADSElEQVQ4y2WTy2/qRhTG/bd30W67qtRNs4qqtot7b1UpV0kIAWywsTF+AQbzsLHxC0zAgCGJrr6emaSp1C4+zXjOY37nnLHw3X2K7/+w8MNvOn78a4rrhxluBiuIfQeGqkCWZXQ6MnS9z/eyrCCOY6xWK6Rp+j8J190QN6KJrw8KvtZlfFZnuOvaUBUZdduDRAnakoRms4XhcIQoihCGIUJaP/akt30E4WaQoDcfYTTXESY+kixHTFqRwzxKEIVLLAMfYRAQQYJ1nqLIM6wz0nr9oYzotsUGgrHI4EULOEsPU3+KxXyOcBkgSjLMohxedsQ0zLFIdrSusUhLuFGB+SolqpAuC+Av5vCDJbyACC0vgTOaoq3beHxs4f5RhCgpEDUbn0UHV/cDXH1q4NfbPq6+SPgkeriuD3CnOrir1VEj/xrFdannzf4Ywp0eQBv6iLId4s2RK8z26KgGak0FP/3yO36+/hO38hD1nodad4zblo6GqOC23oY7i5BsTxSzQ16UEBpyH2PXxe74jP3pXxn2EDM/oqFoEEnZZodid8SGxFatb2O6iHB+BcVeeMyhemEJDQxHI+RPFda7N+Uk1RhQT2MiNSF1DaQFJSqfsSkv3EfRLH7OKtvszzx+W57fCEcjlx8W5bto3zOHmAcxmlIXcs/mSYp3n/XuRIQOGpIKa+jR2YXHPx0uEB4kDS6VzBy3dMBFDrwkKvmx2abyJyirV+7Dgor9CTpdqFJSRTOpDRWP21PpQqtrUskuUmosw2bKSIruYDKP8NDsoGeNeakZ86HgdHuE0nPQknW0qSXsm8WwCngP3f8OhfZ9cwB/GUPsdDFwZzhS9xlBSfbdoYJhDdFWelB1k6jP70N5hlATNU7InktSnD7UoaYPJgFqjQ6cyZLILohpMOyJxJsD9dVBXVThLXMirMh24n2mhNRYy8KBCNgNbPRsNaw3wrbcxXKVoXr+xumO5xciPcO0R9B0iz8ZRl9SzIlsQksxYJg2VsXp42Gz20Q6t9wFEcrQzAmRVVi926J8TwOhh07VWWP6x5/OiNZH3n+hLvU44enyym/4R87AhR/GRGFiMvVRkZ3RMb+SCMeTGdls8klwfvmGI1VWXV7wNy32gHMyrE/EAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/3db8661e5629898ff373ef74a2d98541/507e6/people_table_2.webp 200w,\n/static/3db8661e5629898ff373ef74a2d98541/28a80/people_table_2.webp 400w,\n/static/3db8661e5629898ff373ef74a2d98541/1ea1b/people_table_2.webp 443w\"\n          sizes=\"(max-width: 443px) 100vw, 443px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/3db8661e5629898ff373ef74a2d98541/36ca5/people_table_2.png 200w,\n/static/3db8661e5629898ff373ef74a2d98541/a3397/people_table_2.png 400w,\n/static/3db8661e5629898ff373ef74a2d98541/27348/people_table_2.png 443w\"\n          sizes=\"(max-width: 443px) 100vw, 443px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/3db8661e5629898ff373ef74a2d98541/27348/people_table_2.png\"\n          alt=\"People table with duplicates\"\n          title=\"People table with duplicates\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n    </span></p>\n<p>Of course, if we drop another one of files into the remote directory, that will processed and we will see another entry in the Metadata Store.</p>","headings":[{"value":"SFTP to JDBC File Ingest","depth":1},{"value":"Prerequisites","depth":2},{"value":"Data Flow Installation","depth":3},{"value":"Using Data Flow","depth":3},{"value":"SFTP server","depth":3},{"value":"NFS configuration","depth":3},{"value":"Cloud Foundry NFS configuration","depth":4},{"value":"Kubernetes NFS configuration","depth":4},{"value":"Deployment","depth":2},{"value":"Local","depth":3},{"value":"Register the applications","depth":4},{"value":"Create the task","depth":4},{"value":"Create and deploy the stream","depth":4},{"value":"Verify Stream deployment","depth":4},{"value":"Inspect the application logs","depth":4},{"value":"Drop a file into the remote directory","depth":4},{"value":"Inspect Job Executions","depth":4},{"value":"Verify data","depth":4},{"value":"Cloud Foundry","depth":3},{"value":"Prerequisites","depth":4},{"value":"Register the applications","depth":4},{"value":"Create the task","depth":4},{"value":"Create the stream","depth":4},{"value":"Deploy the stream","depth":4},{"value":"Verify Stream deployment","depth":4},{"value":"Inspect the application logs","depth":4},{"value":"Drop a file into the remote directory","depth":4},{"value":"Inspect Job Executions","depth":4},{"value":"Verify data","depth":4},{"value":"Kubernetes","depth":3},{"value":"Prerequisites","depth":4},{"value":"Register the applications","depth":4},{"value":"Create the task","depth":4},{"value":"Create the stream","depth":4},{"value":"Deploy the stream","depth":4},{"value":"Verify Stream deployment","depth":4},{"value":"Inspect the application logs","depth":4},{"value":"Drop a file into the remote directory","depth":4},{"value":"Inspect Job Executions","depth":4},{"value":"Verify data","depth":4},{"value":"Limiting concurrent task executions","depth":2},{"value":"Lower the maximum concurrent task executions","depth":3},{"value":"Verify maximum concurrent task executions is enforced.","depth":3},{"value":"Monitor the task executions","depth":3},{"value":"Run the sample with multiple files","depth":3},{"value":"Avoiding duplicate processing","depth":2},{"value":"Configure and Build the SFTP source","depth":3},{"value":"Run the sample app","depth":3},{"value":"Drop a file into the remote directory","depth":3},{"value":"Inspect the database","depth":3}],"fields":{"path":"/docs/2.7.x/recipes/batch/sftp-to-jdbc/","version":"2.7.x","category":"recipes","sourcePath":"pages/6-recipes/7-batch/2-sftp-to-jdbc.md"},"frontmatter":{"title":"SFTP to JDBC","summary":null,"path":"recipes/batch/sftp-to-jdbc/","toc":null,"prevNext":null}}},"pageContext":{"slug":"/docs/2.7.x/recipes/batch/sftp-to-jdbc/","version":"2.7.x","versionPath":""}},"staticQueryHashes":["2044043181"]}